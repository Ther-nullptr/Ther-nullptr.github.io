[{"content":"以下对于distill model的研究将不只局限于ASR领域，还包括CV和NLP领域等。\nloss algorithms 首先需要借助PyTorch平台简要介绍知识蒸馏中经常需要用到的一些loss api。\nKL loss KL div的计算方式如下：\n其中，PyTorch API为：torch.nn.KLDivLoss。\nKL div衡量的是给定任意分布偏离真实分布的程度。从公式中可以看出，$p(x_i)$ 有更高概率的匹配区域比低 $p(x_i)$ 概率的匹配区域更加重要。\n实际上，我们有：\n等式右边第一项为交叉熵，由于$H(X)$（某一事件的熵）是固定的，所以KL散度的含义就是，相对于最优的编码，使用错误的编码浪费的比特数。\ncos embedding loss PyTorch API为：torch.nn.CosineEmbeddingLoss。\ncontrastive loss BCE loss BCEloss解决的是二分类问题，或者可以视作一种简化版的交叉熵损失函数——将所有的其它例子都视作负例。\nInfoNCE loss 同样可以使用温度参数$\\tau$进行调节。\n$l1$/$l2$ loss l1: torch.nn.L1Loss\nl2: torch.nn.MSELoss\ndistill基础思想 distill最初提出于论文Distilling the Knowledge in a Neural Network。\n文章在最初指出了混合模型在提高精度方面的作用，但混合模型具有开销较大的特点，一个较好的办法是将其蒸馏至一个student model中。在传统的认知中，我们认为知识蕴含在形式化的模型参数中，因此很难想象在变换模型形式的基础上保留学到的知识。\n该论文指出对知识的正确认识应该是“it is a learned mapping from input vectors to output vectors”。更具体地讲，teacher model具有良好的泛化能力，蒸馏的目的就是要让student model学会teacher model的泛化能力，从而起到比直接训练student model更好的结果。\n如何学习这种泛化能力？蒸馏的基础思想是使用teacher model的soft target（model预测的概率分布）训练student model（对应的，hard target指的是model预测的ground truth）。使用soft target训练有两个好处：\n 相比hard target有更多信息——soft target中可以携带很多有用的信息，而这些信息不可能用一个hard target来编码。相当于提高了label的质量，允许model使用更少的参数。 梯度差异小，lr可以更高。  但使用soft target存在一个问题：有些概率分布很小，在计算loss时可以忽略不计，但其中蕴含的一些关键信息会丢失。前人的解决方案是使用logits（softmax的input）而不是probablity（实际上，后文指出，这是一种特殊情况的distillation）。本文中提出了一种叫做“distillation”的方法，用于提高softmax结果的“温度”。直到繁琐的模型产生一套合适的软目标。然后我们在训练小模型时使用同样的高温来匹配这些软目标。\n“温度”的使用方法如下。一般来说，$T$越大，产生的概率分布越柔和。值得注意的是，student model在训练时使用$T\u0026gt;1$，但在推理时使用$T=1$。\n从以上分析可以看出，蒸馏实际上是一个自监督过程，我们也可以引入监督过程——使用两个不同目标函数的加权平均，第一个目标函数是与软目标的交叉熵，这个交叉熵的计算方法是使用蒸馏模型的softmax中的高温，就像从繁琐的模型中生成软目标时一样，第二个目标函数是与正确标签的交叉熵（通常使用较低的权重）。\n 由于软目标产生的梯度的大小为$\\frac{1}{T^2}$，因此在使用硬目标和软目标时，必须将其乘以$T^2$。这可以确保在试验元参数时，如果改变蒸馏所用的温度，硬目标和软目标的相对贡献大致保持不变。\n distill model联合训练 参考自论文Apprentice: Using KD Techniques to Improve Low-Precision Network Accuracy。\n该论文主要针对低精度的学生网络而言。论文中一共提供了3种训练方法：第一种方案（方案A）联合训练两个网络\u0026ndash;全精度的教师和低精度的学生网络。第二种方案（方案B）只训练低精度的学生网络，但在整个训练过程中从训练好的全精度教师网络中提取知识。第三种方案（方案C）从训练好的全精度教师和全精度学生网络开始，但在降低了学生网络的精度后对其进行微调。第二种相比第一种收敛更快，第三种准确率最高。在以上三种结构中，学生网络具有与教师网络类似的拓扑结构，只是学生网络具有低精度的神经元，而教师网络的神经元则以全精度运行。\n其训练方式可用下图概括：\n其中$\\alpha=1,\\beta=0.5,\\gamma=0.5$。\nKL div的应用 总结一下，之前在蒸馏时计算loss的函数为： $$ \\mathtt {loss} = \\alpha T^2 \\mathtt{CEloss}(Q_s^\\tau,Q_t^\\tau)+(1-\\alpha) \\mathtt{CEloss}(Q_s,y) $$ 现在我们将其改写为： $$ \\mathtt {loss} = \\alpha T^2 \\mathtt{KLdiv}(Q_s^\\tau,Q_t^\\tau)+(1-\\alpha) \\mathtt{CEloss}(Q_s,y) $$ 两者的本质是一样的。\ndistill teacher的hidden states 参考自论文FITNETS: HINTS FOR THIN DEEP NETS：\n论文指出，使用教师学到的中间表征作为提示，以改善训练过程和学生的最终表现。因为学生的中间隐藏层一般会比教师的中间隐藏层小，所以要引入额外的参数，将学生的隐藏层映射到教师隐藏层的预测上。\n论文指出了传统知识蒸馏模型的一个局限性：以前所有与卷积神经网络相关的工作都集中在将教师网络或网络集合压缩到宽度和深度相似的网络中，或者压缩到较浅和较宽的网络中；而没有利用深度的优势。因此本文指出了一种新的distill方法：使用同等深度但更窄的网络，从教师的隐藏层中引入中间层次的提示来指导学生的训练过程。\n在传统的知识蒸馏模型中，如果加深student model的深度，KDLoss的效果会变差。因此，此处引入了“提示层”和“引导层”的概念。一个提示被定义为负责指导学生学习过程的教师隐藏层的输出。类似地，我们选择FitNet的一个隐藏层，即引导层，从教师的提示层学习。我们希望引导层能够预测提示层的输出。我们选择提示层为教师网络的中间层。同样地，我们选择引导层作为学生网络的中间层。\n其中$\\mathbf{W_r}$指的是回归器。为了减小参数量，回归器一般使用卷积层而不是全连接层。\n训练分为两个阶段：第一个阶段利用Hint-based loss诱导学生网络达到一个合适的初始化状态（只更新$\\mathbf{W_Guided}$与$\\mathbf{W_r}$）；第二个阶段利用教师网络的soft label指导整个学生网络的训练（即知识蒸馏），且Total loss中Soft target相关部分所占比重逐渐降低，从而让学生网络能够全面辨别简单样本与困难样本（教师网络能够有效辨别简单样本，而困难样本则需要借助真实标注，即Hard target）。\ndistill在NLP领域的应用——DistilBERT和TinyBERT DistilBERT 参考自论文DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter和TinyBERT: Distilling BERT for Natural Language Understanding。\nDistillBERT用到了3种loss——除了传统无监督的$L_{CE}$和有监督的$L_{mlm}$，还引入了一个cos embedding loss $L_{cos}$。它将倾向于对齐学生和教师隐藏状态向量的方向。权重为5:2:1。\nDistillBERT每隔两层就抽取一层进行初始化，缩减了一半的层数。\nTinyBERT TinyBERT的蒸馏分为两个阶段：在一般蒸馏阶段，没有微调的原始BERT作为教师模型。学生的TinyBERT通过提议的Transformer蒸馏法在一般领域的语料库上模仿教师的行为。之后，我们得到一个一般的TinyBERT，作为学生模型的初始化，用于进一步的蒸馏。在特定任务的蒸馏阶段，我们首先进行数据增强，然后使用经过微调的BERT作为教师模型在增强后的数据集上进行蒸馏。应该指出的是，这两个阶段对于提高TinyBERT的性能和泛化能力至关重要。\n一般蒸馏帮助TinyBERT学习嵌入在预训练的BERT中的丰富知识，这对提高TinyBERT的泛化能力起到了重要作用。特定任务蒸馏进一步向TinyBERT传授来自微调的BERT的知识。\n需要指出的是，在finetune阶段进行蒸馏时，需要对数据进行增强。\n而模型的loss来源有3种：1）嵌入层的输出；2）来自Transformer层的隐藏状态和注意矩阵；3）预测层输出的logits。\n具体来讲，其计算方法如下：\n其中，teacher model有$N$层，student model有$M$层，$m=0$为embedding层，$m=M+1$为logits。\n在计算时，我们需要使用attention和hidden states，两者的区别如下：\n$\\mathcal{L_layer}$的定义如下：\ndistill在ASR领域的应用——DistilHubert distilhubert在计算loss时，并不是直接使用层的特征，而是使用student model第二层的输出映射过的特征与teacher model进行计算loss。\n我们可以与tinybert做一个对比：distilhubert在训练时没有使用student各层的信息，而是使用末端output的信息；但tinybert的计算则是基于层的，而且分为attention metrics和hidden state。当然一个可能的考量是distilhubert层数较少而tinybert层数较多。\ndistill与对比学习 参考自论文From Dense to Sparse: Contrastive Pruning for Better Pre-trained Language Model Compression。\n大多数研究只注意在剪枝过程中对下游任务的特定知识，而忽略了在剪枝模型中是否很好地保持了原PLM的任务诊断性知识。这会导致严重的灾难问题；此外在极高的稀疏度下，修剪后的模型与原始密集模型相比性能急剧下降。\n我们有三种修剪模块：PrC、SnC和FiC。\n其loss分为两部分：无监督和监督。其中监督数据的正例只需要其对应的标签相同。\n PrC Contrastive Learning with Pre-trained Model。在向特定的下游任务转移学习时，原始PLM中与任务无关的知识倾向于丢失，这可能导致灾难性的遗忘问题。因此我们需要引入一个PrC模块来维护这种基于对比学习的通用语言知识。 SnC 该模型使用了迭代修剪的算法，这些中间模型会被保存。当前的剪枝模型能够基于对比学习从这些快照中学习。 FiC 在finetune model上的学习。  文章提供了两种剪枝方式：\n最后将loss相加即可：\n无监督少量数据的distill 参考自论文From Dense to Sparse: Contrastive Pruning for Better Pre-trained Language Model Compression。\n该方法适用于只有少量的无标签数据。\n(1)通过压缩教师网获得学生网；(2)在学生网的每个区块末尾增加一个1×1的卷积层，并通过最小二乘回归估计1×1卷积层的参数来对齐教师和学生；(3)将增加的1×1卷积层合并到先前的卷积层中，获得最终的学生网。\nreference ","date":"2022-08-17T08:22:05+08:00","permalink":"https://ther-nullptr.github.io/posts/research/knowledge-distillation-papers/","title":"knowledge distillation papers"},{"content":"structure of finetune models 首先有必要记录一下finetune model的结构（以wav2vec2、hubert、data2vec）为例：\nwav2vec2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  Wav2VecCtc( (w2v_encoder): Wav2VecEncoder( (w2v_model): Wav2Vec2Model( (feature_extractor): ConvFeatureExtractionModel( (conv_layers): ModuleList( (0): Sequential( (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True) (3): GELU() ) (1): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (2): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (3): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (4): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (5): Sequential( (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (6): Sequential( (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) ) ) (post_extract_proj): Linear(in_features=512, out_features=768, bias=True) (dropout_input): Dropout(p=0.0, inplace=False) (dropout_features): Dropout(p=0.1, inplace=False) (quantizer): None (project_q): None (encoder): TransformerEncoder( (pos_conv): Sequential( (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16) (1): SamePad() (2): GELU() ) (layers): ModuleList( (0): TransformerSentenceEncoderLayer( (self_attn): MultiheadAttention( (dropout_module): FairseqDropout() (k_proj): Linear(in_features=768, out_features=768, bias=True) (v_proj): Linear(in_features=768, out_features=768, bias=True) (q_proj): Linear(in_features=768, out_features=768, bias=True) (out_proj): Linear(in_features=768, out_features=768, bias=True) ) (dropout1): Dropout(p=0.0, inplace=False) (dropout2): Dropout(p=0.1, inplace=False) (dropout3): Dropout(p=0.0, inplace=False) (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) (fc1): Linear(in_features=768, out_features=3072, bias=True) (fc2): Linear(in_features=3072, out_features=768, bias=True) (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) ) ... ) (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) ) (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True) (final_proj): None ) (final_dropout): Dropout(p=0.0, inplace=False) (proj): Linear(in_features=768, out_features=32, bias=True) ) )   hubert 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  HubertCtc( (w2v_encoder): HubertEncoder( (w2v_model): HubertModel( (feature_extractor): ConvFeatureExtractionModel( (conv_layers): ModuleList( (0): Sequential( (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True) (3): GELU() ) (1): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (2): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (3): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (4): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (5): Sequential( (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) (6): Sequential( (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): GELU() ) ) ) (post_extract_proj): Linear(in_features=512, out_features=768, bias=True) (dropout_input): Dropout(p=0.0, inplace=False) (dropout_features): Dropout(p=0.1, inplace=False) (encoder): TransformerEncoder( (pos_conv): Sequential( (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16) (1): SamePad() (2): GELU() ) (layers): ModuleList( (0): TransformerSentenceEncoderLayer( (self_attn): MultiheadAttention( (dropout_module): FairseqDropout() (k_proj): Linear(in_features=768, out_features=768, bias=True) (v_proj): Linear(in_features=768, out_features=768, bias=True) (q_proj): Linear(in_features=768, out_features=768, bias=True) (out_proj): Linear(in_features=768, out_features=768, bias=True) ) (dropout1): Dropout(p=0.0, inplace=False) (dropout2): Dropout(p=0.1, inplace=False) (dropout3): Dropout(p=0.0, inplace=False) (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) (fc1): Linear(in_features=768, out_features=3072, bias=True) (fc2): Linear(in_features=3072, out_features=768, bias=True) (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) ) ... ) (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) ) (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True) (final_proj): None ) (final_dropout): Dropout(p=0.0, inplace=False) (proj): Linear(in_features=768, out_features=32, bias=True) ) )   data2vec 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151  Wav2VecCtc( (w2v_encoder): Wav2VecEncoder( (w2v_model): Data2VecAudioModel( (feature_extractor): ConvFeatureExtractionModel( (conv_layers): ModuleList( (0): Sequential( (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) (1): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) (2): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) (3): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) (4): Sequential( (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) (5): Sequential( (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) (6): Sequential( (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False) (1): Dropout(p=0.0, inplace=False) (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() ) (3): GELU() ) ) ) (post_extract_proj): Linear(in_features=512, out_features=768, bias=True) (dropout_input): Dropout(p=0.0, inplace=False) (dropout_features): Dropout(p=0.0, inplace=False) (encoder): TransformerEncoder( (pos_conv): Sequential( (0): Sequential( (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16) (1): SamePad() (2): TransposeLast() (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False) (4): TransposeLast() (5): GELU() ) (1): Sequential( (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16) (1): SamePad() (2): TransposeLast() (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False) (4): TransposeLast() (5): GELU() ) (2): Sequential( (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16) (1): SamePad() (2): TransposeLast() (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False) (4): TransposeLast() (5): GELU() ) (3): Sequential( (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16) (1): SamePad() (2): TransposeLast() (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False) (4): TransposeLast() (5): GELU() ) (4): Sequential( (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16) (1): SamePad() (2): TransposeLast() (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False) (4): TransposeLast() (5): GELU() ) ) (layers): ModuleList( (0): TransformerSentenceEncoderLayer( (self_attn): MultiheadAttention( (dropout_module): FairseqDropout() (k_proj): Linear(in_features=768, out_features=768, bias=True) (v_proj): Linear(in_features=768, out_features=768, bias=True) (q_proj): Linear(in_features=768, out_features=768, bias=True) (out_proj): Linear(in_features=768, out_features=768, bias=True) ) (dropout1): Dropout(p=0.0, inplace=False) (dropout2): Dropout(p=0.1, inplace=False) (dropout3): Dropout(p=0.0, inplace=False) (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) (fc1): Linear(in_features=768, out_features=3072, bias=True) (fc2): Linear(in_features=3072, out_features=768, bias=True) (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) ) ... ) (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True) ) (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True) (final_proj): None ) (final_dropout): Dropout(p=0.0, inplace=False) (proj): Linear(in_features=768, out_features=32, bias=True) ) )   对比可以看出，wav2vec2和hubert的结构基本类似，而与data2vec则有以下区别：\n  hubert的feature extractor只有第一层有normalization，而data2vec的feature extractor每一层都有normalization，而且一个是groupnorm，一个是layernorm。\nhubert:\n1  (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)   data2vec:\n1 2 3 4 5  (2): Sequential( (0): TransposeLast() (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True) (2): TransposeLast() )   不过两者的区别应该不本质，因为wav2vec2原论文就是layernorm。\n  hubert的pos conv只有1层，而data2vec的pos conv有5层，且架构略有不同： hubert:\n1 2 3 4 5  (pos_conv): Sequential( (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16) (1): SamePad() (2): GELU() )   data2vec:\n1 2 3 4 5 6 7 8  (0): Sequential( (0): Conv1d(768, 768, kernel_size=(19,), stride=(1,), padding=(9,), groups=16) (1): SamePad() (2): TransposeLast() (3): LayerNorm((768,), eps=1e-05, elementwise_affine=False) (4): TransposeLast() (5): GELU() )   此外，论文中特别强调wav input和每一层conv的输出全是要经过normalization的。\n两者所起到的作用都是relative positional embedding。\n  config for finetune 以下均以base model为例：\n    wav2vec2 hubert data2vec     updates 80000 80000 -   lr(max) 2e-5/3e-5(librilight),1e-4(librispeech) 5e-4 -   normalization false false true    ","date":"2022-08-12T00:13:05+08:00","permalink":"https://ther-nullptr.github.io/posts/research/ssl-model-finetune/","title":"SSL model finetune"},{"content":"以下记录了superb任务中不同的downstream model：\nKS 1 2 3 4 5 6 7 8 9 10 11  DownstreamExpert( (projector): Linear(in_features=768, out_features=256, bias=True) (model): UtteranceLevel( (pooling): MeanPooling() (post_net): FrameLevel( (hiddens): Sequential() (linear): Linear(in_features=256, out_features=12, bias=True) ) ) (objective): CrossEntropyLoss() )   ASR 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  DownstreamExpert( (projector): Linear(in_features=768, out_features=1024, bias=True) (model): RNNs( (rnns): ModuleList( (0): RNNLayer( (layer): LSTM(1024, 1024, batch_first=True, bidirectional=True) (dp): Dropout(p=0.2, inplace=False) ) (1): RNNLayer( (layer): LSTM(2048, 1024, batch_first=True, bidirectional=True) (dp): Dropout(p=0.2, inplace=False) ) ) (linear): Linear(in_features=2048, out_features=32, bias=True) ) (objective): CTCLoss() )   SID 1 2 3 4 5 6 7 8 9 10 11  DownstreamExpert( (projector): Linear(in_features=768, out_features=256, bias=True) (model): UtteranceLevel( (pooling): MeanPooling() (post_net): FrameLevel( (hiddens): Sequential() (linear): Linear(in_features=256, out_features=1251, bias=True) ) ) (objective): CrossEntropyLoss() )   ","date":"2022-08-12T00:13:05+08:00","permalink":"https://ther-nullptr.github.io/posts/research/superb-downstream/","title":"SUPERB downstream"},{"content":"小黑前传的名字叫作《追忆似火年华》，不过小黑后传似乎和“似火”并不怎么沾边，索性就叫小黑后传好了，以后有想法再更新一个文艺点的标题。\n一 2022.6.19 考完试的第一天。\n“您当日的听歌时间为8h42min，位居好友榜榜首，恭喜！”\n虽然知道自己网抑云的习惯由来已久（确切地来讲，网易云和QQ音乐都听，而且QQ更多一些），但看到这个数字小黑还是震惊了一下的。其他人排解心魔的方式有社交、有读书、也有游戏，小黑则是网抑云，嗯网抑云。\n小黑的听歌方式，比较奇怪。他不怎么关注日推，也不会从500多首红心中随机抽取音乐，而是这样的：在一个特定的时间段里，他会对歌单里的5~10首歌进行单曲循环，如果在这期间搜罗到了什么好音乐，单曲循环的队列就会被更新。\n 从这个角度讲，这种听歌机制其实很像计算机里面cache的原理——平时单曲循环的歌存在cache里，适当的时候从主存里加载歌曲到cache里再单曲循环\u0026hellip;\n 从这个听歌习惯，似乎也能看到小黑的一点习惯——或者更确切的说，叫秉性——念旧、保守\u0026hellip;\u0026hellip;\n小黑摇了摇头，网抑云不是这么抑的。不过说起来，这个习惯是怎么形成的？\n二 2022.5.22 小黑居然在大二下学期中刷完了一部番，不过是老番，也比较短——《新世纪福音战士》。\n男主似乎和小黑有不少共同点——弱不禁风，胆小，喜欢边喝着酒/饮料边瘫坐着听音乐。\n这里要特别说一下“边喝着酒/饮料边瘫坐着听音乐”，小黑在看到这些镜头时，竟然前所未有地产生了共鸣感——比起那种激励人奋进的鸡汤，小黑似乎对这样的状态更加向往。\n男主有一段台词让他十分印象深刻：\n 你总是逃避自己讨厌的事情。\n我已经很努力地再试了！\n这有什么不好！\n逃避讨厌的事情又有什么不对！\n 小黑感觉自己也在逃避，逃避的是什么？也许不只是眼前的困难——就像科研进度十分缓慢，小黑第一反应想的不是调整状态，多看几篇论文和代码，而是打开手机看eva——美其名曰寻找与自己和解的路子。\n从那以后，耳机便真的成了小黑的耳旁常伴的物品了。\n小黑更想逃避的，也许是真实的自己、阴暗的自己。不过，小黑是什么时候开始思考这些问题的呢？\n三 2022.4.12 这场不大不小的折磨终于结束了。\n身体的折磨是暂时结束了。不过从那以后，小黑似乎就变了一个人——头脑中无用的精神内耗开始变多，头脑里就好像有两个不同的政党在打架，最后也给不出什么具体的执行方案来，生活就这样原地踏步地进行着。\n这造成的直接后果就是：睡眠质量严重下降，上课难以集中精神，科研开始摆烂\u0026hellip;\u0026hellip;不过有一点，小黑始终认为，自己并没有失去对学习的兴趣，只是暂时失去了自己的方向。\n说起方向，小黑有过自己真正的方向吗？从某种意义上，小黑在战略决策上似乎从来只是一株墙头草——小黑从小到大，或者更确切地说，是进了大学之后，努力的出发点就只是“我想成为xxx那样的人”——A的笔记，B的钻研，C的个人魅力\u0026hellip;\u0026hellip;这本是一件好事，但小黑发现自己似乎哪一个人都变不成，而当别人告诉自己要“做自己”时，小黑甚至连“自我”的定义都难以下达——自己追寻了太多别人的足迹，却连自己本来的样子都忘记了。\n那么，自己到底想成为什么样的人？这要从一次谈话说起。\n四 2022.1.18 在入学前，小黑给自己的label是：社恐分子、小镇做题家、局外人。\n一年半后，小黑给自己的label是：孤勇者、想要成为文艺青年的理工男、安静、内向，自己将会在学习和科研的路上一路狂奔。\n但，果真如此吗？\n我与老友聊起了关于自身的定位问题，老友说：其实你一直是一个很有人情味的人，并列举种种事例。\n这时小黑才意识到，自己的内心中，本质上有很多感性的成分。自己也渴望社交、渴望沟通、渴望人与人之间微妙的联结——而不是仅仅一味扎进学术中。\n \u0026ldquo;人有种奇怪的虚荣心，想让别人或自己相信他向往的是真理，但其实他有求于这个世界的是爱。\u0026ldquo;加缪一语道破天机。\n 自己的一些label，似乎硬生生束缚住了自己的手脚。本我，似乎与展现在世人面前的我，以及小黑所期望的我，出现了前所未有的参差。它们相互交织，却又在触及人心最柔软的部分互斥。\n小黑原本以为自己的这些label大概是在高中时期形成的。但另一位老友给了他一个惊人的答案：\n 小学。\n 五 2022.8.4 递归似地分析完了所有问题，接下来要做的，就是要把所有问题层层出栈。只是，这样的思索是存在精确解的吗？如果没有，那这样的思索是无谓的吗？正如小黑不顾繁重的任务和压力，在深夜敲下废话连篇的意识流文章一样，此举意义何在？\n什么才能治好小黑的精神内耗？这个学期的经历似乎告诉小黑：不是忙碌，更不是让自己的身心投入到学习和工作中。\n那是什么？也许是慢慢地与留下太多遗憾地自己和解。但和解的过程，又何尝不是一个精神内耗的过程。\n小黑似乎又一次掉入了无限的递归之中。\n","date":"2022-08-04T01:09:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E5%B0%8F%E9%BB%91%E5%90%8E%E4%BC%A0/","title":"小黑后传"},{"content":" “我们前后找了几十年以来的毕业生，在十六万人中分析了五百人，得到了结论。结果发现很多结果出乎清华校方的意料。 比如，我们分析了成绩因素，按理说成绩好应该更成功吧？但结果是，成绩对以后的发展并没有影响，就是说，成绩好并不代表发展好，当然也不可能发展差对吧。这是很出乎校方意料的一点。 那社工呢？大家都认为如果做了什么学生会主席、社会工作可能对未来发展有所帮助，结果还是没有关系。没有关系意思是有没有这些优势都不影响以后发展。 那么家庭影响应该足够重要了吧，比如有的家长眼界很高，有先进的观念，培养孩子很有方法，这是个影响因素吗？不是。 地域呢？比如有的同学来自偏远地区，有的在大城市，这是影响因素吗？不是。这些都不是，那我们发现了什么呢？ 我们在二十多个因素里，唯一发现很多人都具有的一个共同点就是，他们都很早地开始思考自己的未来并且着手做准备。\n ","date":"2022-07-28T02:11:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/review/","title":"试错，还是错逝？"},{"content":"“失去的二十周” 2022.1.21  “泡沫的顶峰”\n 2022.3.1  “出校理由：北医三院” “原因玄学，大学生，压力大，作息不规律，有心理因素，正常”\n 2022.3.8  “这就是世一大的教学水平吗” 自己的“看家本领”到底是什么？？\n 2022.4.10  第一次大寄\n 2022.4.17  “所以，你们到底做了些什么？”\n 2022.4.23  “搞了半天，还是咱不够卷\u0026hellip;”\n 2022.4.26  第二次大寄 “一段噩梦的结束” “人是会在同一个地方摔两次跟头的”\n 2022.4.28  “今后还会像这般心想事成吗？”\n 2022.4.30  “至少到现在这个阶段我觉得，我看到一个很强的人时，我会这样想：‘我虽然崇拜他，但我并不会说去完全变成他的样子，而只是在想怎么做好自己’” “很遗憾，我目前还做不到这一点”\n 2022.5.2  “残酷な天使のように，少年よ神话になれ！”\n 2022.5.3  一个并不光彩的W\n 2022.5.4  “突然感觉，你清学子要花费很多时间在‘与自己和解’上”\n 2022.5.17  “大家并不是真的有多反感封校和防疫，他们只是想借此机会抒发各自心中的不快罢了”\n 2022.5.23  “千载难逢的机会，你不用吗？” “算了，我怕有后续影响”\n 2022.6.8  “好多人都在讲好大学平台有多好，但是鄙人感觉这个平台并不属于只会埋头干活的人。。”\n 2022.6.12  “有时候选择比努力更重要，以后在社会上更是这样，这也许是这魔幻的一学期带给我们的启示吧”\n 2022.6.14  C楼3层，一个全新的世界\n 2022.6.20  “在一个弱一点的985如果能一开始处于前列，那么你的学习动能是强于在清北挣扎的，是一个向上走的趋势，而且会进入大佬圈子，拿到本校顶尖的资源和信息共享；而清北学渣什么都没有，四年一直走下坡路。这一上一下差距会拉得很大。”\n 2022.6.25  “这他妈就是一个强者恒强的过程。。。”\n So where is the way? ","date":"2022-07-27T23:59:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E6%97%A5%E5%AF%84/","title":"日寄"},{"content":"为了便于一一对应与查找，在此处我们列出了CoFi-BERT中所有的key和Hubert中所有的key：\nCoFi 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207  bert.embeddings.word_embeddings.weight 23440896 bert.embeddings.position_embeddings.weight 393216 bert.embeddings.token_type_embeddings.weight 1536 bert.embeddings.LayerNorm.gamma 768 bert.embeddings.LayerNorm.beta 768 bert.encoder.layer.0.attention.self.query.weight 589824 bert.encoder.layer.0.attention.self.query.bias 768 bert.encoder.layer.0.attention.self.key.weight 589824 bert.encoder.layer.0.attention.self.key.bias 768 bert.encoder.layer.0.attention.self.value.weight 589824 bert.encoder.layer.0.attention.self.value.bias 768 bert.encoder.layer.0.attention.output.dense.weight 589824 bert.encoder.layer.0.attention.output.dense.bias 768 bert.encoder.layer.0.attention.output.LayerNorm.gamma 768 bert.encoder.layer.0.attention.output.LayerNorm.beta 768 bert.encoder.layer.0.intermediate.dense.weight 2359296 bert.encoder.layer.0.intermediate.dense.bias 3072 bert.encoder.layer.0.output.dense.weight 2359296 bert.encoder.layer.0.output.dense.bias 768 bert.encoder.layer.0.output.LayerNorm.gamma 768 bert.encoder.layer.0.output.LayerNorm.beta 768 bert.encoder.layer.1.attention.self.query.weight 589824 bert.encoder.layer.1.attention.self.query.bias 768 bert.encoder.layer.1.attention.self.key.weight 589824 bert.encoder.layer.1.attention.self.key.bias 768 bert.encoder.layer.1.attention.self.value.weight 589824 bert.encoder.layer.1.attention.self.value.bias 768 bert.encoder.layer.1.attention.output.dense.weight 589824 bert.encoder.layer.1.attention.output.dense.bias 768 bert.encoder.layer.1.attention.output.LayerNorm.gamma 768 bert.encoder.layer.1.attention.output.LayerNorm.beta 768 bert.encoder.layer.1.intermediate.dense.weight 2359296 bert.encoder.layer.1.intermediate.dense.bias 3072 bert.encoder.layer.1.output.dense.weight 2359296 bert.encoder.layer.1.output.dense.bias 768 bert.encoder.layer.1.output.LayerNorm.gamma 768 bert.encoder.layer.1.output.LayerNorm.beta 768 bert.encoder.layer.2.attention.self.query.weight 589824 bert.encoder.layer.2.attention.self.query.bias 768 bert.encoder.layer.2.attention.self.key.weight 589824 bert.encoder.layer.2.attention.self.key.bias 768 bert.encoder.layer.2.attention.self.value.weight 589824 bert.encoder.layer.2.attention.self.value.bias 768 bert.encoder.layer.2.attention.output.dense.weight 589824 bert.encoder.layer.2.attention.output.dense.bias 768 bert.encoder.layer.2.attention.output.LayerNorm.gamma 768 bert.encoder.layer.2.attention.output.LayerNorm.beta 768 bert.encoder.layer.2.intermediate.dense.weight 2359296 bert.encoder.layer.2.intermediate.dense.bias 3072 bert.encoder.layer.2.output.dense.weight 2359296 bert.encoder.layer.2.output.dense.bias 768 bert.encoder.layer.2.output.LayerNorm.gamma 768 bert.encoder.layer.2.output.LayerNorm.beta 768 bert.encoder.layer.3.attention.self.query.weight 589824 bert.encoder.layer.3.attention.self.query.bias 768 bert.encoder.layer.3.attention.self.key.weight 589824 bert.encoder.layer.3.attention.self.key.bias 768 bert.encoder.layer.3.attention.self.value.weight 589824 bert.encoder.layer.3.attention.self.value.bias 768 bert.encoder.layer.3.attention.output.dense.weight 589824 bert.encoder.layer.3.attention.output.dense.bias 768 bert.encoder.layer.3.attention.output.LayerNorm.gamma 768 bert.encoder.layer.3.attention.output.LayerNorm.beta 768 bert.encoder.layer.3.intermediate.dense.weight 2359296 bert.encoder.layer.3.intermediate.dense.bias 3072 bert.encoder.layer.3.output.dense.weight 2359296 bert.encoder.layer.3.output.dense.bias 768 bert.encoder.layer.3.output.LayerNorm.gamma 768 bert.encoder.layer.3.output.LayerNorm.beta 768 bert.encoder.layer.4.attention.self.query.weight 589824 bert.encoder.layer.4.attention.self.query.bias 768 bert.encoder.layer.4.attention.self.key.weight 589824 bert.encoder.layer.4.attention.self.key.bias 768 bert.encoder.layer.4.attention.self.value.weight 589824 bert.encoder.layer.4.attention.self.value.bias 768 bert.encoder.layer.4.attention.output.dense.weight 589824 bert.encoder.layer.4.attention.output.dense.bias 768 bert.encoder.layer.4.attention.output.LayerNorm.gamma 768 bert.encoder.layer.4.attention.output.LayerNorm.beta 768 bert.encoder.layer.4.intermediate.dense.weight 2359296 bert.encoder.layer.4.intermediate.dense.bias 3072 bert.encoder.layer.4.output.dense.weight 2359296 bert.encoder.layer.4.output.dense.bias 768 bert.encoder.layer.4.output.LayerNorm.gamma 768 bert.encoder.layer.4.output.LayerNorm.beta 768 bert.encoder.layer.5.attention.self.query.weight 589824 bert.encoder.layer.5.attention.self.query.bias 768 bert.encoder.layer.5.attention.self.key.weight 589824 bert.encoder.layer.5.attention.self.key.bias 768 bert.encoder.layer.5.attention.self.value.weight 589824 bert.encoder.layer.5.attention.self.value.bias 768 bert.encoder.layer.5.attention.output.dense.weight 589824 bert.encoder.layer.5.attention.output.dense.bias 768 bert.encoder.layer.5.attention.output.LayerNorm.gamma 768 bert.encoder.layer.5.attention.output.LayerNorm.beta 768 bert.encoder.layer.5.intermediate.dense.weight 2359296 bert.encoder.layer.5.intermediate.dense.bias 3072 bert.encoder.layer.5.output.dense.weight 2359296 bert.encoder.layer.5.output.dense.bias 768 bert.encoder.layer.5.output.LayerNorm.gamma 768 bert.encoder.layer.5.output.LayerNorm.beta 768 bert.encoder.layer.6.attention.self.query.weight 589824 bert.encoder.layer.6.attention.self.query.bias 768 bert.encoder.layer.6.attention.self.key.weight 589824 bert.encoder.layer.6.attention.self.key.bias 768 bert.encoder.layer.6.attention.self.value.weight 589824 bert.encoder.layer.6.attention.self.value.bias 768 bert.encoder.layer.6.attention.output.dense.weight 589824 bert.encoder.layer.6.attention.output.dense.bias 768 bert.encoder.layer.6.attention.output.LayerNorm.gamma 768 bert.encoder.layer.6.attention.output.LayerNorm.beta 768 bert.encoder.layer.6.intermediate.dense.weight 2359296 bert.encoder.layer.6.intermediate.dense.bias 3072 bert.encoder.layer.6.output.dense.weight 2359296 bert.encoder.layer.6.output.dense.bias 768 bert.encoder.layer.6.output.LayerNorm.gamma 768 bert.encoder.layer.6.output.LayerNorm.beta 768 bert.encoder.layer.7.attention.self.query.weight 589824 bert.encoder.layer.7.attention.self.query.bias 768 bert.encoder.layer.7.attention.self.key.weight 589824 bert.encoder.layer.7.attention.self.key.bias 768 bert.encoder.layer.7.attention.self.value.weight 589824 bert.encoder.layer.7.attention.self.value.bias 768 bert.encoder.layer.7.attention.output.dense.weight 589824 bert.encoder.layer.7.attention.output.dense.bias 768 bert.encoder.layer.7.attention.output.LayerNorm.gamma 768 bert.encoder.layer.7.attention.output.LayerNorm.beta 768 bert.encoder.layer.7.intermediate.dense.weight 2359296 bert.encoder.layer.7.intermediate.dense.bias 3072 bert.encoder.layer.7.output.dense.weight 2359296 bert.encoder.layer.7.output.dense.bias 768 bert.encoder.layer.7.output.LayerNorm.gamma 768 bert.encoder.layer.7.output.LayerNorm.beta 768 bert.encoder.layer.8.attention.self.query.weight 589824 bert.encoder.layer.8.attention.self.query.bias 768 bert.encoder.layer.8.attention.self.key.weight 589824 bert.encoder.layer.8.attention.self.key.bias 768 bert.encoder.layer.8.attention.self.value.weight 589824 bert.encoder.layer.8.attention.self.value.bias 768 bert.encoder.layer.8.attention.output.dense.weight 589824 bert.encoder.layer.8.attention.output.dense.bias 768 bert.encoder.layer.8.attention.output.LayerNorm.gamma 768 bert.encoder.layer.8.attention.output.LayerNorm.beta 768 bert.encoder.layer.8.intermediate.dense.weight 2359296 bert.encoder.layer.8.intermediate.dense.bias 3072 bert.encoder.layer.8.output.dense.weight 2359296 bert.encoder.layer.8.output.dense.bias 768 bert.encoder.layer.8.output.LayerNorm.gamma 768 bert.encoder.layer.8.output.LayerNorm.beta 768 bert.encoder.layer.9.attention.self.query.weight 589824 bert.encoder.layer.9.attention.self.query.bias 768 bert.encoder.layer.9.attention.self.key.weight 589824 bert.encoder.layer.9.attention.self.key.bias 768 bert.encoder.layer.9.attention.self.value.weight 589824 bert.encoder.layer.9.attention.self.value.bias 768 bert.encoder.layer.9.attention.output.dense.weight 589824 bert.encoder.layer.9.attention.output.dense.bias 768 bert.encoder.layer.9.attention.output.LayerNorm.gamma 768 bert.encoder.layer.9.attention.output.LayerNorm.beta 768 bert.encoder.layer.9.intermediate.dense.weight 2359296 bert.encoder.layer.9.intermediate.dense.bias 3072 bert.encoder.layer.9.output.dense.weight 2359296 bert.encoder.layer.9.output.dense.bias 768 bert.encoder.layer.9.output.LayerNorm.gamma 768 bert.encoder.layer.9.output.LayerNorm.beta 768 bert.encoder.layer.10.attention.self.query.weight 589824 bert.encoder.layer.10.attention.self.query.bias 768 bert.encoder.layer.10.attention.self.key.weight 589824 bert.encoder.layer.10.attention.self.key.bias 768 bert.encoder.layer.10.attention.self.value.weight 589824 bert.encoder.layer.10.attention.self.value.bias 768 bert.encoder.layer.10.attention.output.dense.weight 589824 bert.encoder.layer.10.attention.output.dense.bias 768 bert.encoder.layer.10.attention.output.LayerNorm.gamma 768 bert.encoder.layer.10.attention.output.LayerNorm.beta 768 bert.encoder.layer.10.intermediate.dense.weight 2359296 bert.encoder.layer.10.intermediate.dense.bias 3072 bert.encoder.layer.10.output.dense.weight 2359296 bert.encoder.layer.10.output.dense.bias 768 bert.encoder.layer.10.output.LayerNorm.gamma 768 bert.encoder.layer.10.output.LayerNorm.beta 768 bert.encoder.layer.11.attention.self.query.weight 589824 bert.encoder.layer.11.attention.self.query.bias 768 bert.encoder.layer.11.attention.self.key.weight 589824 bert.encoder.layer.11.attention.self.key.bias 768 bert.encoder.layer.11.attention.self.value.weight 589824 bert.encoder.layer.11.attention.self.value.bias 768 bert.encoder.layer.11.attention.output.dense.weight 589824 bert.encoder.layer.11.attention.output.dense.bias 768 bert.encoder.layer.11.attention.output.LayerNorm.gamma 768 bert.encoder.layer.11.attention.output.LayerNorm.beta 768 bert.encoder.layer.11.intermediate.dense.weight 2359296 bert.encoder.layer.11.intermediate.dense.bias 3072 bert.encoder.layer.11.output.dense.weight 2359296 bert.encoder.layer.11.output.dense.bias 768 bert.encoder.layer.11.output.LayerNorm.gamma 768 bert.encoder.layer.11.output.LayerNorm.beta 768 bert.pooler.dense.weight 589824 bert.pooler.dense.bias 768 cls.predictions.bias 30522 cls.predictions.transform.dense.weight 589824 cls.predictions.transform.dense.bias 768 cls.predictions.transform.LayerNorm.gamma 768 cls.predictions.transform.LayerNorm.beta 768 cls.predictions.decoder.weight 23440896 cls.seq_relationship.weight 1536 cls.seq_relationship.bias 2   Hubert 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214  mask_emb 768 feature_extractor.conv_layers.0.0.weight 5120 feature_extractor.conv_layers.0.2.weight 512 feature_extractor.conv_layers.0.2.bias 512 feature_extractor.conv_layers.1.0.weight 786432 feature_extractor.conv_layers.2.0.weight 786432 feature_extractor.conv_layers.3.0.weight 786432 feature_extractor.conv_layers.4.0.weight 786432 feature_extractor.conv_layers.5.0.weight 524288 feature_extractor.conv_layers.6.0.weight 524288 post_extract_proj.weight 393216 post_extract_proj.bias 768 encoder.pos_conv.0.bias 768 encoder.pos_conv.0.weight_g 128 encoder.pos_conv.0.weight_v 4718592 encoder.layers.0.self_attn.k_proj.weight 589824 encoder.layers.0.self_attn.k_proj.bias 768 encoder.layers.0.self_attn.v_proj.weight 589824 encoder.layers.0.self_attn.v_proj.bias 768 encoder.layers.0.self_attn.q_proj.weight 589824 encoder.layers.0.self_attn.q_proj.bias 768 encoder.layers.0.self_attn.out_proj.weight 589824 encoder.layers.0.self_attn.out_proj.bias 768 encoder.layers.0.self_attn_layer_norm.weight 768 encoder.layers.0.self_attn_layer_norm.bias 768 encoder.layers.0.fc1.weight 2359296 encoder.layers.0.fc1.bias 3072 encoder.layers.0.fc2.weight 2359296 encoder.layers.0.fc2.bias 768 encoder.layers.0.final_layer_norm.weight 768 encoder.layers.0.final_layer_norm.bias 768 encoder.layers.1.self_attn.k_proj.weight 589824 encoder.layers.1.self_attn.k_proj.bias 768 encoder.layers.1.self_attn.v_proj.weight 589824 encoder.layers.1.self_attn.v_proj.bias 768 encoder.layers.1.self_attn.q_proj.weight 589824 encoder.layers.1.self_attn.q_proj.bias 768 encoder.layers.1.self_attn.out_proj.weight 589824 encoder.layers.1.self_attn.out_proj.bias 768 encoder.layers.1.self_attn_layer_norm.weight 768 encoder.layers.1.self_attn_layer_norm.bias 768 encoder.layers.1.fc1.weight 2359296 encoder.layers.1.fc1.bias 3072 encoder.layers.1.fc2.weight 2359296 encoder.layers.1.fc2.bias 768 encoder.layers.1.final_layer_norm.weight 768 encoder.layers.1.final_layer_norm.bias 768 encoder.layers.2.self_attn.k_proj.weight 589824 encoder.layers.2.self_attn.k_proj.bias 768 encoder.layers.2.self_attn.v_proj.weight 589824 encoder.layers.2.self_attn.v_proj.bias 768 encoder.layers.2.self_attn.q_proj.weight 589824 encoder.layers.2.self_attn.q_proj.bias 768 encoder.layers.2.self_attn.out_proj.weight 589824 encoder.layers.2.self_attn.out_proj.bias 768 encoder.layers.2.self_attn_layer_norm.weight 768 encoder.layers.2.self_attn_layer_norm.bias 768 encoder.layers.2.fc1.weight 2359296 encoder.layers.2.fc1.bias 3072 encoder.layers.2.fc2.weight 2359296 encoder.layers.2.fc2.bias 768 encoder.layers.2.final_layer_norm.weight 768 encoder.layers.2.final_layer_norm.bias 768 encoder.layers.3.self_attn.k_proj.weight 589824 encoder.layers.3.self_attn.k_proj.bias 768 encoder.layers.3.self_attn.v_proj.weight 589824 encoder.layers.3.self_attn.v_proj.bias 768 encoder.layers.3.self_attn.q_proj.weight 589824 encoder.layers.3.self_attn.q_proj.bias 768 encoder.layers.3.self_attn.out_proj.weight 589824 encoder.layers.3.self_attn.out_proj.bias 768 encoder.layers.3.self_attn_layer_norm.weight 768 encoder.layers.3.self_attn_layer_norm.bias 768 encoder.layers.3.fc1.weight 2359296 encoder.layers.3.fc1.bias 3072 encoder.layers.3.fc2.weight 2359296 encoder.layers.3.fc2.bias 768 encoder.layers.3.final_layer_norm.weight 768 encoder.layers.3.final_layer_norm.bias 768 encoder.layers.4.self_attn.k_proj.weight 589824 encoder.layers.4.self_attn.k_proj.bias 768 encoder.layers.4.self_attn.v_proj.weight 589824 encoder.layers.4.self_attn.v_proj.bias 768 encoder.layers.4.self_attn.q_proj.weight 589824 encoder.layers.4.self_attn.q_proj.bias 768 encoder.layers.4.self_attn.out_proj.weight 589824 encoder.layers.4.self_attn.out_proj.bias 768 encoder.layers.4.self_attn_layer_norm.weight 768 encoder.layers.4.self_attn_layer_norm.bias 768 encoder.layers.4.fc1.weight 2359296 encoder.layers.4.fc1.bias 3072 encoder.layers.4.fc2.weight 2359296 encoder.layers.4.fc2.bias 768 encoder.layers.4.final_layer_norm.weight 768 encoder.layers.4.final_layer_norm.bias 768 encoder.layers.5.self_attn.k_proj.weight 589824 encoder.layers.5.self_attn.k_proj.bias 768 encoder.layers.5.self_attn.v_proj.weight 589824 encoder.layers.5.self_attn.v_proj.bias 768 encoder.layers.5.self_attn.q_proj.weight 589824 encoder.layers.5.self_attn.q_proj.bias 768 encoder.layers.5.self_attn.out_proj.weight 589824 encoder.layers.5.self_attn.out_proj.bias 768 encoder.layers.5.self_attn_layer_norm.weight 768 encoder.layers.5.self_attn_layer_norm.bias 768 encoder.layers.5.fc1.weight 2359296 encoder.layers.5.fc1.bias 3072 encoder.layers.5.fc2.weight 2359296 encoder.layers.5.fc2.bias 768 encoder.layers.5.final_layer_norm.weight 768 encoder.layers.5.final_layer_norm.bias 768 encoder.layers.6.self_attn.k_proj.weight 589824 encoder.layers.6.self_attn.k_proj.bias 768 encoder.layers.6.self_attn.v_proj.weight 589824 encoder.layers.6.self_attn.v_proj.bias 768 encoder.layers.6.self_attn.q_proj.weight 589824 encoder.layers.6.self_attn.q_proj.bias 768 encoder.layers.6.self_attn.out_proj.weight 589824 encoder.layers.6.self_attn.out_proj.bias 768 encoder.layers.6.self_attn_layer_norm.weight 768 encoder.layers.6.self_attn_layer_norm.bias 768 encoder.layers.6.fc1.weight 2359296 encoder.layers.6.fc1.bias 3072 encoder.layers.6.fc2.weight 2359296 encoder.layers.6.fc2.bias 768 encoder.layers.6.final_layer_norm.weight 768 encoder.layers.6.final_layer_norm.bias 768 encoder.layers.7.self_attn.k_proj.weight 589824 encoder.layers.7.self_attn.k_proj.bias 768 encoder.layers.7.self_attn.v_proj.weight 589824 encoder.layers.7.self_attn.v_proj.bias 768 encoder.layers.7.self_attn.q_proj.weight 589824 encoder.layers.7.self_attn.q_proj.bias 768 encoder.layers.7.self_attn.out_proj.weight 589824 encoder.layers.7.self_attn.out_proj.bias 768 encoder.layers.7.self_attn_layer_norm.weight 768 encoder.layers.7.self_attn_layer_norm.bias 768 encoder.layers.7.fc1.weight 2359296 encoder.layers.7.fc1.bias 3072 encoder.layers.7.fc2.weight 2359296 encoder.layers.7.fc2.bias 768 encoder.layers.7.final_layer_norm.weight 768 encoder.layers.7.final_layer_norm.bias 768 encoder.layers.8.self_attn.k_proj.weight 589824 encoder.layers.8.self_attn.k_proj.bias 768 encoder.layers.8.self_attn.v_proj.weight 589824 encoder.layers.8.self_attn.v_proj.bias 768 encoder.layers.8.self_attn.q_proj.weight 589824 encoder.layers.8.self_attn.q_proj.bias 768 encoder.layers.8.self_attn.out_proj.weight 589824 encoder.layers.8.self_attn.out_proj.bias 768 encoder.layers.8.self_attn_layer_norm.weight 768 encoder.layers.8.self_attn_layer_norm.bias 768 encoder.layers.8.fc1.weight 2359296 encoder.layers.8.fc1.bias 3072 encoder.layers.8.fc2.weight 2359296 encoder.layers.8.fc2.bias 768 encoder.layers.8.final_layer_norm.weight 768 encoder.layers.8.final_layer_norm.bias 768 encoder.layers.9.self_attn.k_proj.weight 589824 encoder.layers.9.self_attn.k_proj.bias 768 encoder.layers.9.self_attn.v_proj.weight 589824 encoder.layers.9.self_attn.v_proj.bias 768 encoder.layers.9.self_attn.q_proj.weight 589824 encoder.layers.9.self_attn.q_proj.bias 768 encoder.layers.9.self_attn.out_proj.weight 589824 encoder.layers.9.self_attn.out_proj.bias 768 encoder.layers.9.self_attn_layer_norm.weight 768 encoder.layers.9.self_attn_layer_norm.bias 768 encoder.layers.9.fc1.weight 2359296 encoder.layers.9.fc1.bias 3072 encoder.layers.9.fc2.weight 2359296 encoder.layers.9.fc2.bias 768 encoder.layers.9.final_layer_norm.weight 768 encoder.layers.9.final_layer_norm.bias 768 encoder.layers.10.self_attn.k_proj.weight 589824 encoder.layers.10.self_attn.k_proj.bias 768 encoder.layers.10.self_attn.v_proj.weight 589824 encoder.layers.10.self_attn.v_proj.bias 768 encoder.layers.10.self_attn.q_proj.weight 589824 encoder.layers.10.self_attn.q_proj.bias 768 encoder.layers.10.self_attn.out_proj.weight 589824 encoder.layers.10.self_attn.out_proj.bias 768 encoder.layers.10.self_attn_layer_norm.weight 768 encoder.layers.10.self_attn_layer_norm.bias 768 encoder.layers.10.fc1.weight 2359296 encoder.layers.10.fc1.bias 3072 encoder.layers.10.fc2.weight 2359296 encoder.layers.10.fc2.bias 768 encoder.layers.10.final_layer_norm.weight 768 encoder.layers.10.final_layer_norm.bias 768 encoder.layers.11.self_attn.k_proj.weight 589824 encoder.layers.11.self_attn.k_proj.bias 768 encoder.layers.11.self_attn.v_proj.weight 589824 encoder.layers.11.self_attn.v_proj.bias 768 encoder.layers.11.self_attn.q_proj.weight 589824 encoder.layers.11.self_attn.q_proj.bias 768 encoder.layers.11.self_attn.out_proj.weight 589824 encoder.layers.11.self_attn.out_proj.bias 768 encoder.layers.11.self_attn_layer_norm.weight 768 encoder.layers.11.self_attn_layer_norm.bias 768 encoder.layers.11.fc1.weight 2359296 encoder.layers.11.fc1.bias 3072 encoder.layers.11.fc2.weight 2359296 encoder.layers.11.fc2.bias 768 encoder.layers.11.final_layer_norm.weight 768 encoder.layers.11.final_layer_norm.bias 768 encoder.layer_norm.weight 768 encoder.layer_norm.bias 768 layer_norm.weight 512 layer_norm.bias 512 final_proj.weight 196608 final_proj.bias 256 label_embs_concat 129024   CoFi after distill 在此处我们直观展示了distill之后的CoFi的结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96  Layer 0, heads 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer 1, heads 4 5 6 7 8 9 10 11 pruned. Layer 2, heads 2 3 4 5 6 7 8 9 10 11 pruned. Layer 3, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer 4, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer 5, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer 6, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer 7, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer 8, heads 2 3 4 5 6 7 8 9 10 11 pruned. Layer 9, heads 3 4 5 6 7 8 9 10 11 pruned. Layer 10, heads 2 3 4 5 6 7 8 9 10 11 pruned. Layer 11, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned. Layer: 0 query: torch.Size([64, 764]) key: torch.Size([64, 764]) value: torch.Size([64, 764]) output: torch.Size([764, 64]) up: torch.Size([395, 764]) down: torch.Size([764, 395]) Layer: 1 query: torch.Size([256, 764]) key: torch.Size([256, 764]) value: torch.Size([256, 764]) output: torch.Size([764, 256]) up: torch.Size([353, 764]) down: torch.Size([764, 353]) Layer: 2 query: torch.Size([128, 764]) key: torch.Size([128, 764]) value: torch.Size([128, 764]) output: torch.Size([764, 128]) up None down None Layer: 3 query: None key: None value: None output: None up None down None Layer: 4 query: None key: None value: None output: None up None down None Layer: 5 query: None key: None value: None output: None up None down None Layer: 6 query: None key: None value: None output: None up None down None Layer: 7 query: None key: None value: None output: None up None down None Layer: 8 query: torch.Size([128, 764]) key: torch.Size([128, 764]) value: torch.Size([128, 764]) output: torch.Size([764, 128]) up: torch.Size([263, 764]) down: torch.Size([764, 263]) Layer: 9 query: torch.Size([192, 764]) key: torch.Size([192, 764]) value: torch.Size([192, 764]) output: torch.Size([764, 192]) up None down None Layer: 10 query: torch.Size([128, 764]) key: torch.Size([128, 764]) value: torch.Size([128, 764]) output: torch.Size([764, 128]) up None down None Layer: 11 query: None key: None value: None output: None up None down None   ","date":"2022-07-18T00:13:05+08:00","permalink":"https://ther-nullptr.github.io/posts/research/cofi-model-and-hubert-model-keys/","title":"CoFi model \u0026 Hubert model keys"},{"content":"本文旨在列出fairseq中一些常见的自定义函数：\nvirtual functions task setup  setup_task  builders  build_model build_dictionary build_dictionary build_generator(usually useless)  loaders  load_dictionary load_datasets  steps   train_step\n1 2 3 4 5 6 7 8 9 10 11  def train_step(self, sample, model, criterion, optimizer, update_num, ignore_grad=False): model.train() model.set_num_updates(update_num) with torch.autograd.profiler.record_function(\u0026#34;forward\u0026#34;): with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))): loss, sample_size, logging_output = criterion(model, sample) if ignore_grad: loss *= 0 with torch.autograd.profiler.record_function(\u0026#34;backward\u0026#34;): optimizer.backward(loss) return loss, sample_size, logging_output     valid_step\n1 2 3 4 5  def valid_step(self, sample, model, criterion): model.eval() with torch.no_grad(): loss, sample_size, logging_output = criterion(model, sample) return loss, sample_size, logging_output     optimizer_step\n1 2  def optimizer_step(self, optimizer, model, update_num): optimizer.step()     inference_step\n1 2 3 4 5 6 7  def inference_step( self, generator, models, sample, prefix_tokens=None, constraints=None ): with torch.no_grad(): return generator.generate( models, sample, prefix_tokens=prefix_tokens, constraints=constraints )     hook functions  begin_epoch begin_validation_epoch  model   build_model\n除此之外，基本都需要自定义函数。\n  forward\n  criterion   build_criterion\n除此之外，基本都需要自定义函数。\n  forward\n  optimizers fairseq中的optimizer是如何工作的？我们首先需要看一下pytorch API中默认的optimizer：\n1 2  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) optimizer = optim.Adam([var1, var2], lr=0.0001)   对于模型参数中不同的部分，我们也可以使用不同的优化策略：\n1 2 3 4  optim.SGD([ {\u0026#39;params\u0026#39;: model.base.parameters()}, {\u0026#39;params\u0026#39;: model.classifier.parameters(), \u0026#39;lr\u0026#39;: 1e-3} ], lr=1e-2, momentum=0.9)   我们再看看fairseq中的optimizer：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  @register_optimizer(\u0026#34;adam\u0026#34;, dataclass=FairseqAdamConfig) class FairseqAdam(FairseqOptimizer): def __init__(self, cfg: FairseqAdamConfig, params): super().__init__(cfg) fused_adam_cls = get_fused_adam_class() use_fused_adam = ( not getattr(cfg, \u0026#34;use_old_adam\u0026#34;, False) and fused_adam_cls is not None and torch.cuda.is_available() ) if getattr(cfg, \u0026#34;tpu\u0026#34;, False): if self.cfg.fp16_adam_stats: raise NotImplementedError(\u0026#34;--fp16-adam-stats is only supported on GPU\u0026#34;) # on TPUs we use the Adam defined here, since it # automatically casts gradients to FP32 self._optimizer = Adam(params, **self.optimizer_config) elif use_fused_adam: logger.info(\u0026#34;using FusedAdam\u0026#34;) self._optimizer = fused_adam_cls( params, use_fp16_stats=self.cfg.fp16_adam_stats, **self.optimizer_config ) else: if self.cfg.fp16_adam_stats: raise NotImplementedError( \u0026#34;--fp16-adam-stats is only supported with FusedAdamV1\u0026#34; ) self._optimizer = Adam(params, **self.optimizer_config)   fairseq的optimizer在传入参数时需要将model的params进行传入。那么这个传入的过程在哪里呢？在train_step中，需要传入所有的主要模块：\n1 2 3 4 5 6 7 8 9 10 11 12 13  def train_step( self, sample, model, criterion, optimizer, update_num, ignore_grad=False ): model.train() model.set_num_updates(update_num) with torch.autograd.profiler.record_function(\u0026#34;forward\u0026#34;): with torch.cuda.amp.autocast(enabled=(isinstance(optimizer, AMPOptimizer))): loss, sample_size, logging_output = criterion(model, sample) if ignore_grad: loss *= 0 with torch.autograd.profiler.record_function(\u0026#34;backward\u0026#34;): optimizer.backward(loss) return loss, sample_size, logging_output   值得注意的是，在fairseq中，反向传播的过程是这么写的（见fairseq_task.py）：\n1  optimizer.backward(loss)   其内部原理如下：\n1 2 3  def backward(self, loss): \u0026#34;\u0026#34;\u0026#34;Computes the sum of gradients of the given tensor w.r.t. graph leaves.\u0026#34;\u0026#34;\u0026#34; loss.backward()   那么何时执行optimizer.step()操作呢？在fairseq_task.py中：\n1 2  def optimizer_step(self, optimizer, model, update_num): optimizer.step()   然后在trainer.py中调用这个函数：\n1 2 3 4 5  with torch.autograd.profiler.record_function(\u0026#34;optimizer\u0026#34;): # take an optimization step self.task.optimizer_step( self.optimizer, model=self.model, update_num=self.get_num_updates() )   而在常规的pytorch程序中，反向传播过程是这么写的，可见有很大的不同：\n1 2  loss.backward() optimizer.step()   ","date":"2022-07-18T00:13:05+08:00","permalink":"https://ther-nullptr.github.io/posts/research/fairseq-functions/","title":"fairseq functions"},{"content":"Makefile \u0026amp; CMake 想象一下我们有如下C++程序hello.cpp：\n1 2 3 4 5  #include \u0026lt;iostream\u0026gt;int main() { std::cout \u0026lt;\u0026lt; \u0026#34;hello world!\u0026#34; \u0026lt;\u0026lt; std::endl; }   我们需要在终端输入以下指令：\n1  $ g++ hello.cpp -o hello   这时我们就可以生成可执行文件hello。但在实际应用场景中，我们可能会面临如下问题：\n 项目中的.h文件和.cpp文件十分繁多。 各.h文件、.cpp文件的依赖关系十分复杂。 多文件可能会出现重复编译的情况，拖慢编译速度。 \u0026hellip;  为了解决这些问题，makefile和CMake应运而生。\n本讲需要使用到的工具：g++，make，cmake。可以通过以下方式安装：\n1  $ sudo apt-get install g++ make cmake   Makefile makefile文件描述了C/C++工程的编译规则，可以用来指明源文件的编译顺序、依赖关系、是否需要重新编译等，自动化编译C/C++项目（实际上也不止局限于C/C++项目）。\n我们可以考虑以下实例：\n1 2 3 4 5  . ├── invsqrt.cpp ├── invsqrt.h ├── main.cpp └── makefile   makefile如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  CXXFLAGS = -std=c++17 -O2 main: main.o invsqrt.o $(CXX) $(CXXFLAGS) -o $@ $^ main.o: main.cpp invsqrt.h $(CXX) $(CXXFLAGS) -o $@ -c $\u0026lt; invsqrt.o: invsqrt.cpp invsqrt.h $(CXX) $(CXXFLAGS) -o $@ -c $\u0026lt; .PHONY: clean clean: rm main.o invsqrt.o main   我们不需要理解每一段代码的具体含义（之后我们可以看到，我们不需要手动编写makefile，而可以直接通过CMake工具生成makefile），我们只需要了解如何使用makefile：\n 在makefile的同目录下输入make，就可以按照makefile所指定的编译规则自动编译整个工程。 在makefile的同目录下输入make clean，可以删除编译生成的中间文件和可执行文件。 除此之外，你还可以为makefile添加更多指令，此处由于篇幅所限，不再展开介绍。  CMake makefile存在以下问题：\n 语法复杂，代码可读性差，难以维护。 跨平台性差。  在目前的C++工程中，我们多使用CMake来管理项目。\n什么是CMake？CMake是一种跨平台的编译工具，可以用较为简洁易读的语法描述C++项目的编译、链接、安装过程等，在现代C++项目上得到了广泛应用。\n1 第一个CMake项目 CMake的项目文件叫做CMakeLists.txt。其放置位置如下图所示：\n1 2  ├── CMakeLists.txt └── main.cpp   该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3  cmake_minimum_required(VERSION 3.5)project (hello_world)add_executable(hello_world main.cpp)   语法总结1\n cmake_minimum_required(VERSION 3.5) CMake需要的最小版本。CMake的版本可以在命令行中输入cmake --version获取，一般无强制要求。 project(\u0026lt;project_name\u0026gt;) 指定工程名称。 add_executable(\u0026lt;executable_name\u0026gt; \u0026lt;cppfile_name\u0026gt;) 生成可执行文件。   cmake工具的使用一般分为两步 1) 使用CMakeLists.txt生成makefile。 2) 使用makefile自动化编译项目。\n 输入cmake CMakeLists.txt，目录下将会生成一个Makefile文件。 输入make，即可将源代码编译生成可执行文件。此处将会在与CMakeLists.txt相同目录的位置生成一个可执行文件hello_word，输入./hello_word即可运行该可执行文件。 此外，输入make help，你也可以查看使用当前的Makefile所能执行的所有指令，例如make clean（清楚生成的可执行文件和中间文件）。  2 多文件 在平时的程设小作业中，我们习惯将所有的代码都写在一个.cpp文件中。但在实际工程中，为了方便代码复用和运行维护，通常将所有的文件划分为头文件(.h)，模块文件(.cpp)和主程序文件(.cpp)。\n在本节中，我们将在头文件中声明一个计算平方根倒数的函数，在模块文件中实现其主体，然后在主函数中调用它。项目结构如下：\n1 2 3 4 5 6 7  . ├── CMakeLists.txt ├── include │ └── invsqrt.h └── src ├── invsqrt.cpp └── main.cpp    tips: 在C++工程中，我们通常在include/目录下放置头文件，在src/目录下放置源文件。\n 该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3 4 5 6 7 8 9 10 11 12  # build part cmake_minimum_required(VERSION 3.5)project(invsqrt)set(SOURCES src/invsqrt.cpp src/main.cpp)add_executable(invsqrt ${SOURCES})target_include_directories(invsqrt PUBLIC ${PROJECT_SOURCE_DIR}/include)# debug part message(\u0026#34;CMAKE_SOURCE_DIR: ${CMAKE_SOURCE_DIR}\u0026#34;)message(\u0026#34;PROJECT_SOURCE_DIR: ${PROJECT_SOURCE_DIR}\u0026#34;)message(\u0026#34;SOURCES: ${SOURCES}\u0026#34;)   语法总结2\n set(\u0026lt;variable\u0026gt; \u0026lt;value\u0026gt;) 设置变量 target_include_directories(\u0026lt;project_name\u0026gt; \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; \u0026lt;headfile_directory\u0026gt;) 指定所要包含的头文件。 message(\u0026quot;your message\u0026quot;) 在终端打印信息。   这里需要特别说明一下CMake中的变量使用。CMake中的变量分为两种：\n 显式变量：使用set指令定义的变量。 隐式变量：通过其它指令隐式生成的变量。如该项目中会隐式生成PROJECT_SOURCE_DIR变量，默认为CMakeLists.txt所在的文件夹。  CMake中有丰富的变量，用于定义工程目录、编译选项等，此处不做过多展开。想要了解更多，可以参考文末列出的参考文档。\n3 静态库和动态库 有些时候，出于方便复用、防止源码泄露等原因，我们需要将代码封装为静态库和动态库。CMake同样提供了生成静态库和动态库的功能。\n3.1 静态库 在此处，我们将上一小节中计算平方根倒数的程序封装为静态库。项目结构如下：\n1 2 3 4 5 6 7  . ├── CMakeLists.txt ├── include │ └── invsqrt.h └── src ├── invsqrt.cpp └── main.cpp   该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3 4 5 6 7 8 9 10  cmake_minimum_required(VERSION 3.5)project(invsqrt)# create static library add_library(invsqrt_static STATIC src/invsqrt.cpp)target_include_directories(invsqrt_static PUBLIC ${PROJECT_SOURCE_DIR}/include)# create executable add_executable(invsqrt src/main.cpp)target_link_libraries(invsqrt PRIVATE invsqrt_static)   语法总结3\n add_library(\u0026lt;library_name\u0026gt; STATIC \u0026lt;cppfile_name\u0026gt;) 生成静态库 target_link_libraries(\u0026lt;executable\u0026gt; \u0026lt;INTERFACE|PUBLIC|PRIVATE\u0026gt; \u0026lt;library_name\u0026gt;) 指定所要链接的库。   此处我们使用一种更为优雅的生成方式——我们期望将生成的静态库、可执行文件输出到build文件夹里，而不是和主项目混杂在一起。为此我们需要输入以下指令：\n1 2 3 4  $ mkdir build $ cd build $ cmake .. # 使用的是上一层目录的CMakeLists.txt，因此需要输入\u0026#39;..\u0026#39; $ make   我们将会在build/目录下看到静态库libinvsqrt_static.a和可执行文件invsqrt。\n3.2 动态库 项目目录结构同静态库一节。\n该项目的CMakeLists.txt中需要添加以下内容：\n1 2 3 4 5 6 7 8 9 10  cmake_minimum_required(VERSION 3.5)project(invsqrt)# create shared library add_library(invsqrt_shared SHARED src/invsqrt.cpp)target_include_directories(invsqrt_shared PUBLIC ${PROJECT_SOURCE_DIR}/include)# create executable add_executable(invsqrt src/main.cpp)target_link_libraries(invsqrt PRIVATE invsqrt_shared)   语法总结4\n add_library(\u0026lt;library_name\u0026gt; SHARED \u0026lt;cppfile_name\u0026gt;) 生成动态库   同样按照上小节的方法生成项目。我们将会在build/目录下看到动态库libinvsqrt_shared.so和可执行文件invsqrt。\n4 使用第三方库 在实际的C++工程中，我们可能需要链接一些开源的第三方库。CMake也提供了相关的配置方式。我们以谷歌开发的单元测试框架googletest为例：\n googletest的安装方法：\n1 2 3 4 5 6 7 8 9  $ git clone https://github.com/google/googletest.git # or git clone git@github.com:google/googletest.git $ cd googletest $ mkdir build $ cd build $ cmake ../ $ make -j all $ make install # or sudo make install     在默认情况下，与该第三方库相关的头文件将会被放置在/usr/local/include目录下，与该第三方库相关的库文件将会被放置在/usr/local/lib目录下，与该第三方库相关的可执行文件将会被放置在/usr/local/bin目录下。\n 项目结构如下：\n1 2 3 4 5 6 7  . ├── CMakeLists.txt ├── include │ └── mysqrt.h └── src ├── mysqrt.cpp └── main.cpp   1 2 3 4 5 6 7 8 9 10 11 12 13 14  cmake_minimum_required(VERSION 2.6)project(cmake_with_gtest)set(SOURCES src/mysqrt.cpp src/main.cpp)find_package(GTest)message(\u0026#34;GTEST_LIBRARIES: ${GTEST_LIBRARIES}\u0026#34;)message(\u0026#34;GTEST_INCLUDE_DIRS: ${GTEST_INCLUDE_DIRS}\u0026#34;)include_directories(${GTEST_INCLUDE_DIRS} ${PROJECT_SOURCE_DIR}/include)add_executable(cmake_with_gtest ${SOURCES})target_link_libraries(cmake_with_gtest ${GTEST_LIBRARIES} pthread)   语法总结5\n find_package(\u0026lt;package_name\u0026gt;) 查询第三方库的位置。若查找成功，则初始化变量\u0026lt;package_name\u0026gt;_INCLUDE_DIR（第三方库的头文件目录）以及\u0026lt;package_name\u0026gt;_LIBRARIES（第三方库的静态/动态库目录）。   CMake支持的所有第三方库可以在https://cmake.org/cmake/help/latest/manual/cmake-modules.7.html中找到。\n写在最后 CMake还有很多强大的功能：\n 设置C++工程的语言标准、编译优化选项。 层级文件之间CMakeLists.txt的相互调用，以便应用于目录层级更加复杂的C++工程。 对生成的库、可执行文件等进行安装。 \u0026hellip;  略过上述内容不会对我们的教学产生太大影响。感兴趣的同学可以参考以下文章：\n CMake官方文档 cmake-examples 该GitHub仓库中有很多开箱即用的CMake实例。 为什么编译c/c++要用makefile，而不是直接用shell呢？ 这篇博文详细地阐述了使用makefile的动机和意义（\\xfgg/）。 跟我一起写Makefile Makefile教程。从中大家也可以看出Makefile的语法十分不友好\u0026hellip;  ","date":"2022-06-23T20:47:58+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/cmake/","title":"Makefile \u0026 CMake"},{"content":"目录 [TOC]\n前言 在程设课上，我们运行一个C++程序的步骤通常是这样的：打开Visual Studio 2008，在文件中写好程序，然后点击“开始调试”或者“开始执行（不调试）”，一个黑色的方框就会弹出来。\n实际上，从C++源代码文件到可执行文件的过程是十分复杂的，Visual Studio等现代化的IDE（Integrated Development Environment，集成开发环境）掩盖了程序构建的复杂流程。本节我们就以linux平台上的C++程序为例，简略介绍C++工程中的一些概念。\n为了获得更好的实验体验，建议大家使用linux操作系统（虚拟机或WSL）来运行本节的程序。\n本讲需要使用到的工具有：gcc，g++。可以通过以下方式安装：\n1  $ sudo apt-get install gcc g++   从.cpp到.exe —— C/C++程序的构建过程 C/C++程序生成一个可执行文件的过程可以分为4个步骤：预处理（Preprocessing）、编译（Compiling）、汇编（Assembly）和链接（Linking）。之后我们将通过演示实例介绍每一步发生的故事。\n编译工具 针对不同的应用场景和平台，各大厂家设计了不同的C++编译工具。\n  MSVC（Microsoft Visual C++）：MSVC是微软公司开发的C++开发工具，我们程设课上使用的Visual Studio就内置了MSVC。\n  GCC（GNU Compiler Collection）：GCC是由GNU（GNU\u0026rsquo;s Not Unix）开发的一套编译工具，支持C、C++、Fortran、Go等一系列语言。本教程中我们使用的编译工具就是GCC。\nGCC提供给用户的前端程序为gcc（针对C）和g++（针对C++）。它们的区别详见gcc vs g++。\n  此外还有Clang、NVCC等编译工具。不同的编译工具对C++的支持不尽然相同，此处不再赘述。\n  1 预处理 C++程序在预处理阶段会执行以下操作：宏的替换、头文件的插入、删除条件编译中不满足条件的部分。\n1  $ g++ –E invsqrt.cpp –o invsqrt.i   2 编译 C++程序在编译阶段会将C++文件转换为汇编文件。\n1 2 3 4  # from .i file $ g++ –S invsqrt.i –o invsqrt.s # from .cpp file $ g++ –S invsqrt.cpp –o invsqrt.s   3 汇编 汇编语言文件经过汇编，生成目标文件.o文件（二进制文件，机器码），每一个源文件都对应一个目标文件。\n1 2 3 4 5  # from .s file $ g++ –c invsqrt.s –o invsqrt.o # from .cpp file $ g++ –c invsqrt.cpp –o invsqrt.o $ g++ -c main.cpp -o main.o    生成的invsqrt.o和main.o文件不能直接打开，你可以使用readelf -a \u0026lt;object file\u0026gt;阅读其信息。\n 4 链接 每个源文件对应的目标.o文件被链接起来，就生成一个可执行程序文件。\n1  $ g++ invsqrt.o main.o -o main.exe   当然，如果想要使用.cpp文件一步到位生成可执行文件，可以使用以下指令：\n1  $ g++ invsqrt.cpp main.cpp -o main.exe    实际上在linux系统上，可执行文件一般是没有后缀名的。此处为了方便说明添加了.exe文件。\n  语法总结\ng++和gcc工具中使用的一些命令行参数：\n  -E 只进行预处理\n  -S 只进行编译\n  -c 只生成目标文件\n  -o \u0026lt;file\u0026gt; 指定输出文件的名称。我们约定：.i为预处理后的文件，.s为汇编文件，.o为目标文件。\n   静态库和动态库 出于便于复用、封装细节或防止源码泄露等原因，在实际应用过程中，我们需要把C++源码封装为库(library)。\n根据其行为不同，可以将库分为静态库(static library)和动态库(shared library)。\n静态库 静态库的代码在编译的过程中，会被直接载入到可执行文件中。这样做的好处是：可执行文件在执行时，不再需要静态库本身。但缺点也显而易见：生成的可执行文件的体积会比较大。\nlinux平台下静态库的后缀通常为.a，命名方式通常为libxxx.a;windows平台下静态库的后缀通常为.lib。\n在linux平台上生成静态库，并使用动态库链接形成可执行文件的方法为：\n1 2 3 4  # generate static lib $ ar crv libinvsqrt.a invsqrt.cpp # link to generate the executable file $ g++ -static main.cpp -L . -linvsqrt -o main_shared.exe   动态库 动态库在程序编译时并不会被连接到目标代码中，而是在程序运行是才被载入。这就带来了一个明显的好处：不同的应用程序如果调用相同的库，那么在内存里只需要有一份该共享库的实例，减小了各个模块之间的耦合程度，也减小了可执行文件的体积。然而，这也要求用户的电脑上需要同时拥有可执行文件和动态库，也有可能因为版本不匹配等问题发生DLL Hell等问题。\nlinux平台下静态库的后缀通常为.so，命名方式通常为libxxx.so;windows平台下静态库的后缀通常为.dll。\n在linux平台上生成动态库，并使用动态库链接形成可执行文件的方法为：\n1 2 3 4  # generate shared lib $ g++ invsqrt.cpp -I ./ -fPIC -shared -o libinvsqrt.so # link to generate the executable file $ g++ main.cpp -L . -linvsqrt -o main_shared.exe   写在最后 由于时间所限，还有很多有趣的内容我们没有涉及：\n gcc/g++有着丰富的命令行参数设置，比如程序优化、C/C++语言标准设置等。 在本节中，我们只介绍了如何在linux平台上生成和使用静态库、动态库。实际上，利用Visual Studio也可以便捷地在windows平台上生成静态库、动态库。 \u0026hellip;  略过上述内容不会对我们的教学产生太大影响。感兴趣的同学可以参考以下文档：\n GCC官网 learn cpp 一份新手友好的C++入门文档。 演练：使用Visual Studio创建并使用静态库 演练：使用Visual Studio创建并使用动态库  ","date":"2022-06-23T20:47:58+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/compile/","title":"编译、链接、静态库、动态库"},{"content":"C# async 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118  using System; using System.Collections.Generic; using System.Threading.Tasks; namespace AsyncBreakfast { // These classes are intentionally empty for the purpose of this example. They are simply marker classes for the purpose of demonstration, contain no properties, and serve no other purpose. internal class Bacon { } internal class Coffee { } internal class Egg { } internal class Juice { } internal class Toast { } class Program { static async Task Main(string[] args) { Coffee cup = PourCoffee(); Console.WriteLine(\u0026#34;coffee is ready\u0026#34;); var eggsTask = FryEggsAsync(2); // save the task  var baconTask = FryBaconAsync(3); var toastTask = MakeToastWithButterAndJamAsync(2); var breakfastTasks = new List\u0026lt;Task\u0026gt; { eggsTask, baconTask, toastTask }; while (breakfastTasks.Count \u0026gt; 0) { Task finishedTask = await Task.WhenAny(breakfastTasks); // use this code to await an async process if (finishedTask == eggsTask) { Console.WriteLine(\u0026#34;eggs are ready\u0026#34;); } else if (finishedTask == baconTask) { Console.WriteLine(\u0026#34;bacon is ready\u0026#34;); } else if (finishedTask == toastTask) { Console.WriteLine(\u0026#34;toast is ready\u0026#34;); } breakfastTasks.Remove(finishedTask); } Juice oj = PourOJ(); Console.WriteLine(\u0026#34;oj is ready\u0026#34;); Console.WriteLine(\u0026#34;Breakfast is ready!\u0026#34;); } // combine an async task and a simple task static async Task\u0026lt;Toast\u0026gt; MakeToastWithButterAndJamAsync(int number) { var toast = await ToastBreadAsync(number); ApplyButter(toast); ApplyJam(toast); return toast; } private static Juice PourOJ() { Console.WriteLine(\u0026#34;Pouring orange juice\u0026#34;); return new Juice(); } private static void ApplyJam(Toast toast) =\u0026gt; Console.WriteLine(\u0026#34;Putting jam on the toast\u0026#34;); private static void ApplyButter(Toast toast) =\u0026gt; Console.WriteLine(\u0026#34;Putting butter on the toast\u0026#34;); private static async Task\u0026lt;Toast\u0026gt; ToastBreadAsync(int slices) { for (int slice = 0; slice \u0026lt; slices; slice++) { Console.WriteLine(\u0026#34;Putting a slice of bread in the toaster\u0026#34;); } Console.WriteLine(\u0026#34;Start toasting...\u0026#34;); await Task.Delay(3000); Console.WriteLine(\u0026#34;Remove toast from toaster\u0026#34;); return new Toast(); } private static async Task\u0026lt;Bacon\u0026gt; FryBaconAsync(int slices) { Console.WriteLine($\u0026#34;putting {slices} slices of bacon in the pan\u0026#34;); Console.WriteLine(\u0026#34;cooking first side of bacon...\u0026#34;); await Task.Delay(3000); for (int slice = 0; slice \u0026lt; slices; slice++) { Console.WriteLine(\u0026#34;flipping a slice of bacon\u0026#34;); } Console.WriteLine(\u0026#34;cooking the second side of bacon...\u0026#34;); await Task.Delay(3000); Console.WriteLine(\u0026#34;Put bacon on plate\u0026#34;); return new Bacon(); } private static async Task\u0026lt;Egg\u0026gt; FryEggsAsync(int howMany) { Console.WriteLine(\u0026#34;Warming the egg pan...\u0026#34;); await Task.Delay(3000); Console.WriteLine($\u0026#34;cracking {howMany} eggs\u0026#34;); Console.WriteLine(\u0026#34;cooking the eggs ...\u0026#34;); await Task.Delay(3000); Console.WriteLine(\u0026#34;Put eggs on plate\u0026#34;); return new Egg(); } private static Coffee PourCoffee() { Console.WriteLine(\u0026#34;Pouring coffee\u0026#34;); return new Coffee(); } } }   ","date":"2022-06-22T10:40:10+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/csharp_async/","title":"Csharp async"},{"content":"dotnet build 生成一个.NET工程。目录下必须有.sln文件或.csproj文件。\ndotnet publish 生成一个.NET工程的发布版本。目录下必须有.sln文件或.csproj文件。\ndotnet run 启动一个.NET工程。目录下必须有.csproj文件。\ndotnet clean 清除一个.NET工程的所有编译文件。目录下必须有.sln文件或.csproj文件。\ndotnet list package 查看一个.NET工程的所有依赖包。目录下必须有.sln文件或.csproj文件。\ndotnet list reference 列举项目的所有依赖项。目录下必须有.csproj文件。\ndotnet add package \u0026lt;PACKAGE_NAME\u0026gt; --version \u0026lt;VERSION\u0026gt; 添加一个依赖包。目录下必须有.csproj文件。\n publish命令和build命令最大的区别在于：publish命令将应用程序的依赖项，从NuGet缓存复制到输出文件夹中。\n ","date":"2022-06-21T17:59:46+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/csharp_on_linux/","title":"Csharp on Linux"},{"content":"Protobuf 目录 [TOC]\n数据的传输与解析——浅谈序列化与反序列化 在网络通信的过程中，服务器端和客户端之间常常需要进行对象的传输。对象中常常含有不同的变量：\n 整数 字符串 数组 数组对象 \u0026hellip;  那么我们如何正确地进行这种传递呢？要想实现对象的传输，在发送端我们需要使用一定的规则，将对象转换为具体的字节数组，这就是序列化(serialization)；而在接受端再以这种规则将字节数组还原为对象，这就是反序列化(deserialization)。\n常见的序列化-反序列化协议有XML、JSON、Protobuf。\n XML(eXtensible Markup Language，可扩展标记语言)使用标签\u0026lt;xx\u0026gt;和\u0026lt;/xx\u0026gt;来区隔不同的数据。 JSON(JavaScript Object Notation，JavaScript对象简谱)使用JavaScript构造对象的方法来存储、传输数据。 Protobuf(Protocol Buffers)是Google公司开源跨平台的序列化数据结构的协议。  我们通过一个实例说明三者的差异。我们不妨定义以下对象：\n1 2 3 4 5 6 7 8 9 10 11 12  #include \u0026lt;string\u0026gt; class Helloworld { int id; std::string name; } int main() { Helloworld helloworld(101, \u0026#34;hello\u0026#34;); }   使用XML序列化该对象：\n1 2 3 4  \u0026lt;helloworld\u0026gt; \u0026lt;id\u0026gt;101\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;hello\u0026lt;/name\u0026gt; \u0026lt;/helloworld\u0026gt;   使用JSON序列化该对象：\n1 2 3 4  { \u0026#34;id\u0026#34;: 101, \u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34; }   使用Protobuf序列化该对象（16进制格式）：\n1  08 65 12 06 48 65 6C 6C 6F 77   根据上述实例，我们可以用一张表格总结三者的差异：\n    XML JSON Protobuf     数据存储格式 文本 文本 二进制   可读性 好 较好 差   存储空间 大 较大 小   序列化/反序列速度 慢 慢 快   侧重点 数据结构化 数据结构化 数据序列化     本节我们将重点介绍Protobuf的使用方法。但XML及其各种变体（如HTML、XAML）和JSON也在软件部的后续开发中有着广泛应用。感兴趣的同学可以参考相关资料了解XML和JSON的更多使用方法。\n protobuf的安装 protobuf可以通过以下方式安装（参考自Protobuf C++ Installation）\n1 2 3 4 5 6 7 8 9 10 11 12  $ sudo apt-get install autoconf automake libtool curl make g++ unzip # 安装所需要的工具包 $ git clone https://github.com/protocolbuffers/protobuf.git # 若网络不佳，可以将指令换为 git clone https://gitee.com/mirrors/protobuf_source.git ./protobuf $ cd protobuf # (optional) git submodule update --init --recursive $ git checkout 3.20.x # 根据版本需求选择不同的分支 $ ./autogen.sh $ ./configure $ make -j$(nproc) $ sudo make install $ sudo ldconfig   以上操作会将protoc可执行文件（后续教程会介绍其使用方法）以及与protobuf相关的头文件、库安装至本机。在终端输入protoc，若输出提示信息，则表示安装成功。\nproto文件 基础使用 在使用protobuf时，我们首先需要在.proto文件中将需要被序列化的数据结构进行定义。\n一个.proto文件示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  // import \u0026#34;other_protos.proto\u0026#34;; // 如果需要引用其它的protobuf文件，可以使用import语句。 syntax = \u0026#34;proto3\u0026#34;; // 指定protobuf遵循的语法格式是proto2还是proto3。在本教程和之后的开发中，我们都使用proto3语法格式。 package student; // 包名声明。如在本例中，proto文件生成的类都会被放在namespace student中，这一举措的意义在于防止命名冲突 enum Sex // 自定义枚举类型 { MALE = 0; FEMALE = 1;}message Course // protobuf中，使用message定义数据结构，类似于C中的结构体 { int32 credit = 1; string name = 2;}message StudentInfo{ // 变量声明格式 \u0026lt;限定修饰符\u0026gt; \u0026lt;数据类型\u0026gt; \u0026lt;变量名\u0026gt;=id  int32 age = 1; string name = 2; Sex sex = 3; repeated Course courses = 4; // repeated表示重复（数组），本例也表明message可以嵌套message }  protobuf语法标准 protobuf有两套语法标准：proto2和proto3，两套语法不完全兼容。我们可以使用syntax关键字指定protobuf遵循的语法标准。\npackage 为了防止命名冲突，protobuf文件中可以声明包名（package）。具体效果将在后续章节介绍。\n编号 消息定义中的每个字段都有一个唯一的编号，从1开始。这些字段号用于识别你在二进制格式消息中的信息。\n一个常见的约定是，我们会将经常使用的字段编号为1-15，不常用的字段编号为16以上的数字，因为1-15的编号编码仅需要1 byte，这样可以减小字节流的体积。\n数据类型 Protobuf中常见的基础数据类型与若干编程语言的对应关系如下：\n   proto Type C++ Type Python Type C# Type     double double float double   float float float float   int32 int32 int int   int64 int64 int/long long   uint32 uint32 int/long uint   uint64 uint64 int/long ulong   sint32 int32 int int   sint64 int64 int/long long   fixed32 uint32 int/long uint   fixed64 uint64 int/long ulong   sfixed32 int32 int int   sfixed64 int64 int/long long   bool bool bool bool   string string str/unicode string   bytes string str (Python 2) bytes (Python 3) ByteString    更多语言的对应关系参看Protobuf scalar types。\n此外，Protobuf还支持使用enum关键字定义枚举类型。每个枚举定义都必须包含一个映射到0的常量作为枚举的默认值。\n为了尽可能多地压缩数据，Protobuf对各数据类型地默认值做了以下处理：\n numeric types: 0 bool: false string: 空字符串 byte: 空字节 enum: 第一个定义的枚举值（0） message: 取决于目标编程语言  repeated repeated关键字可以定义重复多次的信息（即数组），其顺序是有序的。\n命名法 为了便于阅读，protobuf规定了一系列命名法：\n message、enum采用大驼峰命名法，如message StudentInfo。 字段采用下划线分割法，且全部小写，如string student_name。 枚举值采用下划线分割法，且全部大写，如FIRST_VALUE。  进阶使用 protobuf中还有一些高级语法：\noneof 如果你有一个信息，它可能包含若干种字段，并且最多只有一个字段会同时被设置（回忆C/C++中的联合体union），你可以使用oneof字段来节省空间。\noneof块中可以定义除了map字段（后续会讲到）和repeated字段外的所有类型字段。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  syntax = \u0026#34;proto3\u0026#34;;package oneof_demomessage MessageA{\tstring name_a = 1;}message MessageOneof{\toneof test_oneof\t{\tstring name = 1;\tMessageA message_a = 2;\t}}  map map字段可以定义关联映射类型（类似于Python中的字典dict()）。\nmap字段的定义方式如下：map\u0026lt;key_type, value_type\u0026gt; map_field = N;。其中，key_value可以为整数类型或字符串类型，value_type为除map类型的任意类型。\n1 2 3 4 5 6 7  syntax = \u0026#34;proto3\u0026#34;;package map_demomessage StudentInfo{\tmap\u0026lt;int32,string\u0026gt; id_name_pairs = 1;}  除此之外，protobuf中还有很多高阶语法：\n Any 保留字段（Reserved Values） 嵌套类型（Nested Types） \u0026hellip;  此处由于篇幅所限，我们不做过多展开。\n使用proto文件进行序列化和反序列化 生成目标语言文件 编写好的protobuf文件不能直接应用于工程中，我们需要使用protoc工具生成对应的文件（以C++和Csharp为例）：\n1 2 3  $ protoc --help # 查看使用方法 $ protoc test.proto --cpp_out=. # 在当前目录下生成.cpp文件和.h文件 $ protoc test.proto --csharp_out=. # 在当前目录下生成.cs文件   若使用--cpp_out选项，则会生成\u0026lt;protobuf_name\u0026gt;.pb.h文件和\u0026lt;protobuf_name\u0026gt;.pb.cc文件；若使用--csharp_out选项，则会生成\u0026lt;protobuf_name\u0026gt;.cs文件。生成的文件中会将proto文件中定义的message转换为对应的类，供目标语言程序使用。\nC++ 在C++程序中使用protobuf工具的例程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60  #include \u0026lt;iostream\u0026gt;#include \u0026lt;fstream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;google/protobuf/message.h\u0026gt; // for protobuf #include \u0026#34;test.pb.h\u0026#34; // for protobuf source file int main() { // 可以看到，protobuf文件中的信息都被封装在namespace student中，这是之前protobuf中的`package`语法所规定的。  // 1. 如何实例化一个proto文件中定义的类  student::StudentInfo student1; // 2. 如何设置类的各个属性  // a. 添加单一字段：使用set_\u0026lt;xxx\u0026gt;()语句  student1.set_age(18); student1.set_name(\u0026#34;Alice\u0026#34;); student1.set_sex(student::Sex::female); // b. 添加repeated字段：使用add_\u0026lt;xxx\u0026gt;()语句  student::Course* course1 = student1.add_courses(); course1 -\u0026gt; set_name(\u0026#34;calculus\u0026#34;); course1 -\u0026gt; set_credit(5); student::Course* course2 = student1.add_courses(); course2 -\u0026gt; set_name(\u0026#34;Fundamentals of Electronic Circuits and System\u0026#34;); course2 -\u0026gt; set_credit(2); // 3. 如何使用类的各个属性：使用\u0026lt;xxx\u0026gt;()语句  std::cout \u0026lt;\u0026lt; \u0026#34;----------------student info----------------\u0026#34; \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;age: \u0026#34; \u0026lt;\u0026lt; student1.age() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; student1.name() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;sex (0:male, 1:female): \u0026#34; \u0026lt;\u0026lt; (int)student1.sex() \u0026lt;\u0026lt; std::endl \u0026lt;\u0026lt; \u0026#34;courses: \u0026#34; \u0026lt;\u0026lt; std::endl; for(int i = 0;i\u0026lt;student1.courses_size();i++) { std::cout \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;. \u0026#34; \u0026lt;\u0026lt; \u0026#34;name: \u0026#34; \u0026lt;\u0026lt; student1.courses(i).name() \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; \u0026#34;credit: \u0026#34; \u0026lt;\u0026lt; student1.courses(i).credit() \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;--------------------------------------------\u0026#34; \u0026lt;\u0026lt; std::endl; // 4. 序列化  std::cout \u0026lt;\u0026lt; \u0026#34;serialize to file.\u0026#34; \u0026lt;\u0026lt; std::endl; std::fstream output(\u0026#34;./output\u0026#34;, std::ios::out | std::ios::binary ); student1.SerializeToOstream(\u0026amp;output); // 序列化为流  std::cout \u0026lt;\u0026lt; \u0026#34;serialize to array.\u0026#34; \u0026lt;\u0026lt; std::endl; size_t size = student1.ByteSizeLong(); unsigned char* data = new unsigned char [size]; student1.SerializeToArray(data, student1.ByteSizeLong()); // 序列化为数组  // 5. 反序列化和debug  std::cout \u0026lt;\u0026lt; \u0026#34;deserialize from array.\u0026#34; \u0026lt;\u0026lt; std::endl; student::StudentInfo studentInfoFromArray; std::cout \u0026lt;\u0026lt; std::endl; studentInfoFromArray.ParseFromArray(data, size); std::cout \u0026lt;\u0026lt; studentInfoFromArray.DebugString() \u0026lt;\u0026lt; std::endl; // 输出字符串化的信息 }   需要指出的是，想要成功生成可执行文件，需要链接protobuf的静态库和动态库。在linux系统上应用使用到protobuf的C++工程，最好的方法是使用CMake。在本例中，库的依赖关系由CMake工具处理。\nCsharp 在Csharp程序中使用protobuf工具的例程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65  using System; using System.IO; using Google.Protobuf; using Student; namespace example { class Program { static void Main(string[] args) { // 1. 如何实例化一个proto文件中定义的类  var student1 = new StudentInfo(); // 2. 如何设置类的各个属性 // a. 添加单一字段（回忆Csharp一讲中的“字段”） student1.Age = 18; student1.Name = \u0026#34;Alice\u0026#34;; student1.Sex = Sex.Female; // b. 添加repeated字段（使用Add()方法） var course1 = new Course(); course1.Name = \u0026#34;calculus\u0026#34;; course1.Credit = 5; student1.Courses.Add(course1); var course2 = new Course(); course2.Name = \u0026#34;Fundamentals of Electronic Circuits and System\u0026#34;; course2.Credit = 2; student1.Courses.Add(course2); // 3. 如何使用类的各个属性（回忆Csharp一讲中的“字段”） Console.WriteLine(\u0026#34;----------------student info----------------\u0026#34;); Console.WriteLine($\u0026#34;age: {student1.Age}\u0026#34;); Console.WriteLine($\u0026#34;name: {student1.Name}\u0026#34;); Console.WriteLine($\u0026#34;sex (0:male, 1:female): {student1.Sex}\u0026#34;); Console.WriteLine($\u0026#34;courses: \u0026#34;); foreach (Course course in student1.Courses) { Console.WriteLine($\u0026#34;name: {course.Name} credit: {course.Credit}\u0026#34;); } // 4. 序列化 Console.WriteLine(\u0026#34;serialize to array.\u0026#34;); byte[] data = new byte[student1.CalculateSize()]; MemoryStream ostream = new MemoryStream(); using (CodedOutputStream output = new CodedOutputStream(ostream, true)) { student1.WriteTo(output); output.Flush(); } data = ostream.ToArray(); // 5. 反序列化和debug Console.WriteLine(\u0026#34;deserialize from array.\u0026#34;); var student2 = new StudentInfo(); MemoryStream istream = new MemoryStream(data); using (CodedInputStream input = new CodedInputStream(istream)) { student2?.MergeFrom(input); } Console.WriteLine(student2); } } }   在Csharp程序中，需要在NuGet程序包中搜索并下载Google.Protobuf安装包。\n 补充说明：如何在Visual Studio中使用NuGet为Csharp程序安装第三方库？\nNuGet是一个自由开源软件包管理系统，作为Visual Studio的一个扩展，可以简化在Visual Studio中添加、更新和删除库的操作。\n我们在开发Csharp程序时不可避免地要用到第三方库，NuGet是一种很好用的工具。以下将以protobuf为例简要介绍NuGet的使用。\n  右键项目，点击“管理NuGet程序包”。\n  点击“浏览”，搜索你想要安装的包名。可以根据项目所需要切换不同的版本。\n  点击安装。在编辑器内输入using Google.Protobuf，若无报错，说明安装成功。\n   写在最后 由于篇幅所限，我们仍然有许多内容没有展开：\n protobuf编码之varint/zigzag protobuf为什么可以获得如此高效的编码效果？这涉及到其底层算法——varint和zigzag算法。 proto2语法和proto3语法的区别。 \u0026hellip;  略去上述内容不会对我们的教学产生太大影响，感兴趣的同学可以参考Protobuf官方文档学习更多知识。\n","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/protobuf/","title":"Protobuf"},{"content":"Parameters Parameters are Tensor subclasses, that have a very special property when used with Module s - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear e.g. in parameters() iterator.\n简单来讲，nn.Parameters用于注册可供训练的参数。e.g:\n1 2 3 4 5 6  In [6]: a = torch.nn.Parameter(torch.Tensor([0])) In [7]: a Out[7]: Parameter containing: tensor([0.], requires_grad=True)   nn.Parameter默认requires_grad=True\n一些常用参量（用于更新参数等）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  \u0026gt;\u0026gt; class Net(torch.nn.Module): ...: def __init__(self): ...: super().__init__() ...: self.linear_1 = torch.nn.Linear(3,2) ...: self.linear_2 = torch.nn.Linear(2,1) \u0026gt;\u0026gt; net = Net() \u0026gt;\u0026gt; net.modules \u0026gt;\u0026gt; \u0026lt;bound method Module.modules of Net( (linear_1): Linear(in_features=3, out_features=2, bias=True) (linear_2): Linear(in_features=2, out_features=1, bias=True) )\u0026gt; \u0026gt;\u0026gt; net.named_modules \u0026gt;\u0026gt; \u0026lt;bound method Module.named_modules of Net( (linear_1): Linear(in_features=3, out_features=2, bias=True) (linear_2): Linear(in_features=2, out_features=1, bias=True) )\u0026gt; \u0026gt;\u0026gt; net.state_dict() \u0026gt;\u0026gt; OrderedDict([(\u0026#39;linear_1.weight\u0026#39;, tensor([[-0.5300, -0.5476, 0.0943], [-0.2907, 0.1068, 0.5465]])), (\u0026#39;linear_1.bias\u0026#39;, tensor([ 0.3375, -0.4314])), (\u0026#39;linear_2.weight\u0026#39;, tensor([[ 0.0114, -0.2185]])), (\u0026#39;linear_2.bias\u0026#39;, tensor([0.1354]))]) \u0026gt;\u0026gt; net.parameters \u0026gt;\u0026gt; \u0026lt;bound method Module.parameters of Net( (linear_1): Linear(in_features=3, out_features=2, bias=True) (linear_2): Linear(in_features=2, out_features=1, bias=True) )\u0026gt; \u0026gt;\u0026gt; net.lambda1 = torch.nn.Parameter(torch.randn((1,1))) \u0026gt;\u0026gt; net.lambda1 \u0026gt;\u0026gt; Parameter containing: tensor([[-0.0876]], requires_grad=True) \u0026gt;\u0026gt; net.state_dict() \u0026gt;\u0026gt; OrderedDict([(\u0026#39;lambda1\u0026#39;, tensor([[-0.0876]])), (\u0026#39;linear_1.weight\u0026#39;, tensor([[-0.5300, -0.5476, 0.0943], [-0.2907, 0.1068, 0.5465]])), (\u0026#39;linear_1.bias\u0026#39;, tensor([ 0.3375, -0.4314])), (\u0026#39;linear_2.weight\u0026#39;, tensor([[ 0.0114, -0.2185]])), (\u0026#39;linear_2.bias\u0026#39;, tensor([0.1354]))])   optimizer 1 2 3 4 5 6 7 8 9 10 11  \u0026gt;\u0026gt; optimizer = torch.optim.Adam(net.parameters(), lr=0.01) \u0026gt;\u0026gt; optimizer.state_dict() \u0026gt;\u0026gt; {\u0026#39;state\u0026#39;: {}, \u0026#39;param_groups\u0026#39;: [{\u0026#39;lr\u0026#39;: 0.01, \u0026#39;betas\u0026#39;: (0.9, 0.999), \u0026#39;eps\u0026#39;: 1e-08, \u0026#39;weight_decay\u0026#39;: 0, \u0026#39;amsgrad\u0026#39;: False, \u0026#39;params\u0026#39;: [0, 1, 2, 3, 4]}]} \u0026gt;\u0026gt; optimizer.state \u0026gt;\u0026gt; defaultdict(dict, {})   ","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/pytorch/","title":"Protobuf"},{"content":"面向对象程序设计基础 目录 [TOC]\n在大一的程设课上，我们系统学习了C++的语法，掌握了一些编写小型程序的技能。实际上，要想写出一个可读性好、可复用、鲁棒性强的程序，掌握一些基本的设计原则是十分必要的。\n本讲的内容并不针对具体的某一语言，而且相比之前的一些内容，本讲的知识更需要在长期的实践中“内化”；与此同时，与软件工程相关的理论博大精深，本讲仅仅挑选一些代表性的原则，只能带领大家入门，想要了解更多还需要仔细阅读文末提供的书单~\nKISS KISS代表着“Keep It Simple and Stupid”。KISS原则指出，简单性应该是软件开发的主要目标，应该避免不必要的复杂性。\n不过，如何界定“简单”？KISS原则指出，为了保证代码的灵活性和可扩展性，我们可能不得不增加代码的复杂度。但除此之外，在这种问题固有复杂性的基础之上增加自制的复杂性，是十分不明智的做法——程序并非程序员炫技的场所，而应该是一件简约的艺术品。\n一言以概之：如无必要，勿增实体。\nLoose Coupling⭐ Loose Coupling，即松耦合原则。这一原则指出：模块与模块之间的耦合（即相互关联的程度）应该越小越好，或者说，它们应该尽可能少地感知到对方的存在。\n举一个例子吧（本例选自 Clean C++ 一书）：\n考虑你有一台电灯，和一个用于控制电灯的开关：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  class Lamp { public: void on() { } void off() { } } class Switch { public: Switch(Lamp\u0026amp; lamp): lamp(lamp) {} void toggle() { if (state) { state = false; lamp.off(); } else { state = true; lamp.on(); } } }   在这样的设计方法下，开关可以工作，但可能会带来一个问题：Switch类中包含了Lamp类的引用，Switch类与Lamp类之间存在着强耦合关系——Switch类可以感知到Lamp类的存在。\n这种写法不仅不符合常理，而且不便于维护和扩展：试想，如果我们想要用开关控制电扇、充电器等其它电器该怎么办？难道我们需要分别设计SwitchForLamp、SwitchForFan、SwitchForCharger类吗？\n如何解决这类耦合问题？一个方法是：将两个类之间相关联的部分抽象成一个接口（interface），第二个类此时不需要包含第一个类的实例或引用，而只需要对接口负责，从而降低耦合度，提高程序的可扩展性。\n以上程序可以改写如下（在C++中，接口可以使用虚基类实现）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  #include \u0026lt;iostream\u0026gt; class Switchable { public: virtual void on() = 0; virtual void off() = 0; }; class Switch { public: Switch(Switchable\u0026amp; switchable) : Switchable(switchable) {} void toggle() { if (state) { state = false; switchable.off(); } else { state = true; switchable.on(); } } private: Switchable\u0026amp; switchable; bool state {false}; }; class Lamp: public Switchable { public: void on() override { std::cout \u0026lt;\u0026lt; \u0026#34;Lamp is on!\u0026#34; \u0026lt;\u0026lt; std::endl; } void off() override { std::cout \u0026lt;\u0026lt; \u0026#34;Lamp is off!\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class Fan: public Switchable { public: void on() override { std::cout \u0026lt;\u0026lt; \u0026#34;Fan is on!\u0026#34; \u0026lt;\u0026lt; std::endl; } void off() override { std::cout \u0026lt;\u0026lt; \u0026#34;Fan is off!\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { Lamp lamp; Switch switch1(lamp); switch1.toggle(); switch1.toggle(); Fan fan; Switch switch2(fan); switch2.toggle(); switch2.toggle(); }   在以上更改中，开关与其它电器耦合的部分被抽象为一个接口Switchable，开关只需要对这一接口进行操作，避免了开关与具体电器类的耦合。\nSOLID⭐ SOLID是以下五大面向对象设计原则的缩写：\n 单一功能原则（Single Responsibility Principle，SRP） 开闭原则（Open Closed Principle，OCP） 里氏替换原则（Liskov Substitution Principle，LSP） 接口隔离原则（Interface Segregation Principle，ISP） 依赖反转原则（Dependency Inversion Principle，DIP）。  单一功能原则 单一功能原则指出，每个软件单元（类、函数等），应该只有一个单一的、定义明确的责任。\n如何界定单一责任？一个比较普适的定义是，改变该软件单元只能有一个原因。如果有多个原因，那么该单元就应该拆分。\n开闭原则 开闭原则指出，软件单元（类、函数等）应该对于扩展是开放的，但是对于修改是封闭的。\n具体来讲，如果我们需要给一个软件添加新的功能，我们通常不建议修改源码，而更加建议通过继承的方式。\n里氏替换原则⭐ 里氏原则指出，派生类（子类）对象可以在程序中代替其基类（超类）对象。\n换句话说，一个软件实体如果使用的是一个父类，那么也一定适用于其子类——把一个软件里面的父类都替换为它的子类，程序的行为是不会发生变化的。\n利用这一原则，我们可以判断类与类之间的继承关系是否合适。\n举个例子，假设我们拥有一个矩形类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  class Rectangle { public: Rectangle(int width, int height) : width(width), height(height) {} void setWidth(int width) { this-\u0026gt;width = width; } void setHeight(int height) { this-\u0026gt;height = height; } void setEdges(int width, int height) { this-\u0026gt;width = width; this-\u0026gt;height = height; } private: int width; int height; };   我们想要再新建立一个正方形类。根据初中几何知识：正方形是一种特殊的矩形——因此一种直观的想法是：让正方形类去继承矩形类：\n1 2 3 4  class Square: public Rectangle { // ... };   但如果站在里氏替换原则的角度来看，这一设计是不科学的！比如我们考虑以下操作：\n1 2 3  Rectangle rectangle; rectangle.setHeight(20); rectangle.setEdges(10, 5);   根据里氏替换原则，派生类对象（Square）一定可以替换基类对象（Rectangle），假如我们进行这一替换：\n1 2 3  Square square; square.setHeight(20); square.setEdges(10, 5);   这时就出现了问题：\n 第一个操作会产生歧义：该操作是只改变正方形的宽（这样会违背正方形的定义），还是同时改变正方形的长和宽（这样违背函数的字面意思）。 第二个操作则会直接违背正方形的定义。  可以看到，派生类对象在此处替换基类对象会产生很多问题，这一继承是不科学的！\n接口隔离原则⭐ 接口隔离原则指出，程序员在设计接口时应当将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法——使用多个专门的接口比使用单一的总接口要好。\n换句话讲，接口约束了类的行为，是一种减轻代码耦合程度的好方法。但如果一个接口太过宽泛，可能会带来一些不必要的麻烦。举例说明：\n我们想要定义一个“鸟”接口：\n1 2 3 4 5 6 7  class Bird { public: virtual void eat() = 0; virtual void breathe() = 0; virtual void fly() = 0; };   在此基础上实现一个鸽子类，现在一切看上去都正常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Pigeon: public Bird { public: virtual void eat() override { // ...  } virtual void breathe() override { // ...  } virtual void fly() override { // ...  } };   我们再实现一个企鹅类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Penguin: public Bird { public: virtual void eat() override { // ...  } virtual void breathe() override { // ...  } virtual void fly() override { // ???  } };   问题发生了。我们在一开始设计“鸟”这一接口时，想当然地以为所有地鸟类都会飞，却忽略了企鹅不会飞这一特例。\n为了避免这样的情况发生，我们需要小心地将接口拆分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  class Lifeform { public: virtual void eat() = 0; virtual void breathe() = 0; }; class Flyable { public: virtual void fly() = 0; }; class Pigeon: public Lifeform, public Flyable { public: void eat() override { // ...  } void breathe() override { // ...  } void fly() override { // ...  } }; class Penguin: public Lifeform { public: void eat() override { // ...  } void breathe() override { // ...  } };   如上文所示，所有的鸟类都需要呼吸和进食，我们可以大胆地将其封装为Lifeform接口，而并非所有鸟类都会飞，所以需要将其单独提取出来作为Flyable接口。在实现不同的鸟类时，我们将这些接口进行筛选组合即可。\n依赖倒转原则⭐ 依赖倒转原则指出，在实际的开发场景中，类与类之间的依赖关系是十分复杂，在设计依赖关系时，高层模块不应该依赖低层模块，二者都应该依赖其抽象。\n什么意思呢？考虑以下实例，一个用户在某在线网络平台上拥有一个账户，而这个账户又存储着该用户的信息。由此，两者不可避免地产生了下列的循环依赖关系——你中有我，我中有你：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class Account; class Customer { public: // ...  void setAccount(Account *account) { customerAccount = account; } // ... private: Account *customerAccount; }; class Account { public: void setOwner(Customer *customer) { owner = customer; } private: Customer *owner; }; int main() { Account* account = new Account { }; Customer* customer = new Customer { }; account-\u0026gt;setOwner(customer); customer-\u0026gt;setAccount(account); }   这会导致很严重的问题：首先代码的可读性由于循环依赖下降，而且两者的生命周期不相互独立——如果Account对象的生命周期先于Customer对象结束，Customer对象中将会产生一个空指针，调用Customer对象中的成员函数可能会导致程序崩溃。\n而依赖倒转原则为解决此类问题提供了一套流程：\n 不允许两个类中的其中一个直接访问另一个类，要想进行这种访问操作，需要通过接口。 实现这个接口。  在本例中，我们不再使得Account类中包含有Customer类的指针，所有Account类需要访问Customer类的行为，都被定义进一个叫做Owner的接口中，而后，Customer类需要实现这个接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt; class Owner { public: virtual std::string getName() = 0; }; class Account; class Customer : public Owner { public: void setAccount(Account* account) { customerAccount = account; } virtual std::string getName() override { // return the Customer\u0026#39;s name here...  } // ... private: Account* customerAccount; // ... }; class Account { public: void setOwner(Owner* owner) { this-\u0026gt;owner = owner; } //... private: Owner* owner; };   经过修改之后，Account类将不依赖于Customer类。\n设计模式⭐ C++、C#、Python等语言为实现继承、多态等面向对象特性提供了丰富的语法。那么在具体的软件工程中，又该如何使用这些特性呢？这就是设计模式。设计模式是上述SOLID原则在软件工程中的具体体现。\n设计模式共计分为3大类22小类：\n  创建型模式提供创建对象的机制， 增加已有代码的灵活性和可复用性。\n  结构型模式介绍如何将对象和类组装成较大的结构， 并同时保持结构的灵活和高效。\n  行为模式负责对象间的高效沟通和职责委派。\n  不同的设计模式之间有着相似的理念和重叠之处。合理利用设计模式可以让代码更加规范、更容易维护，但盲目使用设计模式也不是明智之举。\n本讲将介绍一个难度较大，而且应用较为广泛的设计模式——桥接模式（属于结构型模式）。\n桥接模式的定义如下：桥接模式是将类抽象部分与实现部分分离，使它们都可以独立地变化。\n什么是抽象部分？什么是实现部分？让我们先考虑以下场景：一家奶茶店售卖不同种类的奶茶，奶茶既有不同的容量，也有不同的口味。如果我们只需要改变奶茶的容量，可以做出如下设计：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class IMilkTea // 通用接口 { virtual void order() = 0; }; class MilkTeaSmallCup: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: small cup\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaMediumCup: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: medium cup\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaLargeCup: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: large cup\u0026#34; \u0026lt;\u0026lt; std::endl; } };   当类的变化只有一个维度时，继承的思路是比较直接而简单的。但当我们将“口味”也加入继承体系中，也就是当类的变化有两个维度时，沿用上面的思路将会使得类的数量急剧增长：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class MilkTeaSmallCupFairyGrass: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: small cup\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;flavor: fairy grass\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaSmallCupPearl: public IMilkTea { void order() override { std::cout \u0026lt;\u0026lt; \u0026#34;order info:\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;size: small cup\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;flavor: pearl\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // class MilkTeaMediumCupPearl, class MilkTeaLargeCupFairyGrass, ...   问题的根源在于，我们试图在两个独立的维度（“容量”和“口味”）上扩展奶茶类。这时候，桥接模式就派上了用场：我们将容量视为抽象部分，将口味视为实现部分，并将两者桥接。\n “抽象部分”和“实现部分”所承担的角色：\n 抽象部分：抽象化给出的定义，只提供高层控制逻辑，依赖于完成底层实际工作的实现对象。抽象部分保存一个对实现化对象的引用（指针）。 实现部分：给出实现化角色的通用接口，抽象部分仅能通过在这里声明的方法与实现对象交互。   例如在本例中，可以做如下修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  // 实现化部分 class IMilkTeaFlavorBase { public: virtual void GetFlavor() = 0; }; class MilkTeaPearl: public IMilkTeaFlavorBase { public: void GetFlavor() override { std::cout \u0026lt;\u0026lt; \u0026#34;flavor: pearl\u0026#34; \u0026lt;\u0026lt; std::endl; } }; class MilkTeaFairyGrass: public IMilkTeaFlavorBase { public: void GetFlavor() override { std::cout \u0026lt;\u0026lt; \u0026#34;flavor: fairy grass\u0026#34; \u0026lt;\u0026lt; std::endl; } }; // 抽象化部分 class IMilkTeaSizeBase { public: virtual void SetFlavor(std::shared_ptr\u0026lt;IMilkTeaFlavorBase\u0026gt; flavorBase) { this-\u0026gt;flavorBase = flavorBase; } virtual void Order() = 0; protected: std::shared_ptr\u0026lt;IMilkTeaFlavorBase\u0026gt; flavorBase; }; class MilkTeaSmall: public IMilkTeaSizeBase { public: void Order() override { std::cout \u0026lt;\u0026lt; \u0026#34;size: small\u0026#34; \u0026lt;\u0026lt; std::endl; flavorBase-\u0026gt;GetFlavor(); } }; class MilkTeaMedium: public IMilkTeaSizeBase { public: void Order() override { std::cout \u0026lt;\u0026lt; \u0026#34;size: medium\u0026#34; \u0026lt;\u0026lt; std::endl; flavorBase-\u0026gt;GetFlavor(); } }; class MilkTeaLarge: public IMilkTeaSizeBase { public: void Order() override { std::cout \u0026lt;\u0026lt; \u0026#34;size: large\u0026#34; \u0026lt;\u0026lt; std::endl; flavorBase-\u0026gt;GetFlavor(); } }; // 使用方法 int main() { // 大杯烧仙草  std::shared_ptr\u0026lt;MilkTeaFairyGrass\u0026gt; milkTeaFairyGrass = std::make_shared\u0026lt;MilkTeaFairyGrass\u0026gt;(); std::shared_ptr\u0026lt;MilkTeaLarge\u0026gt; milkTeaLargeWithFairyGrass = std::make_shared\u0026lt;MilkTeaLarge\u0026gt;(); milkTeaLargeWithFairyGrass-\u0026gt;SetFlavor(milkTeaFairyGrass); milkTeaLargeWithFairyGrass-\u0026gt;Order(); }   可以在上述示例中看到：抽象部分各类中，都含有一个实现部分的指针。如果需要访问实现部分的方法，可以通过该指针进行访问。这样，我们就通过桥接的方式分离了两个不同的维度，使得类的可扩展性更好。\n由于篇幅所限，我们在此处不能对设计模式进行一一介绍，感兴趣的同学可以参考文末给出的阅读清单进行学习。\n参考文献和荐读清单 Refactoring.Guru 该网站详细介绍了各设计模式的特点，并提供了不同编程语言的实例。\nClean C++ 这本书的侧重点不在介绍C++语法，而侧重于使用C++语言介绍如何写出可读性强、符合面向对象规范的程序，强推！\n","date":"2022-06-20T20:07:09+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/oop/","title":"面向对象程序设计基础"},{"content":"gRPC 无03 王与进\n目录 [TOC]\n前言 在介绍gRPC之前，我们需要先介绍几个在通信中需要用到的概念。\nClient-Server model:star: Client-Server结构是一种经典的通信模型。它通常采取两层结构：\n 服务器（Server）负责数据的处理。它有以下特征：  等待来自客户端的请求 处理请求并传回结果   客户端（Client）负责完成与用户的交互任务。它有以下特征：  发送请求 等待直到收到响应    THUAI5就是一个应用了Client-Server model的典型实例：\n在游戏中，玩家通过在Client端编写C++代码来制定游戏策略，而Server端由Csharp语言写成，用于分析处理游戏逻辑。编译生成的Client端可执行文件将向Server端发送请求，请求处理完毕后Server端再向Client端发送处理后的结果，这样Client端就可以接受到游戏实况，以供下一步决策。\nIP Address IP Address(Internet Protocol address，网际协议地址)，是网际协议中用于标识发送或接受数据报的设备的一串数字。\n当设备连接网络后，设备将被分配一个IP地址，对于一个具体的设备而言，IP地址是独一无二的。IP地址有两个主要的功能：标识主机（用户在互联网上可以识别）和网络寻址（允许计算机通过互联网发送和接受数据）。\n常见的IP地址分为IPv4和IPv6两大类：\n  IPv4：32位长，通常书写时以四组十进制数字组成，并以点分割，例如：172.16.254.1。\n  IPv6：128位长，通常书写时以八组十六进制数字组成，并以冒号分割，例如：\n2001:db8:0:1234:0:567:8:1。\n  我们可以使用如下方法查询本机的IP地址：\n windows：ipconfig linux：ifconfig（可能需要使用sudo apt-get install net-tools进行安装）   一个特殊的IP地址：127.0.0.1\n尽管现在有大量可用的 IP 地址，但为了防止编程冲突的特定目的，刻意保留一些地址，甚至是地址范围是很方便的。\n127.0.0.1就是其中一个。它表示的是主机环回地址，表示的是任何数据包都不应该离开计算机，计算机本身即为接收者。\n当我们需要在本地测试一些网站服务，或者只想在本地设备上运行只有本地设备可以访问的服务，就可以使用127.0.0.1。\n Port Port(端口)在电脑网络中是一种经过软件创建的服务，在一个电脑的操作系统中扮演通信的端点。\n什么意思呢？利用IP地址，可以实现不同计算机之间的通信。但实际上，计算机中是运行着多个进程的——当不同的信息被传入计算机后，计算机需要一种手段来区分信息的接收者，以将不同进程的处理结果正确地发送给接收者。\n这个时候，端口就派上了用场。如果我们在通信时不仅指定IP地址，而且指定端口，计算机就可以正确地将不同的请求交给正确的进程处理。\n特定的服务一般对应于特定的端口，详见端口列表。\n我们可以使用如下方法查看本机的端口使用情况：\n windows：netstat -ano| findstr \u0026quot;\u0026lt;port\u0026gt;\u0026quot; linux：netstat -tunlp | grep \u0026lt;port\u0026gt;或lsof -i:\u0026lt;port\u0026gt;  gRPC概况 gRPC的全称是gRPC Remote Procedure Calls。其中“Remote Procedure Calls”翻译为“远程过程调用”。“远程过程调用”指的是客户端（Client）可以像调用本地对象一样直接调用服务端（Server）应用的方法。具体过程如下：\n 定义若干服务（Service），指定其能够被远程调用的方法（包含参数和返回类型）。这些定义都写在.proto文件里。 在服务端（Server）实现这个接口（内部处理逻辑），并运行gRPC服务器，来处理客户端的调用。 在客户端（Client）建立一个存根（stub），提供与服务端相同的方法。  下面的图形象地展示了gRPC的使用过程：\n这样一来，用户在使用gRPC构建的应用程序时，不需要关心调用方法的内部逻辑（被封装在Server中），只需要调用Client端提供的方法向Server端提供请求，等待Server端返回结果即可——看上去就和在Client端本地调用方法一样。\ngRPC有诸多优点：\n 速度快：gRPC使用protobuf进行Server/Client之间数据的序列化和反序列化，保证了通信的高效。 跨语言：构建Server端和Client端程序的源语言无需一致。 跨平台：Server端和Client端的平台无需一致。  我们仍然THUAI5为例，阐述gRPC在构建具体项目中的意义（注：虽然THUIA5中使用的通信方法并非gRPC，但gRPC对我们的设计仍然有着重大的借鉴意义）：\n Server端需要实现复杂的游戏逻辑，而且需要支持Unity，如果使用C++语言可能会导致开发效率太低，因此需要使用Csharp语言进行开发。 Client端需要提供选手接口供选手编写AI代码，因此需要使用C++语言开发。  两者使用语言不同，如何使得两者建立联系？我们可以使用gRPC的思路：\n 在.proto文件中定义选手可以调用的游戏方法（如人物操作和获取物品信息）。 在Server端实现这些接口的内部逻辑。 在Client端提供用户需要直接调用的方法，而无需关心其具体实现。  于是我们就实现了Server和Client的解耦。在此基础上，我们甚至可以提供不同种类语言的用户接口——你可以使用Python、Java或其它语言来编写你的游戏策略。\ngRPC安装 C++ 安装gRPC C++相关的库需要手动编译其源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  $ git clone -b v1.46.3 --depth 1 --shallow-submodules https://github.com/grpc/grpc # 如果网络不佳，可以将网址换为 https://gitee.com/mirrors/grpc.git $ cd grpc $ git submodule update --init --recursive # 在grpc的原文档中没有submodule该步，但笔者实测，如果没有这一步grpc将无法安装。 $ mkdir -p cmake/build $ pushd cmake/build $ cmake -DgRPC_INSTALL=ON \\  -DgRPC_BUILD_TESTS=OFF \\  ../.. $ make -j $ make install # 或 sudo make install $ popd    需要指出的是，由于网络等问题，git submodule update --init --recursive一步往往无法正常运行。为此可以点击此处下载third_party.tar.gz，并将git submodule..一步替换为以下操作：\n1 2 3 4  $ rm -rf third_party $ mv \u0026lt;tar_gz_path\u0026gt; . $ tar -zxvf third_party.tar.gz $ cd ..    Csharp Csharp中，我们可以使用NuGet程序包安装gRPC库（图中第一项）。\ngRPC服务:star: grpc默认使用protobuf作为接口定义语言。定义方式见下例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // The greeter service definition. service Greeter { // Sends a greeting  rpc SayHello (HelloRequest) returns (HelloReply);}// The request message containing the user\u0026#39;s name. message HelloRequest { string name = 1;}// The response message containing the greetings message HelloReply { string reply = 1;}  定义服务使用了service和rpc关键字。粗略地来讲，在本例中，gRPC服务接受一条含有name字段的HelloRequest message，发送给服务端处理后，返回一条含有reply字段的HelloRequest message。\ngRPC可以定义以下4种服务：\n 单一RPC（Unary RPCs），客户端向服务器发送一个请求，并得到一个响应，就像一个正常的函数调用。简单来讲就是一个请求对象对应一个返回对象。  1  rpc SayHello(HelloRequest) returns (HelloResponse);   服务器流式RPC（Server streaming RPCs），客户端向服务器发送请求，并获得一个流来读回一连串的消息。客户端从返回的流中读取信息，直到没有更多的信息。gRPC保证在单个RPC调用中的信息排序。简单来讲就是发送一个请求对象，服务端可以传回多个结果对象。  1  rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse);   客户端流式RPC（Client streaming RPCs），客户端写了一串消息并将它们发送给服务器，同样使用一个提供的流。一旦客户端完成了消息的写入，它就等待服务器读取它们并返回其响应。gRPC再次保证了单个RPC调用中的消息排序。简单来讲就是客户端传入多个请求对象，服务端返回一个响应结果。  1  rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse);   双向流RPC（Bidirectional streaming RPCs），双方使用读写流发送一连串的消息。这两个流独立运行，因此客户和服务器可以按照他们喜欢的顺序进行读写：例如，服务器可以等待收到所有客户的消息，然后再写它的响应，或者它可以交替地读一个消息，然后再写一个消息，或者其他一些读和写的组合。每个流中的消息的顺序被保留下来。简单来讲就是结合客户端流式rpc和服务端流式rpc，可以传入多个对象，返回多个响应对象。  1  rpc BidiHello(stream HelloRequest) returns (stream HelloResponse);  接下来我们将结合一些实例进一步了解它们的使用方法和区别。\ngRPC使用:star: 在本例中，我们将使用Csharp语言实现一个简单的Client-Server模型——Client端提供两个数和一个操作符，而Server端则进行具体的运算过程并将计算结果返回给Client端。\nproto 我们不妨考虑以下服务场景：\n 客户端发送一个包含两个操作数和一个运算符的元组，服务端返回一个结果：该场景符合单一RPC。 客户端发送一个包含两个操作数和一个运算符的元组，服务端返回计算结果，并将该结果重复多次：该场景符合服务器流式RPC。 客户端发送若干个包含两个操作数和一个运算符的元组，服务端返回计算结果之和：该场景符合客户端流式RPC。 客户端发送若干个包含两个操作数和一个运算符的元组，服务端分别返回每一对元组的计算结果之和：该场景符合双向流RPC。  我们需要在Message.proto文件中定义需要提供的服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  syntax = \u0026#34;proto3\u0026#34;;package hello;enum Operator { NONE_OP = 0; ADD = 1; SUB = 2; MUL = 3;}message Operand { int32 op1 = 1; int32 op2 = 2; Operator opr = 3;}message Result { int32 val = 1;}service Calculator { // Unary  rpc UnaryCall (Operand) returns (Result); // Server streaming  rpc StreamingFromServer (Operand) returns (stream Result); // Client streaming  rpc StreamingFromClient (stream Operand) returns (Result); // Bi-directional streaming  rpc StreamingBothWays (stream Operand) returns (stream Result);}  之后就可以使用该文件生成对应的CSharp文件以供使用。\nServer Server端有两个任务：\n 实现我们服务定义的生成的服务接口：做我们的服务的实际的“工作”。 运行一个 gRPC 服务器，监听来自客户端的请求并返回服务的响应。  为了实现这些目的，我们需要在Server端定义一个CalculatorImpl类，并继承Calculator.CalculatorBase类，以实现所有的服务方法。\n 对于Calculator.CalculatorBase类的解释：Base class for server-side implementations of Calculator。可见它是专供Server端使用的一个基类。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  class CalculatorImpl : Calculator.CalculatorBase { public override Task\u0026lt;Result\u0026gt; UnaryCall(Operand operand, ServerCallContext context) { var res = new Result(); switch (operand.Opr) { case Operator.Add: res.Val = operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val = operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val = operand.Op1 * operand.Op2; break; default: break; } return Task.FromResult(res); } public override async Task StreamingFromServer(Operand operand, IServerStreamWriter\u0026lt;Result\u0026gt; result_stream, ServerCallContext context) { var res = new Result(); switch (operand.Opr) { case Operator.Add: res.Val = operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val = operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val = operand.Op1 * operand.Op2; break; default: break; } for (var i = 0; i \u0026lt; 3; i++) { await result_stream.WriteAsync(res); } } public override async Task\u0026lt;Result\u0026gt; StreamingFromClient(IAsyncStreamReader\u0026lt;Operand\u0026gt; operand_stream, ServerCallContext context) { var res = new Result(); while (await operand_stream.MoveNext()) { var operand = operand_stream.Current; switch (operand.Opr) { case Operator.Add: res.Val += operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val += operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val += operand.Op1 * operand.Op2; break; default: break; } } return res; } public override async Task StreamingBothWays(IAsyncStreamReader\u0026lt;Operand\u0026gt; operand_stream, IServerStreamWriter\u0026lt;Result\u0026gt; result_stream, ServerCallContext context) { while (await operand_stream.MoveNext()) { Operand operand = operand_stream.Current; var res = new Result(); switch (operand.Opr) { case Operator.Add: res.Val = operand.Op1 + operand.Op2; break; case Operator.Sub: res.Val = operand.Op1 - operand.Op2; break; case Operator.Mul: res.Val = operand.Op1 * operand.Op2; break; default: break; } await result_stream.WriteAsync(res); } } }   我们来看上方的代码的特点：\n 为了允许任务的异步执行，我们在返回值中使用Task关键字。 在服务器流式RPC中，我们需要使用异步方法WriteAsync将服务器的响应写入异步流IServerStreamWriter中。 在客户端流式RPC中，我们需要使用异步流IAsyncStreamReader逐个读出请求并进行运算。 在双向流式RPC中，我们需要同时使用IAsyncStreamReader和IServerStreamWriter。  而启用gRPC服务器的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public static void Main() { try { // 禁止复用端口！！！（SoReuseport 置为 0） Grpc.Core.Server server = new Grpc.Core.Server(new[] { new ChannelOption(ChannelOptions.SoReuseport, 0) }) { Services = { Calculator.BindService(new CalculatorImpl()) }, Ports = { new ServerPort(\u0026#34;127.0.0.1\u0026#34;, 8888, ServerCredentials.Insecure) } }; // 建立监听特定IP地址和端口Server的模板代码 server.Start(); Console.WriteLine(\u0026#34;Server begins to listen!\u0026#34;); Console.WriteLine(\u0026#34;Press any key to stop the server...\u0026#34;); Console.ReadKey(); Console.WriteLine(\u0026#34;Server end!\u0026#34;); server.ShutdownAsync().Wait(); } catch (Exception ex) { Console.WriteLine(ex.ToString()); } }   我们总结一下创建客户端的步骤：\n 创建 Grpc.Core.Server 的一个实例。 创建我们的服务实现类 CalculatorImpl 的一个实例。 通过在 Services 集合中添加服务的定义注册我们的服务实现。 指定想要接受客户端请求的地址和监听的端口。通过往 Ports 集合中添加 ServerPort 即可完成。 在服务器实例上调用 Start 为我们的服务启动一个 RPC 服务器。  Client 首先，我们需要建立一个Client对象：\n1 2 3  Channel channel = new Channel(\u0026#34;127.0.0.1:8888\u0026#34;, ChannelCredentials.Insecure); var client = new Calculator.CalculatorClient(channel); // 建立一个连接到特定host的client // ... Client 的调用操作   在调用单一RPC服务时，我们像调用本地方法那样调用远程方法（UnaryCall），如果RPC成功完成，则返回响应值。\n1 2 3 4 5  // case 1: unary call（单一RPC） Console.WriteLine(\u0026#34;case 1:\u0026#34;); var unaryCall = client.UnaryCall(operand0); //  var unaryCallVal = unaryCall.Val; Console.WriteLine(unaryCallVal);   在调用服务器流式RPC服务时，由于得到的响应是流式的，所以我们需要使用MoveNext方法逐个读取其值。\n1 2 3 4 5 6 7 8  // case 2: streaming from server（服务器流式RPC） Console.WriteLine(\u0026#34;case 2:\u0026#34;); var streamingFromServer = client.StreamingFromServer(operand0); while(await streamingFromServer.ResponseStream.MoveNext()) { var streamingFromServerVal = streamingFromServer.ResponseStream.Current.Val; Console.WriteLine(streamingFromServerVal); }   在调用客户端流式RPC服务时，我们需要使用WriteAsync方法逐个写入请求值，最终使用CompleteAsync方法表示不再请求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  // case 3: streaming from client（客户端流式RPC） Console.WriteLine(\u0026#34;case 3:\u0026#34;); var streamingFromClient = client.StreamingFromClient(); Tuple\u0026lt;int, int, Operator\u0026gt;[] tups = { new(1, 1, Operator.Add), new(5, 6, Operator.Mul), new(3, 4, Operator.Sub), new(0, 0, Operator.NoneOp) }; foreach (var tup in tups) { Operand operand = new Operand(); operand.Op1 = tup.Item1; operand.Op2 = tup.Item2; operand.Opr = tup.Item3; await streamingFromClient.RequestStream.WriteAsync(operand); } await streamingFromClient.RequestStream.CompleteAsync(); var streamingFromClientVal = streamingFromClient.ResponseAsync.Result.Val; Console.WriteLine(streamingFromClientVal);   在调用双向流RPC服务时，我们将请求写入RequestStream，使用ResponseStream获取响应。两者是相互独立的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  // case 4: streaming both ways（双向流RPC） Console.WriteLine(\u0026#34;case 4:\u0026#34;); var streamingBothWays = client.StreamingBothWays(); foreach (var tup in tups) { Operand operand = new Operand(); operand.Op1 = tup.Item1; operand.Op2 = tup.Item2; operand.Opr = tup.Item3; _ = streamingBothWays.RequestStream.WriteAsync(operand); if (!await streamingBothWays.ResponseStream.MoveNext()) { break; } var streamingBothWaysVal = streamingBothWays.ResponseStream.Current.Val; Console.WriteLine(streamingBothWaysVal); }   运行结果如下：\n参考与荐读 由于时间所限，有很多有趣的内容我们没有涉及：\n 计算机网络模型 RPC的生命周期 在gRPC中使用安全认证和通讯协议 \u0026hellip;  略过上述内容不会对我们的教学产生太大影响，感兴趣的同学可以参考以下文档和资源：\n 计算机网络——自顶向下方法 Stanford CS144 gRPC 官方文档  ","date":"2022-06-20T19:55:32+08:00","permalink":"https://ther-nullptr.github.io/posts/programming/grpc/","title":"grpc"},{"content":"chapter 1 是谁把这些星星撒过天空\n像闪光的尘埃\n像发光的云\n他们将乳白色的光芒\n倒入深黑色的碗中\nWho spilled those stars across the sky\nlike sparkling dust\nlike clouds of light?\nThey pour their milky shine\ninto the deep black bowl\nchapter 2 我是我所行走的世界\n我所见所闻所感都来自我自己\nI was the world in which I walked\nand what I saw or heard or felt\ncame not but from myself\nchapter 3 大理石永久幻化成一个灵魂\n孤独地航行在陌生的\n思想海洋中\nThe marble index of a mind forever\nVoyaging through strange seas of thought, alone\nchapter 4 现在我用沉静的目光见到\n恰是那台机器脉冲的颤跳\nAnd now I see with eye serene\nThe very pulse of the machine\n","date":"2022-06-19T20:55:58+08:00","image":"https://ther-nullptr.github.io/posts/ldr/LDR_hu8eb093704b9dd0a9c9f2f554fd593af3_2854661_120x120_fill_q75_box_smart1.jpg","permalink":"https://ther-nullptr.github.io/posts/ldr/","title":"Love Death Robots"},{"content":"  打开wsl，输入以下指令：\n1  $ VSCODE_WSL_DEBUG_INFO=true code .   此时terminal会输出调试信息：\n此时所执行的脚本路径为~//.vscode//extensions//ms-vscode-remote.remote-wsl-0.xx.x//scripts//wslDownload.sh(On Windows)。定位程序发生卡死的位置：\n将该程序的第110行（或临近位置，带tar的那行）删掉：\n手动下载，并解压该文件，将其名称改为其SHA-1值。然后移动到~/.vscode-server/bin/中：\n成功解决！\n  ","date":"2022-06-19T19:10:59+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/wsl_remote/","title":"解决VSCode更新后无法启动Remote WSL的问题"},{"content":"Q 现实世界或许不坏，可是我讨厌自己。\nA 你认为现实不好，所以心生厌恶。\nA 是你的内心把现实和真实对调了。\nA 只要看现实的角度和切入点稍有不同，心里就会有很大的变化。\nA 有多少种人就有多少种真实。\nA 但是，你自己的真实只有一个。它由狭义的世界观而生，是为了保护自己而修改过的信息。是被歪曲过的真实。\nA 不过仅有一个人所持的世界观是微不足道的。\nA 可是人只能用自己渺小的基准来测量事物，只愿意用别人给予的真实去看待事物。\nA 晴天使人快乐，雨天使人忧郁，被人这样教导之后就深信不疑。\nA 雨天也会有快乐的事，接受的方式不同就会产生完全不同的结果。人内心的真实，还真是脆弱啊。\nA 人的真实不过仅此而已，所以才会想要知道更深层的真实。\nA 只是，你不习惯被人喜欢罢了。\nA 所以你没有必要总是看别人的脸色。\nQ 但，大家不是都讨厌我吗？\nA 你是笨蛋吗？这只是你自己钻牛角尖而已。\nQ 可是，我讨厌自己。\nA 讨厌自己的人是无法喜欢和信赖他人的。\nQ 我悲怯，胆小，狡猾，懦弱。\nA 理解自己后，就可以对自己温柔一点了吧。\nQ 我讨厌自己，不过，也有可能会喜欢上自己。或许，我可以呆在这里。没错，我就是我自己。我就是我，我想做自己，我想呆在这里，我可以呆在这里！\n","date":"2022-06-19T19:09:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/eva2/","title":"每日一遍"},{"content":"CMake \u0026amp; Makefile makefile\nCMake\ncpp Standard C++ Programming\nNetwork Computer Network\nsystem CSAPP\nSafety in Systems Programming\nsoftware engineering software engineering\nother IAP\n","date":"2022-06-16T18:55:51+08:00","permalink":"https://ther-nullptr.github.io/posts/resource/cs_course/","title":"CS course"},{"content":" 给您跪了。\n 自己的负面情绪，真的已经外溢到如此严重的地步了吗？\n或者说，这种网抑云式的生活状态，本身就是不可理喻的吗？\n","date":"2022-06-15T23:59:43+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/%E6%97%A0%E9%A2%98/","title":"外溢"},{"content":"优秀stack站点记录 zhixuan\u0026rsquo;s Blog\n相忘于江湖\nHome\n一笼虾饺有四个\n","date":"2022-06-15T00:24:11+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/websites/","title":"Websites"},{"content":"多周期CPU 多周期数据通路     R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; ALUOut\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2)) * * *   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) if (A=B)PC\u0026lt;=ALUOut PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   MEM Reg[IR[15:11]]\u0026lt;=ALUOut Lw:MDR\u0026lt;=MemData[ALUOut];Sw:MemData[ALUout] \u0026lt;=B     WB  Reg[IR[20:16]]\u0026lt;=MDR      重点控制信号的周期：\n IRWrite：在Instruction fench阶段被置为1，但在lw的Memory access阶段被置为0，因为在lw的Register writeback阶段，Instruction Register不能再更新，如果更新的话，会被读出的数据覆盖。 MemRead：在Instruction fench阶段被置为1（用于读取指令），在Instruction decode阶段为0，在lw的Memory access阶段被置为1。 MemWrite：默认0，在sw的Memory access阶段被置为1。 ALUSrc1：在Instruction fench阶段为00（PC），在Execution阶段根据实际情况修改。 ALUSrc2：在Instruction fench阶段为01（4），在Instruction decode阶段为11（imm\u0026laquo;2），在Execution阶段根据实际情况修改。 PCWrite：在Instruction fench阶段为1（PC\u0026lt;=PC+4），在Instruction decode阶段为0，此后若执行跳转类指令则被置为1。 PCSource：默认为00（PC\u0026lt;=PC+4），在Execution阶段视情况改变。 IorD：默认0（取指令），在Memory access阶段被置为1。 PCWriteCond：在beq的Execution阶段被置为1。 MemtoReg：默认00。 RegDst：默认00。 RegWrite：默认0，在jal和jalr以及Register writeback中被置为1。 ExtOp：在Instruction decode阶段被置为1，因为需要算跳转地址。 ALUOp：在Instruction fench和Instruction decode均为00，因为需要执行加法操作；R type被置为10，beq被置为01。  多周期异常和中断处理 异常指内部不可预知事件（溢出，同步），中断指外部不可预知事件（I/O，异步）。\n简单起见，假设我们需要处理两种异常：1)未定义指令的执行 2)算术溢出，异常处理程序的入口为0x80000180。\n我们需要添加2个寄存器：\n EPC Register：保存受影响的指令的地址。注意写入EPC的地址应该为PC-4。 Cause Register：记录产生异常事件原因。此处0为未定义指令，1为算术溢出。  4个控制信号：\n EPCWrite：EPC写入使能，在触发异常/中断时被置为1。 CauseWrite：Cause写入使能。 PCSource：增加0x80000180。 IntCause：异常原因选择信号。  异常处理的步骤大致如下：\n  异常检测。通过检测 ALU 的溢出信号，判断是否发生溢出异常。\n  保存现场。在异常程序计数器（Exception Program Counter，EPC）中保存出错的指令地址。\n  跳转到异常处理程序。通过修改程序计数器（PC）的值，使得处理器进入异常处理程序。\n  异常/中断处理程序采取操作，比如可以执行对溢出情况实现定义的一些操作，或者终止程序运行并报告。在异常处理完成后，异常处理程序可以选择终止程序，也可以根据 EPC 存储的指令地址恢复并继续执行程序。\n  ","date":"2022-06-04T11:43:15+08:00","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/multicycle_cpu/","title":"Multicycle CPU"},{"content":"控制信号常见答疑 About Extop https://stackoverflow.com/questions/55290060/what-does-extend-immediate-to-32-bits-mean-in-mips\nI-type instructions with 16-bit immediates are different.\n addi / addiu immediates are sign-extended (by duplicating the top/sign bit of the immediate to all higher bits). https://en.wikipedia.org/wiki/Two%27s_complement#Sign_extension This allows 2\u0026rsquo;s complement numbers from -2^15 .. +2^15-1 to be encoded. (0xFFFF8000 to 0x00007FFF) ori/andi/xori boolean immediates are zero-extended (by setting all higher bits to zero) This allows unsigned / 2\u0026rsquo;s complement numbers from 0 .. 2^16-1 to be encoded. (0x00000000 to 0x0000FFFF)  For other instructions see this [instruction-set reference](https://web.cse.ohio-state.edu/~crawfis.3/cse675-02/Slides/MIPS Instruction Set.pdf) which breaks down each instruction showing 016 || [I15..0] for zero-extension or [I15]16 || [I15..0] for sign-extension.\nAnd usually you don\u0026rsquo;t want to raise an exception on signed overflow, so normally compilers use addu / addiu even on signed integers. addiu is badly named: it\u0026rsquo;s not \u0026ldquo;for unsigned integers\u0026rdquo;, it\u0026rsquo;s just a wrapping-allowed / never-faulting version of add/addi. It sort of makes sense if you think of C, where signed overflow is undefined behaviour (and thus could use add and raise an exception in that case if the compiler wanted to implement it that way), but unsigned integers have well-defined overflow behaviour: base 2 wraparound.\n可以为X的控制信号  控制数据来源的信号（RegDst，MemtoReg）等，不需要用到时可以为X。 控制是否执行某操作（RegWrite）等，必须为0/1。  ","date":"2022-06-04T10:34:25+08:00","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/control_signal/","title":"CPU中的控制信号"},{"content":"处理器 处理器架构  普林斯顿架构：存储器同时存储指令和其他数据 哈佛架构：数据存储和指令存储分开  处理器性能 执行时间 = 指令数 x CPI x 时钟周期\n或： $$ CPI = CPI_1\\times p_1+\u0026hellip;+CPI_n\\times p_n $$ 性能提升方法：\n 优化编译技术（减少指令数） 快速电路技术或更为先进的电路结构（减少时钟周期）  寄存器 VS 存储器  寄存器：以编号进行访问，可同时访问不同寄存器。 存储器：以地址进行访问，不可同时访问不同地址，相邻数据的地址相差4字节。  数据单位约定 在32位MIPS中，1 word = 4 bytes = 32 bits，相邻数据的地址相差4字节。\n1 2 3 4 5 6 7 8 9 10 11  #include\u0026lt;stdio.h\u0026gt;int main() { printf(\u0026#34;%d\\n\u0026#34;,sizeof(int)); // 4  printf(\u0026#34;%d\\n\u0026#34;,sizeof(char)); // 1  printf(\u0026#34;%d\\n\u0026#34;,sizeof(unsigned int)); // 4  printf(\u0026#34;%d\\n\u0026#34;,sizeof(long int)); // 8  printf(\u0026#34;%d\\n\u0026#34;,sizeof(long long int)); // 8  printf(\u0026#34;%d\\n\u0026#34;,sizeof(float)); // 4  printf(\u0026#34;%d\\n\u0026#34;,sizeof(double)); // 8 }   MIPS汇编指令 汇编优化相关问题   算数\u0026amp;逻辑指令11bit冗余能否利用起来？\n额外11bit用于移位量\u0026amp;功能码。好处：寄存器算术操作只占用一种操作码，指令集可以使用其他操作码支持更多种指令。\n  分支可能的地址范围有32位，如何用16bit表示？\n采用基址+偏移地址的寻址方式。\n addr \u0026laquo; 2：将直接地址转换为字节地址。\n   带立即数的分支指令立即数如何编码？\nMIPS没有带立即数的分支指令，使用比较指令(slti、sltiu等）+ 分支指令组合实现。\n  访存可能的地址有32位，如何用21bit表示？\n采用基址+偏移地址的寻址方式进行访存（5 bit：寄存器 16 bit：立即数）。\n  跳转可能的地址有32位，如何用26bit表示？\nj小范围，jr大范围。\n  寻址方式  寄存器寻址：找到对应的寄存器，从寄存器中取数/写数。如：R type(add)。 立即数寻址：指令中的立即数可以被直接使用。如：I type(addi) 基址寻址：目标地址=基址（存储于寄存器中）+ 立即数。如：lw,sw PC相对寻址：PC+立即数。如：beq 伪直接寻址：固定PC的高4位不变。如：j  MIPS过程调用   Preserved（子程序不改变这些寄存器的数据，如果子程序要用，需要子程序维护好）\n  Not Preserved（子程序可以改变这些寄存器的数据，如果主程序要用，需要主程序维护好）\n  考虑以下汇编：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  fact: addi $sp, $sp, -8 sw $ra, 4($sp) sw $a0, 0($sp) slti $t0, $a0, 1 beq $t0, $zero, L1 addi $v0, $zero, 1 addi $sp, $sp, 8 jr $ra L1: addi $a0, $a0, -1 jal fact lw $a0, 0($sp) lw $ra, 4($sp) addi $sp, $sp, 8 mul $v0, $a0, $v0 jr $ra   对应：\n1 2 3 4 5  int fact(int n) { if (n \u0026lt; 1) return 1; else return (n * fact(n-1)); }   ","date":"2022-06-03T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/assembly/","title":"MIPS汇编语言"},{"content":"Memory RAM random access是指该存储器的所有内容都可以被读取和写入，且与时间和位置无关。\n    SRAM DRAM     中文名 静态随机访问存储器 动态随机访问存储器   速度 快 慢（需要读取内容后刷新、定期刷新）   结构 由MOS管组成的锁存器（6T） 由MOS管和电容实现（1T1C）   容量 小 大   应用 缓存 主存   访问时间 1~10ns 10~100ns    常见问答：\n  DRAM电容量C的权衡：\n 大电容容量C的优势：提供更长的数据保持时间 大电容容量C的劣势：工艺实现难度加大，密度降低    RAS和CAS均为低电平有效，其中CAS可以作为输出使能信号。\n  cache 原理 存储系统满足局部性原理：\n 时间局部性——最近的将来要用到的信息很可能就是现在正在使用的信息。主要由循环造成。 空间局部性——最近的将来要用到的信息很可能与现在正在使用的信息在空间上是邻近的。主要由顺序执行和数据的聚集存放造成。  cache的访问时间 一级cache（$r$为访问时间比，$e$为访问效率）： $$ T_A=T_{A1}+(1-H)T_{A2}\\ r=\\frac{T_{A2}}{T_{A1}}\\ e=\\frac{T_{A1}}{T_A} = \\frac{1}{1+(1-H)r} $$ 二级cache： $$ T_A=T_{A1}+(1-H_1)[T_{A2}+(1-H_2)T_{A3}] $$\ncache的基本结构 需要解决两个问题：\n 数据是否在cache中？ 如果在cache中，如何找到数据？  首先需要指出主存存储和cache存储的格式：\n 主存存储 主存块号+行内地址 cache存储 （标签）+cache行号+行内地址  每个主存块和每个cache行储存的数据相同，两者的数据传输以块/行为单位。其中每个cache行的组成如下：数据+标签+有效位。\ncache地址映像方式 三种地址映像方式：\n 直接映像: 主存块只可能在cache的某个特定行中 全相联映像: 主存块可以放在cache的任意行中 组相联映像: 主存块可以放在cache中的n个特定行中，n一般在2到8之间，将这n个行称为一个Cache组。  直接映像 主存标号$i$，cache标号$j$满足以下关系： $$ j = i \\mod N \\ i = j+Nk(k=0,1..) $$ 可以直接写成AB、AC，但是只适用于直接映像。\n对于32位内存系统，假设cache每行有$x$byte，cache共$y$行，则低$\\log_2x$位为块内地址，中间$\\log_2y$位为cache行号，剩下$(32-\\log_2x-\\log_2y)$位为主存标签。\n在这种情况下，由于每行cache的数据有$4x$bit，还有1 bit有效位，所以cache的实际总位数为： $$ y[4x+1+(32-\\log_2x-\\log_2y)] $$ 注意到cache每行至少储存1个word，所以$x$一定是4的倍数，地址的后两位一定是0。载入cache数据时仍然以word为单位进行载入。\n全相联映像 对于32位内存系统，假设cache每行有$x$byte，则低$\\log_2x$位为块内地址，剩下$(32-\\log_2x)$位作为主存标签。\n组相联映像 对于32位内存系统，假设cache每行有$x$byte，cache共$y$行，$z$路组相连，则低$\\log_2x$位为块内地址，中间$\\log_2(\\frac{y}{z})$位作为cache组号，剩下$(32-\\log_2x-\\log_2(\\frac{y}{z}))$位作为主存标签。\n直接映像为$z=1$，全相联映像为$z=y$。\ncache数据替换 每个cache行有一个有效标志位v，表明“这一行的主存数据副本是有效的”。v=1时cache行才能被命中。\n 复位、刚上电或清空cache时，所有行的v=0。 cache行刚刚被替换时，对应行的v=1。  当访问一个地址发现其不在cache中时，复制主存块到缓存的行中；当主存块对应的cache行均被占用（有效位为1）时，需要选择一个cache行进行替换。\n 直接映像 只有一行可以被替换，不用选 组相联/全相联  随机法(Random)：在cache中随机选择一个主存块 先进先出法(FIFO, First-In First-Out)：选择一个集合中最先进入cache中的主存块(即存在时间最长的块)，类似于数据结构中的队列。 最近最少使用法(LRU, Least recently used)：替换cache中最近最少被使用的主存块    cache数据更新 当需要向层次结构存储器写入数据时，需要考虑将数据存入cache还是主存的问题。\nwrite through 指高速缓存和主存都写入。\nwrite back 先将数据写入Cache中，之后在该块要被替换出Cache时才将数据写到主存储器中。\n在cache中会添加一个脏位（dirty bit）。脏位为1意味着cache里面的数据是更新后的，而主存储器里面的数据是过时的。不一致的数据在被替换时一定要写回主存中。\n    Write Through Write Back      既写到cache同时也更新主存储器 只写cache，当数据被替换出cache时才将写回到主存储器    慢 快   被替换是否会导致写操作 No Yes   重复的写操作是否重复写主存 Yes No    cache性能评估  强迫性缺失：第一次访问主存储器中的某一个数据块，只能先从主存储器将数据加载到cache中。 容量缺失：由于cache容纳不了程序所需的所有主存块而引起的缺失。 冲突缺失：在组相联或者直接映像中，多个的主存块竞争同一个cache组时引起的缺失，也称碰撞缺失。  ","date":"2022-05-31T19:22:17+08:00","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/memory/","title":"Cache"},{"content":"流水线计算公式 $n$为指令数，$k$为流水线级数，级间延时$\\Delta t$。\n实际吞吐率（单位时间内流水线处理的指令数）： $$ TP=\\frac{n}{(k+n-1)\\Delta t} $$ 最大吞吐率： $$ TP_{max} = \\frac{1}{\\Delta t} $$ 实际加速比： $$ S = \\frac{kn}{k+n-1} $$ 最大加速比： $$ S_{max}=k $$\n流水线中控制信号的流动 控制信号在IF之后的ID/RF阶段产生。\n ID/RF：Extop EX：ALUSrc、ALUOp、RegDst？？ MEM：MemWrite、Branch WB：MemToReg、RegWrite  流水线中的冒险 首先列出未冒险时流水线CPU在各步中进行的操作：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC] * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; ALUOut\u0026lt;=PC+(signext(IR[15:0]\u0026lt;\u0026lt;2)) * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) if (A=B)PC\u0026lt;=ALUOut    MEM Reg[IR[15:11]]\u0026lt;=ALUOut Lw:MDR\u0026lt;=MemData[ALUOut];Sw:MemData[ALUout] \u0026lt;=B     WB  Reg[IR[20:16]] \u0026lt;=MDR      结构冒险 problem 流水线处理器中直接取消了InstMemory和DataMemory混用的做法，因此不必担心存储器访问的冲突。\n ALU使用冲突。考虑下列指令：  1 2  add $t0,$t1,$t2 beq $a0,$a1,label   当add指令执行完EX时，beq指令执行完ID，ALU产生冲突的结果。\n寄存器堆写入冲突。考虑下列指令：  1 2  lw $a0,0($t0) add $t0,$t1,$t2   当add指令执行完MEM时，lw指令执行完WB，寄存器写入数据产生冲突的结果。\nsolution   ALU使用冲突：\nbeq指令原先需要进行两次计算操作：1)在ID阶段计算分支地址 2)在EX阶段作差比较，更新PC。\n现在需要将计算分支地址移动到EX阶段，把ALUOut计算分解为ALU和PCAdd（一个周期进行两次计算），在MEM阶段更新PC。\n  寄存器堆写入冲突：\n将R型的Write back移动到WB阶段。\n  更新后的操作如下：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026lt;\u0026lt;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      数据冒险 无法得到所需的数据而导致不能执行后续指令。数据冒险面对的是操作数是否已经更新的问题。\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B ALUOut\u0026lt;=A+sign-ext(IR[15:0]) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026lt;\u0026lt;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;= ALUOut Reg[IR[20:16]] \u0026lt;= MDR      Read after write data hazards(RAW) 硬件优化 考虑以下指令：\n1 2  add $r1,$r2,$r3 add $r2,$r1,$r3   before:\n               add $r1,$r2,$r3 IF ID EX MEM WB     nop          nop          add $r2,$r1,$r3    IF ID EX MEM    注意到第一条指令在WB阶段将结果写回寄存器（注意已经不是MEM阶段了！），而第二条指令在ID阶段读取寄存器。可以不修改数据通路，但是需要保证寄存器先写后读（否则需要阻塞3个周期）。\n 实现方法：\n 流水线上的寄存器在上升沿时写入，在时钟的下降沿写入寄存器堆。 比较写入地址和读取地址，当两者相同且要写入寄存器堆时，读取端的数据直接选择为写入端的数据而不从寄存器堆中读取。   Forward(转发) 考虑以下指令：\n1 2 3  add $r1,$r2,$r3 sub $r4,$r1,$r5 and $r6,$r1,$r7   after:\n               add $r1,$r2,$r3 IF ID EX MEM WB     sub $r4,$r1,$r5  IF ID EX MEM WB    and $r6,$r1,$r7   IF ID EX MEM WB    指令1在WB阶段写入r1寄存器，但指令2、3在ID阶段就要用到r1。不过实际上在指令的EX阶段该数值就已经计算完毕，需要在指令2、3的EX阶段用到。\n对于指令2，EX的操作数来源于EX/MEM.ALUOut；对于指令3，EX的操作数来源于MEM/WB.ALUOut；\nLoad-use data hazard(lw-calculate type) Forward 考虑以下指令：\n1 2 3  lw $r1,100($r2) sub $r4,$r1,$r5 and $r6,$r1,$r7   before:\n               lw $r1,100($r2) IF ID EX MEM WB     nop          nop          sub $r4,$r1,$r5    IF ID EX MEM   and $r6,$r1,$r7     IF ID EX    after:\n               lw $r1,100($r2) IF ID EX MEM WB               sub $r4,$r1,$r5   IF ID EX MEM WB   and $r6,$r1,$r7    IF ID EX MEM    lw后r1的新值在MEM阶段后产生，随后被转发至MDR（注意此处的MDR与多周期中的MDR不同，此处的MDR应该是MEM/WB的一部分）中，在下个周期供sub的EX阶段使用。\n上述方法必须使用一次stall，可以重排指令，在lw之后运行一条不依赖r1寄存器的指令。\n更新后的操作如下：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B; (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A+sign-ext(IR[15:0]); (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      Load-use data hazard(lw-sw type) 考虑以下指令：\n1 2  lw $a0,10($a1) sw $a0,10($a2)   before\n               lw $a0,10($a1) IF ID EX MEM WB     nop          sw $a0,10($a2)   IF ID EX MEM WB    after\n               lw $a0,10($a1) IF ID EX MEM WB     sw $a0,10($a2)  IF ID EX MEM WB     lw在MEM阶段结束后更新a0的值，此时可以直接转发给sw，以供在下一时钟周期存入存储器。\n 注意与以下情景做区分：\n1 2  lw $t4, 0($t0) sw $t0, 0($t4)   这就不是lw-sw type了，解决方案见lw-calculate type。\n 控制冒险 取到的指令可能不是所需要的，导致指令不能在预定的时钟周期内执行。控制冒险面对的是下一条指令的PC是多少的问题。\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * * PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B; (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A+sign-ext(IR[15:0]); (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A-B; PCAdd\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2))    MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B(B,MEM/WB.MemReadData) if(Zero) PC\u0026lt;=PCAdd    WB Reg[IR[15:11]]\u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      beq hazard 考虑如下指令：\n1 2  beq $t1,$t2,0x10 add $a3,$a2,$a1   before:\n               beq $t1,$t2,0x10 IF ID EX MEM WB     nop          nop          nop          add $a3,$a2,$a1     IF ID EX    beq在MEM阶段才执行跳转，在WB阶段将目标地址写入PC，写入PC后下一条指令在IF阶段取用PC，默认情况下需要stall 3个周期，否则下一条指令执行可能会发生错误。\n但实际上判断是否需要跳转的所有条件在EX阶段执行后就可以全部掌握，可以将ALUOut转发的结果转发至IF，这样只需要stall 2个周期。\nafter(v1):\n               beq $t1,$t2,0x10 IF ID EX MEM WB     nop          nop          add $a3,$a2,$a1    IF ID EX MEM    实际上，也可以将分支判断移动到ID阶段：\n    R lw or sw beq J     IF PC\u0026lt;=PC+4; IR \u0026lt;=MemInst[PC]; * * *   ID opcode\u0026lt;=IR[31:26]; A\u0026lt;=Reg[IR[25:21]]; B\u0026lt;=Reg[IR[20:16]]; * if(A==B) PC\u0026lt;=PC+(signext(IR[15:0]\u0026laquo;2)) PC \u0026lt;= {PC[31:28],IR[25:0],2’b00}   EX ALUOut \u0026lt;= A op B; (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR) ALUOut\u0026lt;=A+sign-ext(IR[15:0]); (Register,EX/MEM.ALUOut,MEM/WB.ALUOut,MDR)     MEM  Lw:MDR\u0026lt;=MemData[ALUOut]; Sw:MemData[ALUout] \u0026lt;=B(B,MEM/WB.MemReadData)     WB Reg[IR[15:11]] \u0026lt;=ALUOut Reg[IR[20:16]] \u0026lt;=MDR      但是可能会带来一些新的问题：\n  在EX阶段我们使用ALU比较两个操作数是否相等，使用PCAdder计算分支地址，所以现在需要在ID阶段额外引入比较器和PC计算器。注意到数据可能来自旁路。\n  在ID阶段判断beq，等价于将beq的EX阶段提前进行，这样就会产生3种情况：\n beq前1条指令为R type指令，stall 1个周期（1EX-\u0026gt;2ID）                 add $a3,$a2,$a1 IF ID EX MEM WB     nop          beq $t0,$a3,0x10   IF ID EX MEM WB     beq前1条指令为lw指令，stall 2个周期（1MEM-\u0026gt;2ID）                 lw $a3,0($a2) IF ID EX MEM WB     nop          nop          beq $t0,$a3,0x10    IF ID EX MEM     beq前2条指令为lw指令，stall 1个周期（1MEM-\u0026gt;3ID）                 lw $a3,0($a2) IF ID EX MEM WB     add $t3,$t2,$t1  IF ID EX MEM WB    nop          beq $t0,$a3,0x10    IF ID EX MEM      延迟槽技术 即使将beq的判断前移到ID阶段，在beq之后也必须stall一个周期。可以在stall周期内执行一些必定要执行的指令，这就是延迟槽技术。\n无特殊说明使用延迟槽技术的情况下，即使beq后面的指令必定执行，也必须要stall。\n预测  静态预测：总预测分支不执行或者执行，错误则撤销指令。若预测失误会导致不必要的流水线重置。 动态预测：在IF阶段进行分支预测缓存，可以用PC（或者PC的低位地址）为索引，记录过去是否跳转。   实现过程：\n  clock 1(IF):\n在第一次执行beq指令时，建立BHT和BTB，并存下1)指令地址 2)最终是否跳转 3)跳转目标地址；在之后执行beq指令时，查询指令地址是否在BHT和BTB中，若不存在，建立新的条目；若存在，根据历史记录判断是否跳转；若跳转，取出目标地址作为下一条指令的IF地址。\n  clock 2(ID):\n根据预测目标地址取出指令。\n   j hazard 考虑如下指令：\n1 2  j label add $t3,$t1,$t2                  j label IF ID EX MEM WB     stall          add $a3,$a2,$a1   IF ID EX MEM WB    j在ID阶段完成目标地址的计算，需要stall一个周期。\n**但这种做法是错误的！**因为流水线直到ID阶段才能知道取出的指令为j，而此时下一条指令只能已经从指令存储中取出，只能延后执行，而不能不执行。\n于是我们不进行硬件阻塞。j指令执行完ID阶段时，可以判断出执行的是j指令，此时下一条指令（实际上不会执行）也执行完IF阶段，但之后的步骤都会被flush掉，ID阶段生成的新地址也被用于载入下下一条指令。从时间上看还是stall了一个周期。\n               j label  IF ID EX MEM WB     add $a3,$a2,$a1(next)  IF x x x x    add $a3,$a2,$a1(jump target)   IF ID EX MEM WB     转发方式总结\n 数据冒险   A2-\u0026gt;B1 R型的前前条为R型 A3-\u0026gt;B1 R型的前条为R型 A4-\u0026gt;B2 lw-sw转发  此外，A4-\u0026gt;B1无法转发，对应于lw-R型必须stall一个周期。\n 控制冒险(beq)   A2-\u0026gt;B0 beq的前前条为R型，可以使用转发解决 A3-\u0026gt;B0 beq的前前条为lw，需要stall 2个周期 A4-\u0026gt;B0 beq的前条为R型，需要stall 1个周期 A5-\u0026gt;B0 beq的前条为lw型，需要stall 2个周期  注意在转发时不能跨时钟周期转发，比如上上条指令ALU的结果输出不能直接转发，必须要经过MEM/WB寄存器。\n 考虑冒险的数据通路设计 Forward Unit R-R type(1) 若R型的前条为R型，则可能需要从EX_MEM寄存器中转发至EX阶段：\n1 2 3 4 5 6 7 8  if (EX_MEM.RegWrite // 需要写入寄存器  and (EX_MEM.RegWrAddr != 0) // 不能使用0寄存器  and (EX_MEM.RegWrAddr == ID_EX.RegisterRs)) // 触发转发条件（如果不使用转发就会冒险）  ForwardA = 10; if (EX_MEM.RegWrite and (EX_MEM.RegWrAddr != 0) and (EX_MEM.RegWrAddr == ID_EX.RegisterRt)) ForwardB = 10;   R-R type(2) 若R型的前前条为R型，则可能需要从MEM_WB寄存器中转发至EX阶段：\n1 2 3 4 5 6 7 8 9 10 11 12  if (MEM_WB.RegWrite and (MEM_WB.RegWrAddr != 0) and (MEM_WB.RegWrAddr == ID_EX.RegisterRs) and (EX_MEM.RegWrAddr != ID_EX.RegisterRs || ~ EX_MEM.RegWrite) // 从前条转发的条件不满足 ) ForwardA = 01; if (MEM_WB.RegWrite and (MEM_WB.RegWrAddr != 0) and (MEM_WB.RegWrAddr == ID_EX.RegisterRt) and (EX_MEM.RegWrAddr != ID_EX.RegisterRt || ~ EX_MEM.RegWrite) // 从前条转发的条件不满足 ) ForwardB = 01;   最后一个判断条件是为了避免以下情况（前两条指令都是以关联寄存器为目的寄存器的时候，需要转发最新的数据，其数据来源是前一条，而不是前前条）：\n1 2 3  add $1,$1,$2 add $1,$1,$3 add $1,$1,$4   综上可知，EX阶段的forward单元可以描述为（以操作数1为例）：\n1 2 3 4 5 6 7 8  always @(*) begin case(ForwardA) 00:ALU_op1 \u0026lt;= ID_EX.op1; 01:ALU_op1 \u0026lt;= MEM_WB.wb_res; 10:ALU_op1 \u0026lt;= EX_MEM.alu_res; default:ALU_op1 \u0026lt;= ID_EX.op1; endcase end   lw-sw type 若sw的前条为lw，则可能需要从MEM/WB寄存器中转发至MEM阶段：\n1 2 3 4 5 6  if(EX_MEM.RegWrAddr != 0 // 不能使用0寄存器  and EX_MEM.MemWrite // 需要写入存储器(sw)  and MEM_WB.MemRead // 需要读取存储器(lw)  and EX_MEM.RegWrAddr == MEM_WB.RegWrAddr // 转发源和转发目标的寄存器编号一致 ) ForwardA = 1;   综上可知，MEM阶段的forward单元可以描述为：\n1 2 3 4 5 6  always @(*) begin case(Forward) 0:Mem_Write_Data \u0026lt;= EX_MEM.op2; 1:Mem_Write_Data \u0026lt;= MEM_WB.Mem_Read_Data; endcase end   beq 若beq的前前一条指令为R type，则需要将EX_MEM中的ALU计算结果转发至ID阶段：\n1 2 3 4  if(EX_MEM.RegWrite // 需要写入寄存器  and EX_MEM.RegisterRd == IF_ID.RegisterRs // 需要用到寄存器中的结果  ) Forward = 1;   综上可知，ID阶段的forward单元可以描述为：\n1 2 3 4 5 6  always @(*) begin case(Forward) 0:compare_op1 \u0026lt;= regA; 1:compare_op1 \u0026lt;= EX_MEM.alu_res; endcase end   Hazard Unit lw-R type 1 2 3 4  if (ID/EX.MemRead // 是否为load指令  and ((ID/EX.RegisterRd == IF/ID.RegisterRs) or (ID/EX.RegisterRd == IF/ID.RegisterRt)) ) // EX级的装载指令的目的寄存器是否与在ID级指令的某一个源寄存器相匹配（可能会发生冒险）  stall = 5\u0026#39;b11000; // stall IF and ID   beq 1 2 3 4 5  if(ID.branch // 分支指令  and ((ID_EX.RegWrite and (ID_EX.RegisterRd == IF_ID.RegisterRs or ID_EX.RegisterRd == IF_ID.RegisterRt))) // R type  and ((EX_MEM.MemRead and (EX_MEM.RegisterRd == IF_ID.RegisterRs or EX_MEM.RegisterRd == IF_ID.RegisterRt))) // lw  ) stall = 5\u0026#39;b11000; // stall IF and ID    当 beq 前一条指令为 lw 指令时，我们阻塞流水线一个周期，在 lw 和 beq 中间插入一个气泡。此时这一情况自动退化为前前一条指令为 lw 的情况，会被上述逻辑再次处理，因此最终还是会完成 2 个周期的阻塞。\n Flush Unit 使用flush[i]清除第i级流水线上执行的指令（对应4级流水寄存器以及最终写回的寄存器堆）：\n1 2 3  if(flush[i]) begin stage_reg[i] \u0026lt;= 0; end   流水线CPU异常处理 假设有3种异常：badop，IRQ（外部中断），ALUExp。\nException被放置在EX阶段，因此badop要经过一次ID/EX寄存器。\n触发异常时，该单元会flush掉当前指令的EX/MEM寄存器，下条指令的ID/EX寄存器，下下条指令的IF/ID寄存器。（注意flush由hazard和exception单元共同控制）\n扩展技术 指令级并行 超级流水线 用于缩短时钟周期。\n多发射 用于降低CPI。\n  超长指令字 静态决定让哪些指令同时执行（在编译阶段由编译器决定）。\n  超标量 动态决定哪些指令同时执行 （在运行时由硬件决定）。\n IOI-IOC,IOI-OOC,OOI-OOC\n   线程级并行 超线程 多核处理器 $a$为并行部分的比例，$n$为并行部分的加速比。 $$ S=\\frac{1}{(1-a)+\\frac{a}{n}} $$\n异构计算 单指令流多数据流，具有更大的并行度，设计相对比较简单。\n","date":"2022-05-31T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/digital_logic_and_processors/pipeline_cpu/","title":"Pipeline CPU"},{"content":"冰菓 今夜与君\n爱梦相会\n务必觅得\n微眠之约\n萌生此等惬意\n实乃徒增彷徨\n予君之意\n君不知乎\n察其目光\n未萦他意\n宛如待友\n毫无二致\n许愿星逝于晓\n夜现晨湮之法\n愿君得察\n今夜与君\n爱梦相会\n务必觅得\n微眠之约\n","date":"2022-05-29T16:24:16+08:00","permalink":"https://ther-nullptr.github.io/posts/small_talk/ice-cream/","title":"Ice Cream"},{"content":"Hugo commands  create a article  1  $ hugo new post/first.md    start hugo server  1 2  $ hugo server # simple debug $ hugo server --theme=Mainroad --buildDrafts # debug with theme    watch environment info  1  $ hugo env   ","date":"2022-05-29T00:00:00Z","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/command/","title":"Hugo Commands"},{"content":"Fourier Transform:\n1  FourierTransform[HeavisideTheta[x],x,w]  Inverse Fourier Transform:\n1  InverseFourierTransform[1/(1+I*w),w,x]  Fourier coefficient:\n1 2 3  FourierSinCoefficient[SquareWave[x],x,n]FourierCosCoefficient[SquareWave[x],x,n]FourierCoefficient[SquareWave[x],x,n]  Convolution:\n1 2  Convolve[UnitBox[x],UnitBox[x],x,x]Convolve[Exp[-a*t]*HeavisideTheta[t],Sin[t]*HeavisideTheta[t],t,x]  DTFT:\n1  FourierSequenceTransform[HeavisideTheta[n]*a^n,n,w]  IDTFT:\n1  InverseFourierSequenceTransform[1,n,w]  Laplace:\n1  LaplaceTransform[t^4Sin[t],t,s]  InverseLaplace:\n1  LaplaceTransform[E^(-t),t,s]  ","date":"2022-04-16T00:14:35+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/ss_mathematica/","title":"Mathematica in Signal \u0026 System"},{"content":"快速排序与归并排序的思想 起源是递归法——将序列分成两部分处理，或者说，用二叉树遍历的逻辑处理。二叉树的遍历基本有三种方式——前序、中序、后序。\n  归并是一种后序遍历：算法到手有两个已经处理好的序列，然后把这两个序列处理成最终的结果。处理的最后一步，当然是完成对序列的排序，因此，算法的内容就是：将两个排序好的序列排成一个新的序列——这就是归并。\n  快排是一种前序遍历：对一个序列进行处理，然后处理其子列。处理有这样的要求：将两个子列都完全完成处理以后，整个数列就排好了。因此：“划分点”是唯一的符合条件的处理方法。\n  那么有没有中序遍历？手里拿着一个序列：一半已经排好，另一半还是完全乱的，这一步处理的目的就是：这一步执行完成之后，再对右边进行排序，整个序列就排好了。所以，这一个步骤的内容就应该是：维持左边的序列完好，保证右边所有的元素都大于左边的所有元素。\n  ","date":"2021-12-03T00:13:05+08:00","permalink":"https://ther-nullptr.github.io/posts/quotes/%E4%B8%87%E7%A5%9E/","title":"快速排序与归并排序的思想"},{"content":"计算机美化指南 前言 一个美观的开发界面，对于调试程序、管理代码版本、提升编程体验等有着至关重要的作用。本文介绍了windows平台下命令行界面的美化方法，以期让读者拥有更好的编程体验。\n在图形化用户界面（GUI）大规模普及之前，命令行界面（CLI）一直是电脑界的主流。CLI开销小、运行快速，但是非专业用户使用不方便。如今，不从事开发的电脑用户接触到命令行的机会已经很少了（非计算机系学习C，可能只会在“命令行参数”一节接触到命令行），但如果从事软件开发，使用git、gcc等工具，熟练掌握命令行的使用还是有必要的。\ncmd 点击win+R，输入cmd，就会弹出windows下最基本的命令行终端——cmd。它的初始界面长这样：\n且不说白+黑的配色毫无生机，字体看上去也十分违和。这种不美观的界面可能的确劝退了不少人学习它的欲望。\n 科普：什么样的字体才能称之为好看？\n  serif：衬线字体，字体边缘具有明显的艺术修饰效果，如 宋体（simsun）、Times new roman。\n这种字体适合做艺术字，但若用作代码字体，则会显得节外生枝，影响呈现效果。\n  sans-serif：非衬线字体，字体比划一般粗细均匀、清晰，如 微软雅黑（Arial）。这种字体一般用于正文写作。\n  monospace：等宽字体，指每个英文字符（字母、数字、标点）宽度一致的字体。如 Consolas、Courier New。\n这种字体由于呈现效果较好，被广泛地用于编程。\n绝大多数开发工具都会有使用等宽字体的建议（如VS 2019）：\n   我们试图给cmd换一个monospace的字体（右键边框，点击“属性”）。遗憾的是，cmd字体的选择十分匮乏，找不到合适的monospace字体。\npowershell 我们看看windows上另一款更加强大的命令行界面：powershell。在windows搜索框中键入powershell，打开。\n遗憾的是，除了黑色界面变成蓝色界面，字体的呈现效果并没有什么改观。而且，powershell也没有提供一种较为美观的monospace字体。\nwindows terminal 长期以来，windows都没有像mac、Linux那样，为开发者提供一个较为美观的命令行界面。这种情况一直到2019年windows terminal的推出才有所改观。你可以在Microsoft Store中直接安装它。\n安装完毕后，启动效果如下：\n打开“设置-power shell图标-外观”，可以看到现在终端的字体是Cascadia Mono，可以查证这是一种等宽字体。windows powershell的字体的选择十分丰富，你可以根据自己的喜好任意挑选。\noh-my-posh 还可以实现更加美观的效果吗？当然可以！我们需要借助oh-my-posh插件，先看下最终效果吧:\n可以看到，该插件不仅加入了彩色的图标、操作时间等元素，而且对文件夹的git仓库状态等也有较好的显示。\n预安装要求：Windows terminal、git（后台回复：git，领取git安装程序，安装时只需一路点OK）。\n  下载oh-my-posh和posh-git插件\n由于一些众所周知的原因，网络上所展示的传统的下载途径可能需要一些特殊的手段。对此，小编准备了插件资源（后台回复：terminal，提取插件）。资源中有一个Modules文件夹和一个Microsoft.PowerShell_profile.ps1文件。\n下载完毕后，在你的电脑中找到C:\\Users\\用户名\\Documents(或文档)\\WindowsPowerShell文件夹（也有可能是其它的D盘或E盘，因人而异）。此时的文件夹中应该有一个Scripts文件夹。将Modules文件夹和一个Microsoft.PowerShell_profile.ps1文件按照如下方式放置：\n启动windows terminal，会看到以下场景：\n这些方块是什么？是乱码。这是因为系统自带的字体不能渲染oh-my-posh的一些特定符号。我们需要下载对应的字体。\n  终端后续配置\n为渲染这些符号，我们需要下载名为Nerd系列的字体。网址如下：https://www.nerdfonts.com/\n（若网址打不开，也可后台回复：fonts，领取Nerd字体）。解压文件夹后，打开其中的.ttf文件，点击安装，即可使用字体。\n重启windows terminal，选择刚才安装的字体，即可呈现出正确的效果。\n还可以设置终端背景、终端透明度等，让你的命令行界面更加出彩。\n至此，命令行界面美化完成！\n  ","date":"2021-08-19T23:53:42+08:00","permalink":"https://ther-nullptr.github.io/posts/awesome_toolkits/oh-my-posh/","title":"Oh My Posh"}]