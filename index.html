<!DOCTYPE html>
<html lang="en">
<head>
	<meta name="generator" content="Hugo 0.99.0" />
  
    <title>Ther&#39;s Blog</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="https://ther-nullptr.github.io/" />




<link rel="stylesheet" href="https://ther-nullptr.github.io/assets/style.css">

  <link rel="stylesheet" href="assets/%25!s%28%3cnil%3e%29.css">






<link rel="apple-touch-icon" href="https://ther-nullptr.github.io/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="https://ther-nullptr.github.io/">



<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Ther&#39;s Blog">
<meta property="og:description" content="" />
<meta property="og:url" content="https://ther-nullptr.github.io/" />
<meta property="og:site_name" content="Ther&#39;s Blog" />

  
    <meta property="og:image" content="https://ther-nullptr.github.io/">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">





  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Ther&#39;s Blog" />









</head>
<body class="">


<div class="container headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="https://ther-nullptr.github.io/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <div class="menu-trigger">menu</div>
    
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/posts/">Home</a></li>
        
      
        
          <li><a href="/about/">About</a></li>
        
      
        
          <li><a href="/archives/">Archives</a></li>
        
      
        
          <li><a href="/search/">Search</a></li>
        
      
        
          <li><a href="/links/">Links</a></li>
        
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/posts/">Home</a></li>
      
    
      
        <li><a href="/about/">About</a></li>
      
    
      
        <li><a href="/archives/">Archives</a></li>
      
    
      
        <li><a href="/search/">Search</a></li>
      
    
      
        <li><a href="/links/">Links</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
  
  <div class="posts">
    
    

    
    
      
    
    

    
      <div class="post on-list">
        <h1 class="post-title">
          <a href="https://ther-nullptr.github.io/posts/research/knowledge-distillation-papers/">knowledge distillation papers</a>
        </h1>
        <div class="post-meta">
          <span class="post-date">
            2022-08-17
          </span>
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://ther-nullptr.github.io/tags/research/">research</a>&nbsp;
            
          </span>
        


        



        <div class="post-content">
          
            以下对于distill model的研究将不只局限于ASR领域，还包括CV和NLP领域等。
loss algorithms 首先需要借助PyTorch平台简要介绍知识蒸馏中经常需要用到的一些loss api。
KL loss KL div的计算方式如下：
其中，PyTorch API为：torch.nn.KLDivLoss。
KL div衡量的是给定任意分布偏离真实分布的程度。从公式中可以看出，$p(x_i)$ 有更高概率的匹配区域比低 $p(x_i)$ 概率的匹配区域更加重要。
实际上，我们有：
等式右边第一项为交叉熵，由于$H(X)$（某一事件的熵）是固定的，所以KL散度的含义就是，相对于最优的编码，使用错误的编码浪费的比特数。
cos embedding loss PyTorch API为：torch.nn.CosineEmbeddingLoss。
contrastive loss BCE loss BCEloss解决的是二分类问题，或者可以视作一种简化版的交叉熵损失函数——将所有的其它例子都视作负例。
InfoNCE loss 同样可以使用温度参数$\tau$进行调节。
$l1$/$l2$ loss l1: torch.nn.L1Loss
l2: torch.nn.MSELoss
distill基础思想 distill最初提出于论文Distilling the Knowledge in a Neural Network。
文章在最初指出了混合模型在提高精度方面的作用，但混合模型具有开销较大的特点，一个较好的办法是将其蒸馏至一个student model中。在传统的认知中，我们认为知识蕴含在形式化的模型参数中，因此很难想象在变换模型形式的基础上保留学到的知识。
该论文指出对知识的正确认识应该是“it is a learned mapping from input vectors to output vectors”。更具体地讲，teacher model具有良好的泛化能力，蒸馏的目的就是要让student model学会teacher model的泛化能力，从而起到比直接训练student model更好的结果。
如何学习这种泛化能力？蒸馏的基础思想是使用teacher model的soft target（model预测的概率分布）训练student model（对应的，hard target指的是model预测的ground truth）。使用soft target训练有两个好处：
          
        </div>

        
        <div>
          <a class="read-more button"
            href="/posts/research/knowledge-distillation-papers/"> →</a>
        </div>
        
      </div>
    
      <div class="post on-list">
        <h1 class="post-title">
          <a href="https://ther-nullptr.github.io/posts/research/ssl-model-finetune/">SSL model finetune</a>
        </h1>
        <div class="post-meta">
          <span class="post-date">
            2022-08-12
          </span>
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://ther-nullptr.github.io/tags/research/">research</a>&nbsp;
            
          </span>
        


        



        <div class="post-content">
          
            structure of finetune models 首先有必要记录一下finetune model的结构（以wav2vec2、hubert、data2vec）为例：
wav2vec2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  Wav2VecCtc( (w2v_encoder): Wav2VecEncoder( (w2v_model): Wav2Vec2Model( (feature_extractor): ConvFeatureExtractionModel( (conv_layers): ModuleList( (0): Sequential( (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False) (1): Dropout(p=0.
          
        </div>

        
        <div>
          <a class="read-more button"
            href="/posts/research/ssl-model-finetune/"> →</a>
        </div>
        
      </div>
    
      <div class="post on-list">
        <h1 class="post-title">
          <a href="https://ther-nullptr.github.io/posts/research/superb-downstream/">SUPERB downstream</a>
        </h1>
        <div class="post-meta">
          <span class="post-date">
            2022-08-12
          </span>
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://ther-nullptr.github.io/tags/research/">research</a>&nbsp;
            
          </span>
        


        



        <div class="post-content">
          
            以下记录了superb任务中不同的downstream model：
KS 1 2 3 4 5 6 7 8 9 10 11  DownstreamExpert( (projector): Linear(in_features=768, out_features=256, bias=True) (model): UtteranceLevel( (pooling): MeanPooling() (post_net): FrameLevel( (hiddens): Sequential() (linear): Linear(in_features=256, out_features=12, bias=True) ) ) (objective): CrossEntropyLoss() )   ASR 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  DownstreamExpert( (projector): Linear(in_features=768, out_features=1024, bias=True) (model): RNNs( (rnns): ModuleList( (0): RNNLayer( (layer): LSTM(1024, 1024, batch_first=True, bidirectional=True) (dp): Dropout(p=0.
          
        </div>

        
        <div>
          <a class="read-more button"
            href="/posts/research/superb-downstream/"> →</a>
        </div>
        
      </div>
    
      <div class="post on-list">
        <h1 class="post-title">
          <a href="https://ther-nullptr.github.io/posts/small_talk/%E5%B0%8F%E9%BB%91%E5%90%8E%E4%BC%A0/">小黑后传</a>
        </h1>
        <div class="post-meta">
          <span class="post-date">
            2022-08-04
          </span>
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://ther-nullptr.github.io/tags/small-talk/">small talk</a>&nbsp;
            
          </span>
        


        



        <div class="post-content">
          
            小黑前传的名字叫作《追忆似火年华》，不过小黑后传似乎和“似火”并不怎么沾边，索性就叫小黑后传好了，以后有想法再更新一个文艺点的标题。
一 2022.6.19 考完试的第一天。
“您当日的听歌时间为8h42min，位居好友榜榜首，恭喜！”
虽然知道自己网抑云的习惯由来已久（确切地来讲，网易云和QQ音乐都听，而且QQ更多一些），但看到这个数字小黑还是震惊了一下的。其他人排解心魔的方式有社交、有读书、也有游戏，小黑则是网抑云，嗯网抑云。
小黑的听歌方式，比较奇怪。他不怎么关注日推，也不会从500多首红心中随机抽取音乐，而是这样的：在一个特定的时间段里，他会对歌单里的5~10首歌进行单曲循环，如果在这期间搜罗到了什么好音乐，单曲循环的队列就会被更新。
从这个角度讲，这种听歌机制其实很像计算机里面cache的原理——平时单曲循环的歌存在cache里，适当的时候从主存里加载歌曲到cache里再单曲循环…
从这个听歌习惯，似乎也能看到小黑的一点习惯——或者更确切的说，叫秉性——念旧、保守……
小黑摇了摇头，网抑云不是这么抑的。不过说起来，这个习惯是怎么形成的？
二 2022.5.22 小黑居然在大二下学期中刷完了一部番，不过是老番，也比较短——《新世纪福音战士》。
男主似乎和小黑有不少共同点——弱不禁风，胆小，喜欢边喝着酒/饮料边瘫坐着听音乐。
这里要特别说一下“边喝着酒/饮料边瘫坐着听音乐”，小黑在看到这些镜头时，竟然前所未有地产生了共鸣感——比起那种激励人奋进的鸡汤，小黑似乎对这样的状态更加向往。
男主有一段台词让他十分印象深刻：
你总是逃避自己讨厌的事情。
我已经很努力地再试了！
这有什么不好！
逃避讨厌的事情又有什么不对！
小黑感觉自己也在逃避，逃避的是什么？也许不只是眼前的困难——就像科研进度十分缓慢，小黑第一反应想的不是调整状态，多看几篇论文和代码，而是打开手机看eva——美其名曰寻找与自己和解的路子。
从那以后，耳机便真的成了小黑的耳旁常伴的物品了。
小黑更想逃避的，也许是真实的自己、阴暗的自己。不过，小黑是什么时候开始思考这些问题的呢？
三 2022.4.12 这场不大不小的折磨终于结束了。
身体的折磨是暂时结束了。不过从那以后，小黑似乎就变了一个人——头脑中无用的精神内耗开始变多，头脑里就好像有两个不同的政党在打架，最后也给不出什么具体的执行方案来，生活就这样原地踏步地进行着。
这造成的直接后果就是：睡眠质量严重下降，上课难以集中精神，科研开始摆烂……不过有一点，小黑始终认为，自己并没有失去对学习的兴趣，只是暂时失去了自己的方向。
说起方向，小黑有过自己真正的方向吗？从某种意义上，小黑在战略决策上似乎从来只是一株墙头草——小黑从小到大，或者更确切地说，是进了大学之后，努力的出发点就只是“我想成为xxx那样的人”——A的笔记，B的钻研，C的个人魅力……这本是一件好事，但小黑发现自己似乎哪一个人都变不成，而当别人告诉自己要“做自己”时，小黑甚至连“自我”的定义都难以下达——自己追寻了太多别人的足迹，却连自己本来的样子都忘记了。
那么，自己到底想成为什么样的人？这要从一次谈话说起。
四 2022.1.18 在入学前，小黑给自己的label是：社恐分子、小镇做题家、局外人。
一年半后，小黑给自己的label是：孤勇者、想要成为文艺青年的理工男、安静、内向，自己将会在学习和科研的路上一路狂奔。
但，果真如此吗？
我与老友聊起了关于自身的定位问题，老友说：其实你一直是一个很有人情味的人，并列举种种事例。
这时小黑才意识到，自己的内心中，本质上有很多感性的成分。自己也渴望社交、渴望沟通、渴望人与人之间微妙的联结——而不是仅仅一味扎进学术中。
“人有种奇怪的虚荣心，想让别人或自己相信他向往的是真理，但其实他有求于这个世界的是爱。“加缪一语道破天机。
自己的一些label，似乎硬生生束缚住了自己的手脚。本我，似乎与展现在世人面前的我，以及小黑所期望的我，出现了前所未有的参差。它们相互交织，却又在触及人心最柔软的部分互斥。
小黑原本以为自己的这些label大概是在高中时期形成的。但另一位老友给了他一个惊人的答案：
小学。
五 2022.8.4 递归似地分析完了所有问题，接下来要做的，就是要把所有问题层层出栈。只是，这样的思索是存在精确解的吗？如果没有，那这样的思索是无谓的吗？正如小黑不顾繁重的任务和压力，在深夜敲下废话连篇的意识流文章一样，此举意义何在？
什么才能治好小黑的精神内耗？这个学期的经历似乎告诉小黑：不是忙碌，更不是让自己的身心投入到学习和工作中。
那是什么？也许是慢慢地与留下太多遗憾地自己和解。但和解的过程，又何尝不是一个精神内耗的过程。
小黑似乎又一次掉入了无限的递归之中。
          
        </div>

        
        <div>
          <a class="read-more button"
            href="/posts/small_talk/%E5%B0%8F%E9%BB%91%E5%90%8E%E4%BC%A0/"> →</a>
        </div>
        
      </div>
    
      <div class="post on-list">
        <h1 class="post-title">
          <a href="https://ther-nullptr.github.io/posts/small_talk/review/">试错，还是错逝？</a>
        </h1>
        <div class="post-meta">
          <span class="post-date">
            2022-07-28
          </span>
          
        </div>

        
          <span class="post-tags">
            
            #<a href="https://ther-nullptr.github.io/tags/small-talk/">small talk</a>&nbsp;
            
          </span>
        


        



        <div class="post-content">
          
            “我们前后找了几十年以来的毕业生，在十六万人中分析了五百人，得到了结论。结果发现很多结果出乎清华校方的意料。 比如，我们分析了成绩因素，按理说成绩好应该更成功吧？但结果是，成绩对以后的发展并没有影响，就是说，成绩好并不代表发展好，当然也不可能发展差对吧。这是很出乎校方意料的一点。 那社工呢？大家都认为如果做了什么学生会主席、社会工作可能对未来发展有所帮助，结果还是没有关系。没有关系意思是有没有这些优势都不影响以后发展。 那么家庭影响应该足够重要了吧，比如有的家长眼界很高，有先进的观念，培养孩子很有方法，这是个影响因素吗？不是。 地域呢？比如有的同学来自偏远地区，有的在大城市，这是影响因素吗？不是。这些都不是，那我们发现了什么呢？ 我们在二十多个因素里，唯一发现很多人都具有的一个共同点就是，他们都很早地开始思考自己的未来并且着手做准备。
          
        </div>

        
        <div>
          <a class="read-more button"
            href="/posts/small_talk/review/"> →</a>
        </div>
        
      </div>
    
    <div class="pagination">
  <div class="pagination__buttons">
    
    
      <span class="button next">
        <a href="/page/2/">
          <span class="button__text">Older posts</span>
          <span class="button__icon">→</span>
        </a>
      </span>
    
  </div>
</div>

  </div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2022 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="https://ther-nullptr.github.io/assets/main.js"></script>
<script src="https://ther-nullptr.github.io/assets/prism.js"></script>







  
</div>

</body>
</html>
